{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jabir-al-nahian/Text_Summarization_with_Transformers/blob/main/Text_Summarization_with_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7es6fpoKAoA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab1698a9-b1cc-4a2f-9fd5-4dba9e431f33"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KSSto1yK2AJ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import re\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz8nJse7KXjB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f05884bb-456b-4d97-cade-39cc8b2b577d"
      },
      "source": [
        "df=pd.read_excel(\"/content/text_summarization (2).xlsx\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text  \\\n",
              "0  আমি জানি আমার এই লেখা,টির জন্য আমাকে অনেক গালম...   \n",
              "1  একটা ভাষায় তুলনামূলক ভাবে অনেক বেশি মানুষ কথা ...   \n",
              "2  আমাদের ফেব্রুয়ারি মাসটি ভাষার মাস। এর বাইরেও ত...   \n",
              "3  আমাকে যদি কেউ কখনো জিজ্ঞেস করে বাংলাদেশের সবচে...   \n",
              "4  মানুষের মুখ খুব শক্তিশালী এক জিনিস। মানুষ যেটা...   \n",
              "\n",
              "                                             Summary  \n",
              "0        বাংলাদেশে কোচিং বানিজ্য বন্ধ এখন সময়ের দাবি  \n",
              "1  বাংলা ভাষার প্রযুক্তি নিয়ে আমাদের আরো অনেক বেশ...  \n",
              "2  যদি শিশুরা বই পড়ার অভ্যাস করে তাহলে সারা জীবনে...  \n",
              "3  বাংলাদেশে সব স্তরে নারীর ক্ষমতায়নের জন্য আরও অ...  \n",
              "4                          ভালো কথা বল, নয়ত চুপ থাকো  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49c0f0a7-0ee2-4c4b-8f96-2edbe2e1196e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>আমি জানি আমার এই লেখা,টির জন্য আমাকে অনেক গালম...</td>\n",
              "      <td>বাংলাদেশে কোচিং বানিজ্য বন্ধ এখন সময়ের দাবি</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>একটা ভাষায় তুলনামূলক ভাবে অনেক বেশি মানুষ কথা ...</td>\n",
              "      <td>বাংলা ভাষার প্রযুক্তি নিয়ে আমাদের আরো অনেক বেশ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>আমাদের ফেব্রুয়ারি মাসটি ভাষার মাস। এর বাইরেও ত...</td>\n",
              "      <td>যদি শিশুরা বই পড়ার অভ্যাস করে তাহলে সারা জীবনে...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>আমাকে যদি কেউ কখনো জিজ্ঞেস করে বাংলাদেশের সবচে...</td>\n",
              "      <td>বাংলাদেশে সব স্তরে নারীর ক্ষমতায়নের জন্য আরও অ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>মানুষের মুখ খুব শক্তিশালী এক জিনিস। মানুষ যেটা...</td>\n",
              "      <td>ভালো কথা বল, নয়ত চুপ থাকো</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49c0f0a7-0ee2-4c4b-8f96-2edbe2e1196e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49c0f0a7-0ee2-4c4b-8f96-2edbe2e1196e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49c0f0a7-0ee2-4c4b-8f96-2edbe2e1196e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_ScD3LTK0a_"
      },
      "source": [
        "document = df['Text']\n",
        "summary = df['Summary']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0NXAlEKLRwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3190cd96-d866-45f3-d381-b34543251bfb"
      },
      "source": [
        "document[30], summary[30]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('\"গতরাতে আব্বু তার ফোন নিয়ে আমার কাছে এসে বললো, \"বাবা, ফেইসবুকে কোন একটা পোস্টে কিভাবে প্রাইভেসি সেট করে, একটু দেখায় দেও তো\"আমি তাকে একবার দেখালাম প্রসেসটা ... কিন্তু বয়সের কারণে খালি চোখে আব্বু ডান পাশের ছোট ডট দেখতে পাচ্ছিলো না ... বারবার বলতেছিলো, \"কই? কই ক্লিক করবো?\"প্রায় ৫ বার দেখানোর পরেও যখন আব্বু উল্টাপাল্টা ক্লিক করতেসিলো, প্রচণ্ড মেজাজ খারাপ হইলো ... আমি বেখেয়ালে একটু রাগের সুরে বললাম, \"এই সিম্পল জিনিস পারতেছো না? ধুরর\"এই কথাটা বলার সাথে সাথে আব্বুর মুখটা শুকনা হয়ে গেলো ... আমি সাথে সাথে বুঝতে পারলাম, মানুষটাকে আমি ছোট্ট একটা কথা দিয়ে অনেক বড় একটা কষ্ট দিয়ে ফেলসি ... \\'সরি\\' বলে আবার ভালোভাবে প্রসেসটা বুঝায় বললাম !!আমার ধারণা, নিজের অজান্তেই খুব ছোট ছোট কথা দিয়ে আমরা মানুষকে আঘাত করে ফেলি ... পৃথিবীতে সবাই সবকিছু পারে না ... কারো না পারা নিয়ে তার সাথে অপমানের সুরে কথা বললে সে নিজের ভেতর খুব ছোট বোধ করে ... আমার কোন অধিকার নেই কাউকে অপমান করার, কাউকে ছোট করার !!যে বাবার প্রতি আমি বিরক্ত হলাম কারণ সে সামান্য ফোন চালাতে পারছে না, সেই বাবাই ছোট বেলায় কখনো বিরক্ত হয় নি যখন আমি সামান্য হাঁটতেও পারতাম না ... দিনের পর দিন হাতে ধরে ধরে ক্লান্তিহীনভাবে শিখিয়ে গেছে ... তাকে ৫ বার বা ১০ বার ফোন চালানো শিখাতে আমার বিরক্তি আসবে কেন?নিজেকে অন্য মানুষটার জায়গায় কল্পনা করলে বুঝা যায়, কেউ আমার অপারগতা নিয়ে তাচ্ছিল্যের সুরে কথা বললে কতটা কষ্ট লাগে ... হয়তো কোন একটা ব্যাপার আমার আসলেই পারা উচিত, জানা উচিত, কিন্তু আমি পারি না অথবা জানি না ... এই ব্যর্থতা বা অপারগতার জন্য বোধহয় আমি অপমানিত হওয়া ডিজার্ভ করি না !!এই ক্ষুদ্র জীবনে ইচ্ছাকৃত কিংবা অনিচ্ছাকৃতভাবে আমার বলা কথায় যারা কষ্ট পেয়েছেন, তাদের কাছে আমি ক্ষমাপ্রার্থী ... আমি চেষ্টা করবো কখনোই কাউকে তার অজ্ঞতার জন্য ছোট না করতে !!কোন একটা বিষয় না জানাটা কোন অপরাধ না ... কিন্তু সেটা না জানার জন্য কাউকে তাচ্ছিল্য করাটা অবশ্যই অপরাধ !!আমার ধারণা, আমাদের আশেপাশে এমন কিছু মানুষ আছে যারা কথায় কথায় আমাদের ছোট করে, এই মানুষগুলোর আচরণের জন্য আমরা নিজের ভেতর ডিপ্রেসন তৈরি করে ফেলি ... যে মানুষগুলো প্রতিনিয়ত আমার অজ্ঞতা কিংবা অপারগতা নিয়ে অপমানের সুরে কথা বলে, তাদের থেকে দূরে থাকাই ভালো ... অন্যের কথার কারণে নিজের ভেতরে অপমানবোধের যে অনুভূতিটা জন্মায়, তার চেয়ে ভয়ংকর তীব্র অনুভূতি আর একটাওনেই !!',\n",
              " 'সবকিছুর সাথে আপোষ করা যায়,কিন্তু নিজের আত্মসম্মানকে যে আঘাত করে,তার সাথে আপোষ করার প্রশ্নই আসেনা ')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['Text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vanMVt32tQ1y",
        "outputId": "d9248747-5fc5-4c4d-e4fa-ec19e56968a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1026"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c1 = dict(df.Text.str.split(expand=True).stack().value_counts())\n",
        "c1 = dict(sorted(c1.items(), key=lambda x: x[1], reverse=True))\n",
        "c2 = dict(df.Summary.str.split(expand=True).stack().value_counts())\n",
        "c2 = dict(sorted(c2.items(), key=lambda x: x[1], reverse=True))"
      ],
      "metadata": {
        "id": "SN34pX5Xtnl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6FagwZYt5yI",
        "outputId": "11f1870e-ecaa-45d3-90dc-a08f21c40d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'না': 154,\n",
              " 'মানুষ': 70,\n",
              " 'জন্য': 63,\n",
              " 'করে': 62,\n",
              " 'ভালোবাসা': 62,\n",
              " 'না।': 56,\n",
              " 'অনেক': 54,\n",
              " 'করা': 48,\n",
              " 'মানুষের': 45,\n",
              " 'করতে': 45,\n",
              " 'আর': 45,\n",
              " 'হবে': 44,\n",
              " 'সব': 43,\n",
              " 'ভালো': 42,\n",
              " 'হয়': 39,\n",
              " 'কিছু': 39,\n",
              " 'যে': 38,\n",
              " 'সাথে': 34,\n",
              " 'এই': 33,\n",
              " 'কষ্ট': 32,\n",
              " 'এর': 32,\n",
              " 'থেকে': 32,\n",
              " 'নিজের': 32,\n",
              " 'ভালোবাসার': 32,\n",
              " 'কোনো': 31,\n",
              " 'সময়': 30,\n",
              " 'ও': 30,\n",
              " 'করার': 28,\n",
              " 'কথা': 28,\n",
              " 'হতে': 28,\n",
              " 'যায়': 28,\n",
              " ',': 28,\n",
              " 'তার': 26,\n",
              " 'নেই': 26,\n",
              " 'একটি': 25,\n",
              " 'উচিত': 25,\n",
              " 'থাকে': 25,\n",
              " 'হয়ে': 24,\n",
              " 'আমাদের': 24,\n",
              " 'কেউ': 24,\n",
              " 'কারো': 24,\n",
              " 'প্রতি': 24,\n",
              " 'পারে': 23,\n",
              " 'প্রেম': 21,\n",
              " '।': 21,\n",
              " 'আমরা': 21,\n",
              " 'মানুষকে': 21,\n",
              " 'উপর': 20,\n",
              " 'একজন': 20,\n",
              " 'যায়।': 20,\n",
              " 'জীবন': 20,\n",
              " 'এক': 20,\n",
              " 'হবে।': 19,\n",
              " 'হয়।': 19,\n",
              " 'নিজেকে': 19,\n",
              " 'কাউকে': 19,\n",
              " 'মন': 19,\n",
              " 'থাকা': 18,\n",
              " 'একটা': 18,\n",
              " 'কখনো': 18,\n",
              " 'তাকে': 18,\n",
              " 'এবং': 18,\n",
              " 'নিয়ে': 18,\n",
              " 'এখন': 18,\n",
              " 'করোনা': 17,\n",
              " 'এমন': 17,\n",
              " 'তা': 16,\n",
              " 'চলে': 16,\n",
              " 'সে': 16,\n",
              " 'জীবনে': 16,\n",
              " 'মধ্যে': 16,\n",
              " 'মতো': 16,\n",
              " 'শুধু': 15,\n",
              " 'যাবে': 15,\n",
              " 'সবার': 15,\n",
              " 'হচ্ছে': 15,\n",
              " 'মানে': 15,\n",
              " 'গুলো': 15,\n",
              " 'বেশি': 15,\n",
              " 'উচিত।': 14,\n",
              " 'সম্মান': 14,\n",
              " 'নেই।': 14,\n",
              " 'ভালোবাসতে': 14,\n",
              " 'খারাপ': 14,\n",
              " 'টাকা': 14,\n",
              " 'আছে': 14,\n",
              " 'দিতে': 13,\n",
              " 'জীবনের': 13,\n",
              " 'আগে': 13,\n",
              " 'হলে': 13,\n",
              " 'বলে': 13,\n",
              " 'মাঝে': 13,\n",
              " 'থাকতে': 13,\n",
              " 'কাছে': 13,\n",
              " 'যা': 13,\n",
              " 'না,': 13,\n",
              " 'দরকার': 12,\n",
              " 'নয়': 12,\n",
              " 'বলতে': 12,\n",
              " 'কিছুই': 12,\n",
              " 'সেই': 12,\n",
              " 'দিয়ে': 12,\n",
              " 'দিয়ে': 12,\n",
              " 'নারীর': 12,\n",
              " 'বা': 12,\n",
              " 'রাখতে': 12,\n",
              " 'মনে': 11,\n",
              " 'আপনি': 11,\n",
              " 'করে।': 11,\n",
              " 'কে': 11,\n",
              " 'কারণ': 11,\n",
              " 'রাখা': 11,\n",
              " 'কাজ': 11,\n",
              " 'হওয়া': 11,\n",
              " 'মেনে': 11,\n",
              " 'পাওয়া': 11,\n",
              " 'মানেই': 11,\n",
              " 'সম্পর্ক': 11,\n",
              " 'কি': 10,\n",
              " 'নিতে': 10,\n",
              " 'শেষ': 10,\n",
              " 'চেষ্টা': 10,\n",
              " 'মনের': 10,\n",
              " 'থাকলে': 10,\n",
              " 'আমি': 10,\n",
              " 'নাই।': 10,\n",
              " 'আমার': 10,\n",
              " 'থাকার': 10,\n",
              " 'সবাই': 10,\n",
              " 'দরকার।': 10,\n",
              " 'খুব': 10,\n",
              " 'নিজে': 9,\n",
              " 'চায়': 9,\n",
              " 'সময়ের': 9,\n",
              " 'প্রয়োজন': 9,\n",
              " 'সম্পর্কে': 9,\n",
              " 'যার': 9,\n",
              " 'নারীরা': 9,\n",
              " 'পেতে': 9,\n",
              " 'কষ্টের': 9,\n",
              " 'ইচ্ছা': 9,\n",
              " 'পর': 9,\n",
              " 'বন্ধু': 9,\n",
              " 'দেয়া': 9,\n",
              " 'গুরুত্ব': 9,\n",
              " 'যত': 9,\n",
              " 'বড়': 9,\n",
              " 'থাকবে': 9,\n",
              " 'মূল্য': 9,\n",
              " 'বদলে': 8,\n",
              " 'সবচেয়ে': 8,\n",
              " 'সত্যিকারের': 8,\n",
              " 'ভালো।': 8,\n",
              " 'মেয়েদের': 8,\n",
              " 'নারী': 8,\n",
              " 'অন্যের': 8,\n",
              " 'কোন': 8,\n",
              " 'নতুন': 8,\n",
              " 'দিন': 8,\n",
              " 'তাই': 8,\n",
              " 'পাশে': 8,\n",
              " 'বাংলাদেশে': 8,\n",
              " 'তাদের': 8,\n",
              " 'নষ্ট': 8,\n",
              " 'চেয়ে': 8,\n",
              " 'বই': 8,\n",
              " 'ভাইরাস': 8,\n",
              " 'যদি': 7,\n",
              " 'ঠিক': 7,\n",
              " 'নিয়ন্ত্রণ': 7,\n",
              " 'বড়': 7,\n",
              " 'সত্যি': 7,\n",
              " 'দিনশেষে': 7,\n",
              " 'প্রকাশ': 7,\n",
              " 'বলা': 7,\n",
              " 'দেশের': 7,\n",
              " 'কিন্তু': 7,\n",
              " 'লাগে': 7,\n",
              " 'দেশে': 7,\n",
              " 'দুই': 7,\n",
              " 'নাম': 7,\n",
              " 'সৌন্দর্য': 7,\n",
              " 'খুশি': 7,\n",
              " 'লেখক': 7,\n",
              " 'গেলে': 7,\n",
              " 'সুখ': 7,\n",
              " 'হয়।': 7,\n",
              " 'ভারত': 7,\n",
              " 'ছাড়া': 7,\n",
              " 'ছেলে': 7,\n",
              " 'কঠিন।': 7,\n",
              " 'বাংলাদেশ': 6,\n",
              " 'মেয়েরা': 6,\n",
              " 'একই': 6,\n",
              " 'চাওয়া': 6,\n",
              " 'আরো': 6,\n",
              " 'চেয়ে': 6,\n",
              " 'নয়।': 6,\n",
              " 'কিছুর': 6,\n",
              " 'পরিবর্তন': 6,\n",
              " 'প্রকৃত': 6,\n",
              " 'দেয়': 6,\n",
              " 'দেখা': 6,\n",
              " 'মিথ্যা': 6,\n",
              " 'আছে।': 6,\n",
              " 'করো': 6,\n",
              " 'ছেড়ে': 6,\n",
              " 'জোর': 6,\n",
              " 'আপনার': 6,\n",
              " 'দেখে': 6,\n",
              " 'প্রতিটি': 6,\n",
              " 'অল্পতেই': 6,\n",
              " 'তো': 6,\n",
              " 'পারে।': 6,\n",
              " 'লেখকের': 6,\n",
              " 'আসবে': 6,\n",
              " 'আত্মসম্মান': 6,\n",
              " 'কখনও': 6,\n",
              " 'থাকাটা': 6,\n",
              " 'যেমন': 6,\n",
              " 'ধর্ম': 6,\n",
              " 'ভুল': 6,\n",
              " 'তুমি': 6,\n",
              " 'আপনাকে': 6,\n",
              " 'দেশ': 6,\n",
              " 'খুঁজে': 6,\n",
              " 'চাইতে': 6,\n",
              " 'জিনিস': 6,\n",
              " 'বিশ্বাস': 6,\n",
              " 'পাওয়ার': 5,\n",
              " 'খরচ': 5,\n",
              " 'ভালোবেসে': 5,\n",
              " 'জরুরী।': 5,\n",
              " 'কবি': 5,\n",
              " 'শিক্ষা': 5,\n",
              " 'যাবে।': 5,\n",
              " 'যারা': 5,\n",
              " 'মায়ের': 5,\n",
              " 'পুরুষের': 5,\n",
              " 'সমাজে': 5,\n",
              " 'হলো': 5,\n",
              " 'আটকে': 5,\n",
              " 'বছরের': 5,\n",
              " 'বলার': 5,\n",
              " 'মাধ্যমে': 5,\n",
              " 'দোষ': 5,\n",
              " 'চাই।': 5,\n",
              " 'আসল': 5,\n",
              " 'দায়িত্ব': 5,\n",
              " 'দেওয়ার': 5,\n",
              " 'বুঝে': 5,\n",
              " 'একদিন': 5,\n",
              " 'যাওয়ার': 5,\n",
              " 'পৃথিবীতে': 5,\n",
              " 'তখন': 5,\n",
              " 'চোখে': 5,\n",
              " 'বেঁচে': 5,\n",
              " 'ভালোবাসায়': 5,\n",
              " 'যখন': 5,\n",
              " 'সুন্দর': 5,\n",
              " 'হয়ে': 5,\n",
              " 'নিজেদের': 5,\n",
              " 'কঠিন': 5,\n",
              " 'বাংলা': 5,\n",
              " 'ফেলে': 5,\n",
              " 'দাম': 5,\n",
              " 'হওয়ার': 5,\n",
              " 'আসে': 5,\n",
              " 'প্রশ্ন': 5,\n",
              " 'ছেলেদের': 5,\n",
              " 'ভালোবাসা।': 5,\n",
              " 'যথেষ্ট': 5,\n",
              " 'থাকে।': 5,\n",
              " 'সুখী': 5,\n",
              " 'ক্ষতি': 5,\n",
              " 'সবারই': 4,\n",
              " 'গিয়ে': 4,\n",
              " 'পাবে': 4,\n",
              " 'লুকিয়ে': 4,\n",
              " 'সন্তানের': 4,\n",
              " 'চোখের': 4,\n",
              " 'দেওয়া': 4,\n",
              " 'স্মৃতি': 4,\n",
              " 'তোমাকে': 4,\n",
              " 'হলেও': 4,\n",
              " 'আলো': 4,\n",
              " 'মজুদ': 4,\n",
              " 'আমাকে': 4,\n",
              " 'পিছনে': 4,\n",
              " 'চিন্তা': 4,\n",
              " 'অন্যকে': 4,\n",
              " 'দৃষ্টিভঙ্গি': 4,\n",
              " 'এ': 4,\n",
              " 'সকল': 4,\n",
              " 'গুলা': 4,\n",
              " 'করুন': 4,\n",
              " 'মানা': 4,\n",
              " 'সারাজীবন': 4,\n",
              " 'হার': 4,\n",
              " 'ইচ্ছে': 4,\n",
              " 'বয়স': 4,\n",
              " 'ভুলের': 4,\n",
              " 'সারারাত': 4,\n",
              " 'বেস্ট': 4,\n",
              " 'পায়': 4,\n",
              " 'নারীকে': 4,\n",
              " 'জেগে': 4,\n",
              " 'ছোটখাটো': 4,\n",
              " 'অধিকার': 4,\n",
              " 'ভালোবাসে': 4,\n",
              " 'পড়া': 4,\n",
              " 'মেয়েদের': 4,\n",
              " 'জীবনকে': 4,\n",
              " 'বড়ই': 4,\n",
              " 'গ্রহ': 4,\n",
              " 'দিয়েছে।': 4,\n",
              " 'রাখার': 4,\n",
              " 'ভাষার': 4,\n",
              " 'বসে': 4,\n",
              " 'সেটা': 4,\n",
              " 'পৃথিবীর': 4,\n",
              " 'ছোট': 4,\n",
              " 'তেমনি': 4,\n",
              " 'অপেক্ষা': 4,\n",
              " 'সকলের': 4,\n",
              " 'বিভিন্ন': 4,\n",
              " 'যাই': 4,\n",
              " 'আবেগ': 4,\n",
              " 'প্রকৃতির': 4,\n",
              " 'যাই।': 4,\n",
              " 'পরিচয়': 4,\n",
              " 'ধরে': 4,\n",
              " 'আক্রান্ত': 4,\n",
              " 'পবিত্র': 4,\n",
              " 'সঠিক': 4,\n",
              " 'থেমে': 4,\n",
              " 'আবার': 4,\n",
              " 'দূরে': 4,\n",
              " 'এখনো': 4,\n",
              " 'অতি': 4,\n",
              " 'যুদ্ধ': 4,\n",
              " 'করেছে': 4,\n",
              " 'ভুলে': 4,\n",
              " 'ভাইরাসের': 4,\n",
              " 'করতেন।': 4,\n",
              " 'যেতে': 4,\n",
              " 'পেয়ে': 4,\n",
              " 'গল্প': 4,\n",
              " 'স্কুল': 4,\n",
              " 'অবস্থায়': 4,\n",
              " 'সমাজের': 4,\n",
              " 'মহৎ': 4,\n",
              " 'যায়।': 4,\n",
              " 'সময়': 4,\n",
              " 'কাজের': 4,\n",
              " 'পড়ে': 4,\n",
              " 'স্বাধীনতা': 4,\n",
              " 'আছে,': 4,\n",
              " 'সচেতন': 4,\n",
              " 'সামনে': 4,\n",
              " 'লোক': 4,\n",
              " 'তোমার': 4,\n",
              " 'দেয়ার': 4,\n",
              " 'করি।': 4,\n",
              " 'সুযোগ': 4,\n",
              " 'দেখানো': 4,\n",
              " 'নেয়া': 4,\n",
              " 'সবচাইতে': 4,\n",
              " 'পাল্টায়': 4,\n",
              " 'চুরি': 4,\n",
              " 'ভাল': 4,\n",
              " 'দেয়।': 3,\n",
              " 'বাবা': 3,\n",
              " 'অনুভূতি': 3,\n",
              " 'যায়,': 3,\n",
              " 'তবে': 3,\n",
              " 'মর্ম': 3,\n",
              " 'কবিকে': 3,\n",
              " 'উপভোগ': 3,\n",
              " 'ঘুম': 3,\n",
              " 'মেয়ের': 3,\n",
              " 'হয়েছে।': 3,\n",
              " 'কিশোর': 3,\n",
              " 'সত্য': 3,\n",
              " 'বাংলাদেশের': 3,\n",
              " 'পথে': 3,\n",
              " 'কখন': 3,\n",
              " 'এটি': 3,\n",
              " 'স্বপ্ন': 3,\n",
              " 'মেয়ে': 3,\n",
              " 'কথা।': 3,\n",
              " 'মিষ্টি': 3,\n",
              " 'আগামী': 3,\n",
              " 'গেছে': 3,\n",
              " 'করলে': 3,\n",
              " 'মিস': 3,\n",
              " 'অভাব': 3,\n",
              " 'পাই': 3,\n",
              " 'শক্ত': 3,\n",
              " 'স্বাধীনতার': 3,\n",
              " 'টা': 3,\n",
              " 'আত্মবিশ্বাস': 3,\n",
              " 'রাখা।': 3,\n",
              " 'হোক।': 3,\n",
              " 'ই': 3,\n",
              " 'ভরসা': 3,\n",
              " 'যায়': 3,\n",
              " 'পাওয়া': 3,\n",
              " 'কথার': 3,\n",
              " 'পূরণ': 3,\n",
              " 'এখনও': 3,\n",
              " 'উপহার': 3,\n",
              " 'শক্তিশালী': 3,\n",
              " 'পার্থক্য': 3,\n",
              " 'সংসার': 3,\n",
              " 'ধরনের': 3,\n",
              " 'বঙ্গবন্ধুর': 3,\n",
              " 'মধ্যবিত্ত': 3,\n",
              " 'লাগে।': 3,\n",
              " 'বিচার': 3,\n",
              " 'কাহিনী।': 3,\n",
              " 'অনেক।': 3,\n",
              " 'নয়।': 3,\n",
              " 'জানানো': 3,\n",
              " 'নেওয়া': 3,\n",
              " 'পুরাতন': 3,\n",
              " 'আলাদা।': 3,\n",
              " 'করবেন': 3,\n",
              " 'ঘৃণা': 3,\n",
              " 'সম্ভব': 3,\n",
              " 'প্রাপ্য': 3,\n",
              " 'আল্লাহ': 3,\n",
              " 'জানতে': 3,\n",
              " 'যাকে': 3,\n",
              " 'করা।': 3,\n",
              " 'যাওয়া': 3,\n",
              " 'অতিরিক্ত': 3,\n",
              " 'প্রয়োজন।': 3,\n",
              " 'উচিৎ।': 3,\n",
              " 'লজ্জা': 3,\n",
              " 'মানুষেরই': 3,\n",
              " 'কার': 3,\n",
              " 'যথেষ্ট।': 3,\n",
              " 'মুক্তি': 3,\n",
              " 'জানে।': 3,\n",
              " 'আসল।': 3,\n",
              " 'সাহায্য': 3,\n",
              " 'একা': 3,\n",
              " 'জিনিসের': 3,\n",
              " 'বিরুদ্ধে': 3,\n",
              " 'চেনা': 3,\n",
              " 'বেপারে': 3,\n",
              " 'করেই': 3,\n",
              " 'হবার': 3,\n",
              " 'বাস্তবতা': 3,\n",
              " 'হবে,': 3,\n",
              " 'মিথ্যে': 3,\n",
              " 'হাত': 3,\n",
              " 'দুঃখ': 3,\n",
              " 'পারফেক্ট': 3,\n",
              " 'খুবই': 3,\n",
              " 'উপর।': 3,\n",
              " 'মেয়েরা': 3,\n",
              " 'করুন।': 3,\n",
              " 'লাভ': 3,\n",
              " 'কাল': 3,\n",
              " 'মানুষগুলো': 3,\n",
              " 'সারাদিন': 3,\n",
              " 'তুচ্ছ': 3,\n",
              " 'পুরুষদের': 3,\n",
              " 'বোকা': 3,\n",
              " 'পরে': 3,\n",
              " 'মাথায়': 3,\n",
              " 'মত': 3,\n",
              " 'বিয়া': 3,\n",
              " 'এটা': 3,\n",
              " 'ব্ল্যাক': 3,\n",
              " 'বানানো': 3,\n",
              " 'সিনেমা': 3,\n",
              " 'স্ট্যাটাস': 3,\n",
              " 'টেস্ট': 3,\n",
              " 'ধারনা': 3,\n",
              " 'ফল': 3,\n",
              " 'তেমন': 3,\n",
              " 'হয়েছে': 3,\n",
              " 'দুনিয়াতে': 3,\n",
              " 'পারলে': 3,\n",
              " 'পড়াশোনা': 3,\n",
              " 'ক্ষমতা': 3,\n",
              " 'যুদ্ধে': 3,\n",
              " 'বিশ্বের': 3,\n",
              " 'হাতে': 3,\n",
              " 'তে': 3,\n",
              " 'শাস্তি': 3,\n",
              " 'মেধা': 3,\n",
              " 'বাক': 3,\n",
              " 'সবাইকে': 3,\n",
              " 'ক্রিকেট': 3,\n",
              " 'ঢাকা': 3,\n",
              " 'কাজে': 3,\n",
              " 'পেলে': 3,\n",
              " 'ভীষণ': 3,\n",
              " 'বিয়ে': 3,\n",
              " 'সমান': 3,\n",
              " 'উপায়': 3,\n",
              " 'পানি': 3,\n",
              " 'চাই': 3,\n",
              " 'হিসাব': 3,\n",
              " 'লাগার': 3,\n",
              " 'আসার': 3,\n",
              " 'যাওয়া': 3,\n",
              " 'সফলতা': 3,\n",
              " 'তত': 3,\n",
              " 'মাস্ক': 3,\n",
              " 'এসে': 3,\n",
              " 'স্ট্রিং': 3,\n",
              " 'বিজ্ঞান': 3,\n",
              " 'নির্ভর': 3,\n",
              " 'চুপচাপ': 3,\n",
              " 'হল': 3,\n",
              " 'গুলোর': 3,\n",
              " 'পড়ার': 3,\n",
              " 'সৃষ্টি': 3,\n",
              " 'থাকুক': 3,\n",
              " 'কেন্দ্র': 3,\n",
              " 'অবহেলা': 3,\n",
              " 'প্রস্তুতি': 3,\n",
              " 'কিট': 3,\n",
              " 'অর্থের': 3,\n",
              " 'বলে,': 3,\n",
              " 'মূল': 3,\n",
              " 'বোঝাতে': 3,\n",
              " 'হিসাবে': 3,\n",
              " 'ভাইরাসে': 3,\n",
              " 'কাছের': 3,\n",
              " 'থেকেই': 3,\n",
              " 'বন্ধ': 3,\n",
              " 'আলোর': 3,\n",
              " 'একে': 3,\n",
              " 'শক্তি': 3,\n",
              " 'আগলে': 2,\n",
              " 'নাটকের': 2,\n",
              " 'অন্তরে': 2,\n",
              " '৩': 2,\n",
              " 'যুগে': 2,\n",
              " ',আমি': 2,\n",
              " 'প্রজন্ম': 2,\n",
              " 'বুদ্ধিজীবী': 2,\n",
              " 'ভাষা': 2,\n",
              " 'ইংরেজি': 2,\n",
              " 'প্রযুক্তির': 2,\n",
              " 'কমে': 2,\n",
              " 'মার্চ': 2,\n",
              " 'আকাশ': 2,\n",
              " 'দিবে': 2,\n",
              " 'শ্রদ্ধা।': 2,\n",
              " 'বাসনা।': 2,\n",
              " 'রেখেই': 2,\n",
              " 'খবর': 2,\n",
              " ',সে': 2,\n",
              " 'যায়.': 2,\n",
              " 'ভাঙ্গার': 2,\n",
              " 'কুসংস্কার': 2,\n",
              " 'তাৎপর্য': 2,\n",
              " 'থেকেও': 2,\n",
              " 'ভোলা': 2,\n",
              " 'একসাথে': 2,\n",
              " 'চাওয়া।': 2,\n",
              " 'চেয়েও': 2,\n",
              " 'পারা': 2,\n",
              " 'বয়সে': 2,\n",
              " 'ইমোশন': 2,\n",
              " 'বৃদ্ধ': 2,\n",
              " 'ভালোবাসি': 2,\n",
              " 'কোঠাটান': 2,\n",
              " ',এর': 2,\n",
              " 'বোঝা': 2,\n",
              " 'ছাড়াও': 2,\n",
              " 'চাবে': 2,\n",
              " 'শত': 2,\n",
              " 'আকুল': 2,\n",
              " 'সেরা': 2,\n",
              " 'অভিমানের': 2,\n",
              " 'নির্ভরশীল': 2,\n",
              " 'দেখেই': 2,\n",
              " 'সনাক্তকরনের': 2,\n",
              " 'পাবনা': 2,\n",
              " 'অবস্থান': 2,\n",
              " 'ঘরে': 2,\n",
              " 'বোঝে': 2,\n",
              " 'আবেগের': 2,\n",
              " 'বৃষ্টির': 2,\n",
              " 'কুলখানি': 2,\n",
              " 'সূর্য': 2,\n",
              " 'কেন': 2,\n",
              " 'প্রতিষ্ঠিত': 2,\n",
              " 'রাগ': 2,\n",
              " 'শক্তির': 2,\n",
              " 'মধ্য': 2,\n",
              " 'যোগ': 2,\n",
              " 'বহুবচন': 2,\n",
              " 'টেলিস্কোপের': 2,\n",
              " 'পরিবারের': 2,\n",
              " 'মাধ্যমের': 2,\n",
              " 'জেনেও': 2,\n",
              " 'আসতে': 2,\n",
              " 'ছিল': 2,\n",
              " 'গুলোকে': 2,\n",
              " 'কণিকা': 2,\n",
              " 'বুঝতে': 2,\n",
              " 'জেদ': 2,\n",
              " 'প্রোটন': 2,\n",
              " 'এনে': 2,\n",
              " 'ব্যবস্থা': 2,\n",
              " 'কম্পনের': 2,\n",
              " 'হিসেবে': 2,\n",
              " 'পদার্থের': 2,\n",
              " 'দ্বিতীয়': 2,\n",
              " 'মেশিন': 2,\n",
              " 'রাখে।': 2,\n",
              " 'ব্যাবহার': 2,\n",
              " 'মায়ায়': 2,\n",
              " 'অসাধারণ': 2,\n",
              " 'সম্মানী': 2,\n",
              " 'চিনে।': 2,\n",
              " 'মোকাবিলায়': 2,\n",
              " 'তুলে।': 2,\n",
              " 'একদিন।': 2,\n",
              " 'ছেলের': 2,\n",
              " 'দেখতে': 2,\n",
              " 'প্রেমে': 2,\n",
              " 'ভালোবাসলে': 2,\n",
              " 'বিচারিক': 2,\n",
              " 'ম্যাজিস্ট্রেটদের': 2,\n",
              " 'প্রয়োজনে': 2,\n",
              " 'কোরিয়া': 2,\n",
              " 'মৃত্যুর': 2,\n",
              " 'যাওয়া।': 2,\n",
              " 'বাঙালি': 2,\n",
              " 'শরীর': 2,\n",
              " 'জাতির': 2,\n",
              " 'দেহ': 2,\n",
              " 'করো।': 2,\n",
              " 'ছায়াপথ।': 2,\n",
              " 'দিনের': 2,\n",
              " 'কখনোই': 2,\n",
              " 'মূলত': 2,\n",
              " 'ঘুমাতে': 2,\n",
              " 'রাষ্ট্র': 2,\n",
              " 'বেশি।': 2,\n",
              " 'বললে': 2,\n",
              " 'অসুস্থ': 2,\n",
              " 'নির্দেশ': 2,\n",
              " 'ইভেন': 2,\n",
              " 'অর্থ': 2,\n",
              " 'জন্মতোই': 2,\n",
              " 'পাশের': 2,\n",
              " 'কাকে': 2,\n",
              " 'কালের': 2,\n",
              " 'সময়টা': 2,\n",
              " 'রাখি।': 2,\n",
              " 'নারীরাই': 2,\n",
              " 'জাগরণের': 2,\n",
              " 'প্রধান': 2,\n",
              " 'অন্তরায়': 2,\n",
              " 'জন্মদিন': 2,\n",
              " 'বোকামি': 2,\n",
              " '\"প্রাক্তন\"': 2,\n",
              " 'কত': 2,\n",
              " 'এক্সদের': 2,\n",
              " 'ব্যাপার।': 2,\n",
              " 'দিক': 2,\n",
              " 'বোঝার': 2,\n",
              " 'বিশ্ববিদ্যালয়ের': 2,\n",
              " 'বরাদ্দ': 2,\n",
              " 'গেছে।': 2,\n",
              " 'ছাড়াই': 2,\n",
              " 'ফেরানো': 2,\n",
              " 'স্যানিটাইজার': 2,\n",
              " 'ফেসবুকে': 2,\n",
              " 'নারীদের': 2,\n",
              " 'পরিষ্কার': 2,\n",
              " 'পরিপূর্ণভাবে': 2,\n",
              " 'খেলায়': 2,\n",
              " 'সাবান': 2,\n",
              " 'ছুটে': 2,\n",
              " 'হ্যান্ড': 2,\n",
              " 'করিনি': 2,\n",
              " 'অতিমুনাফার': 2,\n",
              " 'মৃত্যু': 2,\n",
              " 'যাবেন।': 2,\n",
              " 'এমনেই': 2,\n",
              " 'ভুলার': 2,\n",
              " 'ভালোবেসেছি।': 2,\n",
              " 'মানিয়ে': 2,\n",
              " 'সংখ্যা': 2,\n",
              " 'ঘৃনা': 2,\n",
              " 'ক্রিকেটের': 2,\n",
              " 'চাঞ্চল্য': 2,\n",
              " 'শিক্ষার্থীরা': 2,\n",
              " 'আব্দুল': 2,\n",
              " 'হামিদ': 2,\n",
              " 'করি': 2,\n",
              " 'ভেজাল': 2,\n",
              " 'পাশাপাশি': 2,\n",
              " 'বয়সের': 2,\n",
              " 'কিছুকে': 2,\n",
              " 'পড়াশুনা': 2,\n",
              " 'মানায়': 2,\n",
              " 'অনেকেই': 2,\n",
              " 'জাতীয়': 2,\n",
              " 'কোচিং': 2,\n",
              " 'উপসর্গ': 2,\n",
              " 'শব্দটা': 2,\n",
              " 'ভেতরে': 2,\n",
              " 'নানা': 2,\n",
              " 'মুখ': 2,\n",
              " 'লিখে': 2,\n",
              " 'কষ্টের।': 2,\n",
              " 'চাইলে': 2,\n",
              " 'অল্প': 2,\n",
              " 'লেখা': 2,\n",
              " 'ইতিহাস': 2,\n",
              " 'জরুরি।': 2,\n",
              " 'মেরে': 2,\n",
              " 'পারছি': 2,\n",
              " 'যাওয়ায়': 2,\n",
              " 'করোনায়': 2,\n",
              " 'জাতি': 2,\n",
              " 'নেয়ার': 2,\n",
              " 'বসবাস': 2,\n",
              " 'নবাবপুর': 2,\n",
              " 'গুজব': 2,\n",
              " 'বিভ্রান্ত': 2,\n",
              " 'ব্যস্ত': 2,\n",
              " 'যত্ন': 2,\n",
              " 'চায়।': 2,\n",
              " 'গভীরতা': 2,\n",
              " 'শোনার': 2,\n",
              " 'ধর্ষিতা': 2,\n",
              " 'অতীত': 2,\n",
              " 'হারিয়ে': 2,\n",
              " 'স্যরি': 2,\n",
              " 'ঘটে': 2,\n",
              " 'করেও': 2,\n",
              " 'দিনে': 2,\n",
              " 'ধর্যের': 2,\n",
              " 'রাখুন।': 2,\n",
              " 'শিখা': 2,\n",
              " 'মনুষ্যত্বহীন': 2,\n",
              " 'হওয়া': 2,\n",
              " 'ভিতরের': 2,\n",
              " 'মানুষই': 2,\n",
              " 'ভাষণ।': 2,\n",
              " 'বিরত': 2,\n",
              " 'মেয়েকে': 2,\n",
              " 'সামান্য': 2,\n",
              " 'মার্চের': 2,\n",
              " 'মায়া': 2,\n",
              " 'গোপন': 2,\n",
              " 'ধরণ': 2,\n",
              " 'অভিযোগ।': 2,\n",
              " 'ধরণের': 2,\n",
              " 'রোমান্টিক': 2,\n",
              " 'অভিনয়': 2,\n",
              " 'মানুষগুলোর': 2,\n",
              " 'বিয়ের': 2,\n",
              " 'বাড়ির': 2,\n",
              " 'কেউই': 2,\n",
              " 'দিয়েছে': 2,\n",
              " 'আপনজন': 2,\n",
              " 'ফ্যামিলির্': 2,\n",
              " 'শিখুন।': 2,\n",
              " 'অপমান': 2,\n",
              " 'রেজাল্ট': 2,\n",
              " 'মানুষটির': 2,\n",
              " 'আজ': 2,\n",
              " 'সাদা': 2,\n",
              " 'কাজই': 2,\n",
              " 'ব্যক্তিত্ব': 2,\n",
              " 'গুছিয়ে': 2,\n",
              " 'দিবেস': 2,\n",
              " 'দিনই।': 2,\n",
              " 'ছড়িয়ে': 2,\n",
              " 'যেকোনো': 2,\n",
              " 'পারি।': 2,\n",
              " 'ভাবে': 2,\n",
              " 'শুভেচ্ছা': 2,\n",
              " 'খুন': 2,\n",
              " 'চাইলেই': 2,\n",
              " 'লাগান।': 2,\n",
              " 'ফ্রেন্ড': 2,\n",
              " 'সময়কে': 2,\n",
              " 'জন্যই': 2,\n",
              " 'জাজমেন্ট': 2,\n",
              " 'প্রিয়': 2,\n",
              " 'রক্ষা': 2,\n",
              " '৭': 2,\n",
              " 'করানো': 2,\n",
              " 'নাই': 2,\n",
              " 'নিদৃষ্ট': 2,\n",
              " 'প্রত্যেক': 2,\n",
              " 'ঐসময়।': 2,\n",
              " 'একুশ': 2,\n",
              " 'রয়েছে।': 2,\n",
              " 'কাউকেও': 2,\n",
              " 'ধ্বংস': 2,\n",
              " 'দিবস': 2,\n",
              " 'মজাই': 2,\n",
              " 'চিঠি': 2,\n",
              " 'সবচেয়ে': 2,\n",
              " 'দিয়া': 2,\n",
              " 'সম্পত্তি': 2,\n",
              " 'অন্য': 2,\n",
              " 'নির্দিষ্ট': 2,\n",
              " 'দিন।': 2,\n",
              " 'সোজা': 2,\n",
              " 'মান': 2,\n",
              " 'নিখুঁত': 2,\n",
              " 'ভাবছি': 2,\n",
              " 'ডাক্তারের': 2,\n",
              " 'প্রভাব': 2,\n",
              " 'অপরিসীম': 2,\n",
              " 'তারাই': 2,\n",
              " 'দিয়েও': 2,\n",
              " 'অপ্রত্যাশিত': 2,\n",
              " 'ধরা': 2,\n",
              " 'ট্রাফিক': 2,\n",
              " 'সিদ্ধান্ত': 2,\n",
              " 'ততো': 2,\n",
              " 'পরীক্ষা': 2,\n",
              " 'বিচারের': 2,\n",
              " 'অপরকে': 2,\n",
              " 'মুখে': 2,\n",
              " 'পারার': 2,\n",
              " 'পারবে': 2,\n",
              " 'স্বামীর': 2,\n",
              " 'পৃথিবী': 2,\n",
              " 'বিয়ে': 2,\n",
              " 'দ্বারা': 2,\n",
              " 'পর্যন্ত': 2,\n",
              " 'পাবেন': 2,\n",
              " 'শুরু': 2,\n",
              " 'আপোষ': 2,\n",
              " 'গুন': 2,\n",
              " 'কি?': 2,\n",
              " 'বৃদ্ধি': 2,\n",
              " 'ভালোবাসাকে': 2,\n",
              " 'সময়ে': 2,\n",
              " 'পায়।': 2,\n",
              " 'বিপদে': 2,\n",
              " 'জীবনটা': 2,\n",
              " 'সৈয়দ': 2,\n",
              " 'বিদেশে': 2,\n",
              " 'ভালবাসার': 2,\n",
              " 'হয়তো': 2,\n",
              " 'নেওয়ার': 2,\n",
              " 'পুরোনো': 2,\n",
              " 'সেবা': 2,\n",
              " 'জটিল': 2,\n",
              " 'পরিশ্রম': 2,\n",
              " 'ধারণ': 2,\n",
              " 'কোনও': 2,\n",
              " 'আনন্দ': 2,\n",
              " 'শুদ্ধতম': 2,\n",
              " 'সাহিত্য': 2,\n",
              " 'নামে': 2,\n",
              " 'বাঁচতে': 2,\n",
              " 'আল্লাহর': 2,\n",
              " 'একাকিত্ব': 2,\n",
              " 'মার': 2,\n",
              " 'সর্বনাশ': 2,\n",
              " 'হউক': 2,\n",
              " 'হক': 2,\n",
              " 'চোরের': 2,\n",
              " 'হাজার': 2,\n",
              " 'নিস্পাপ': 2,\n",
              " 'লেখার': 2,\n",
              " 'চাহিদা': 2,\n",
              " 'ব্যবসা': 2,\n",
              " 'যাচ্ছি।': 2,\n",
              " 'এখানেই': 2,\n",
              " 'নিজেকেই': 2,\n",
              " 'সমস্যাটা': 2,\n",
              " 'ভেবে': 2,\n",
              " 'করেছি': 2,\n",
              " 'পাল্টা': 2,\n",
              " 'বিদেশ': 2,\n",
              " 'সারা': 2,\n",
              " 'দিকে': 2,\n",
              " 'সয়ে': 2,\n",
              " 'মাকে': 2,\n",
              " 'তাহলে': 2,\n",
              " 'হিসেব': 2,\n",
              " 'বের': 2,\n",
              " 'উঠতে': 2,\n",
              " 'পাল্টে': 2,\n",
              " 'ধুকে': 2,\n",
              " 'দুর্বোধ্য': 2,\n",
              " 'তখনই': 2,\n",
              " 'অদ্ভুত': 2,\n",
              " 'বিশ্ববিদ্যালয়': 2,\n",
              " 'সম্পদ': 2,\n",
              " 'জ্ঞান': 2,\n",
              " 'নিজেরই': 2,\n",
              " 'প্রতিনিয়ত': 2,\n",
              " 'কেও': 2,\n",
              " 'করাটা': 2,\n",
              " 'আকর্ষণ': 2,\n",
              " 'উপকার': 2,\n",
              " 'স্বীকার': 2,\n",
              " 'গল্প।': 2,\n",
              " 'তারা': 2,\n",
              " 'খানের': 2,\n",
              " 'বছর': 2,\n",
              " 'মানুুষ': 2,\n",
              " '.': 2,\n",
              " 'অর্ধেক': 2,\n",
              " 'ভাগ্য': 2,\n",
              " 'আজম': 2,\n",
              " 'করবে।': 2,\n",
              " 'পুরুষ': 2,\n",
              " 'বিড়ম্বনা': 2,\n",
              " 'চুপ': 2,\n",
              " 'মেলাতে': 2,\n",
              " 'পেশা': 2,\n",
              " 'দাবি': 2,\n",
              " 'সমস্যার': 2,\n",
              " 'শহরে': 2,\n",
              " 'একেকটা': 2,\n",
              " 'চলার': 2,\n",
              " 'রুখে': 2,\n",
              " 'ব্যাস্ত': 2,\n",
              " 'সহজেই': 2,\n",
              " 'প্রদান': 1,\n",
              " 'রানে': 1,\n",
              " 'অন্যতম।': 1,\n",
              " '\"জিরো\"': 1,\n",
              " 'মুশফিক': 1,\n",
              " 'তিনটি': 1,\n",
              " 'অনুশোচনা': 1,\n",
              " 'গবেষণা': 1,\n",
              " 'সর্বোচ্চ': 1,\n",
              " 'করেছেন।': 1,\n",
              " 'স্বাস্থ্যে': 1,\n",
              " 'আউট': 1,\n",
              " 'পশুর': 1,\n",
              " 'হলো।': 1,\n",
              " 'রিটেক': 1,\n",
              " 'দল।': 1,\n",
              " 'উপভোগে': 1,\n",
              " 'অভিযোগ': 1,\n",
              " 'ক্যাসিনো': 1,\n",
              " 'শেয়ার': 1,\n",
              " 'বাজার': 1,\n",
              " 'দুইটাই': 1,\n",
              " 'জুয়া।': 1,\n",
              " '১০': 1,\n",
              " 'কোটি': 1,\n",
              " 'গুনতে': 1,\n",
              " 'অবশেষে': 1,\n",
              " 'পেলো': 1,\n",
              " 'লেগ': 1,\n",
              " 'স্পিনার।': 1,\n",
              " 'জ্বালিয়ে': 1,\n",
              " 'মারার': 1,\n",
              " 'মজা': 1,\n",
              " 'কোথাও': 1,\n",
              " 'কমের': 1,\n",
              " 'আকুতি।': 1,\n",
              " 'বাসের': 1,\n",
              " 'লোকাল': 1,\n",
              " 'পেরিয়ে': 1,\n",
              " 'খুশি।': 1,\n",
              " 'কলিজা': 1,\n",
              " 'দাদীকে': 1,\n",
              " 'ভোগায়।': 1,\n",
              " 'অমরত্ব': 1,\n",
              " 'নির্বাচন': 1,\n",
              " 'খালি': 1,\n",
              " 'নাচবো': 1,\n",
              " 'খাবো।': 1,\n",
              " 'পানামা': 1,\n",
              " 'সবসময়': 1,\n",
              " 'বহিরাগত।': 1,\n",
              " 'ক্ষমতাবান।': 1,\n",
              " 'গুলো।': 1,\n",
              " 'জীবন্ত': 1,\n",
              " 'করোনো': 1,\n",
              " 'গড়ে': 1,\n",
              " 'তোলার': 1,\n",
              " 'সফলতা।': 1,\n",
              " 'এরা': 1,\n",
              " 'ছাত্র': 1,\n",
              " 'কিংবদন্তী।': 1,\n",
              " 'শূন্যের': 1,\n",
              " 'সহায়তার': 1,\n",
              " 'এত্ত': 1,\n",
              " 'বোর্ড': 1,\n",
              " 'হোয়াইট': 1,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = pd.DataFrame(c1.items(), columns=['Words', 'Count'])\n",
        "d1 = d1.head(20)\n",
        "d1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "jU5Y2x-yu5Ff",
        "outputId": "139edd82-8c12-4d48-933c-bec8d69703ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Words  Count\n",
              "0      না   1532\n",
              "1     করে   1516\n",
              "2    আমার   1143\n",
              "3      আর   1107\n",
              "4     আমি   1105\n",
              "5      এই    922\n",
              "6     তার    879\n",
              "7     না।    770\n",
              "8    একটা    765\n",
              "9      যে    753\n",
              "10   থেকে    723\n",
              "11    হয়ে    645\n",
              "12     সে    639\n",
              "13    ...    628\n",
              "14   সাথে    624\n",
              "15   জন্য    597\n",
              "16     কি    565\n",
              "17  তোমার    551\n",
              "18   করতে    534\n",
              "19    কথা    504"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d564fea6-b0b0-4eec-bb3a-7936b0f3f1aa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Words</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>না</td>\n",
              "      <td>1532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>করে</td>\n",
              "      <td>1516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>আমার</td>\n",
              "      <td>1143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>আর</td>\n",
              "      <td>1107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>আমি</td>\n",
              "      <td>1105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>এই</td>\n",
              "      <td>922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>তার</td>\n",
              "      <td>879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>না।</td>\n",
              "      <td>770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>একটা</td>\n",
              "      <td>765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>যে</td>\n",
              "      <td>753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>থেকে</td>\n",
              "      <td>723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>হয়ে</td>\n",
              "      <td>645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>সে</td>\n",
              "      <td>639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>...</td>\n",
              "      <td>628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>সাথে</td>\n",
              "      <td>624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>জন্য</td>\n",
              "      <td>597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>কি</td>\n",
              "      <td>565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>তোমার</td>\n",
              "      <td>551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>করতে</td>\n",
              "      <td>534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>কথা</td>\n",
              "      <td>504</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d564fea6-b0b0-4eec-bb3a-7936b0f3f1aa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d564fea6-b0b0-4eec-bb3a-7936b0f3f1aa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d564fea6-b0b0-4eec-bb3a-7936b0f3f1aa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d2 = pd.DataFrame(c2.items(), columns=['Words', 'Count'])\n",
        "d2 = d2.head(20)\n",
        "d2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "mQG517rQuINx",
        "outputId": "8fc705f6-b464-4563-a7a3-13b91b7ff219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Words  Count\n",
              "0         না    154\n",
              "1      মানুষ     70\n",
              "2       জন্য     63\n",
              "3        করে     62\n",
              "4   ভালোবাসা     62\n",
              "5        না।     56\n",
              "6       অনেক     54\n",
              "7        করা     48\n",
              "8    মানুষের     45\n",
              "9       করতে     45\n",
              "10        আর     45\n",
              "11       হবে     44\n",
              "12        সব     43\n",
              "13      ভালো     42\n",
              "14        হয়     39\n",
              "15      কিছু     39\n",
              "16        যে     38\n",
              "17      সাথে     34\n",
              "18        এই     33\n",
              "19      কষ্ট     32"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4cf94a0-65b9-40a5-a8c7-8375c237ac6c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Words</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>না</td>\n",
              "      <td>154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>মানুষ</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>জন্য</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>করে</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ভালোবাসা</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>না।</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>অনেক</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>করা</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>মানুষের</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>করতে</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>আর</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>হবে</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>সব</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ভালো</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>হয়</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>কিছু</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>যে</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>সাথে</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>এই</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>কষ্ট</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4cf94a0-65b9-40a5-a8c7-8375c237ac6c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4cf94a0-65b9-40a5-a8c7-8375c237ac6c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4cf94a0-65b9-40a5-a8c7-8375c237ac6c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import numpy as np\n",
        "prop = fm.FontProperties(fname='/content/kalpurush.ttf')\n",
        "plt.barh(d1.Words,d1.Count)\n",
        "plt.yticks(d1.Words,fontproperties=prop)\n",
        "plt.title('Most Frequent Word in Bengali Text')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "6sXflk5xuqhL",
        "outputId": "874b3ecb-01b0-46d6-bf77-6a2ceb1092f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(d2.Words,d2.Count)\n",
        "plt.yticks(d2.Words,fontproperties=prop)\n",
        "plt.title('Most Frequent Word in Bengali Text Summary')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "ad2xMkZuvJtL",
        "outputId": "55bdc207-964a-4071-8bd7-ebaff117c755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70qGA1wNMB8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9e8a034-9eb5-433b-e329-cd765f5b7b08"
      },
      "source": [
        "summary = summary.apply(lambda x: '<go> ' + str(x) + ' <stop>')\n",
        "summary.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    <go> বাংলাদেশে কোচিং বানিজ্য বন্ধ এখন সময়ের দা...\n",
              "1    <go> বাংলা ভাষার প্রযুক্তি নিয়ে আমাদের আরো অনে...\n",
              "2    <go> যদি শিশুরা বই পড়ার অভ্যাস করে তাহলে সারা ...\n",
              "3    <go> বাংলাদেশে সব স্তরে নারীর ক্ষমতায়নের জন্য ...\n",
              "4                <go> ভালো কথা বল, নয়ত চুপ থাকো <stop>\n",
              "Name: Summary, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HvwpXkyME9l"
      },
      "source": [
        "# since < and > from default tokens cannot be removed\n",
        "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "oov_token = '<unk>'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVV8LssUMUrY"
      },
      "source": [
        "document_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=oov_token)\n",
        "summary_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Sj_k9u8Mb1R"
      },
      "source": [
        "document_tokenizer.fit_on_texts(document)\n",
        "summary_tokenizer.fit_on_texts(summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9adUMBPMmlM"
      },
      "source": [
        "inputs = document_tokenizer.texts_to_sequences(document)\n",
        "targets = summary_tokenizer.texts_to_sequences(summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AOW-f0HMqhc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7892812-ece5-45eb-8240-07169305f302"
      },
      "source": [
        "summary_tokenizer.texts_to_sequences([\"বাংলাদেশে কোচিং বানিজ্য বন্ধ এখন সময়ের দাবি\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[153, 547, 942, 379, 61, 134, 548]]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVk8QZJfMw9m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e37049ba-5ed7-4fda-e754-e349788c31bf"
      },
      "source": [
        "summary_tokenizer.sequences_to_texts([[153, 547, 942, 379, 61, 134, 548]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['বাংলাদেশে কোচিং বানিজ্য বন্ধ এখন সময়ের দাবি']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHL2dMQmM9mo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34704a50-18f0-4606-b35f-07d96185cd54"
      },
      "source": [
        "encoder_vocab_size = len(document_tokenizer.word_index) + 1\n",
        "decoder_vocab_size = len(summary_tokenizer.word_index) + 1\n",
        "\n",
        "encoder_vocab_size, decoder_vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23995, 2814)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfaZi7eVNBXi"
      },
      "source": [
        "document_lengths = pd.Series([len(x) for x in document])\n",
        "summary_lengths = pd.Series([len(x) for x in summary])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7dSrFUNNDgC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e58a143-9d40-4f0f-ecb0-0ee27af6788c"
      },
      "source": [
        "document_lengths.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    1026.000000\n",
              "mean      814.735867\n",
              "std       893.202858\n",
              "min        42.000000\n",
              "25%       257.500000\n",
              "50%       524.000000\n",
              "75%      1029.250000\n",
              "max      8262.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOpgw0ZGNFzV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0895eed4-8861-43f9-adca-6a1899b2cfd7"
      },
      "source": [
        "summary_lengths.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    1026.000000\n",
              "mean       54.670565\n",
              "std        23.110480\n",
              "min        15.000000\n",
              "25%        41.000000\n",
              "50%        51.000000\n",
              "75%        63.000000\n",
              "max       462.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8juPbc01NIr9"
      },
      "source": [
        "encoder_maxlen = 250\n",
        "decoder_maxlen = 75"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItReQzKWNMFg"
      },
      "source": [
        "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
        "targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=decoder_maxlen, padding='post', truncating='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG0C_tklNPwy"
      },
      "source": [
        "inputs = tf.cast(inputs, dtype=tf.int32)\n",
        "targets = tf.cast(targets, dtype=tf.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89rZHD26NSgF"
      },
      "source": [
        "BUFFER_SIZE = 2000\n",
        "BATCH_SIZE = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoWgTzpKNV94"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6b0UxwHNZSf"
      },
      "source": [
        "def get_angles(position, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return position * angle_rates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQVUljkTNbuN"
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(\n",
        "        np.arange(position)[:, np.newaxis],\n",
        "        np.arange(d_model)[np.newaxis, :],\n",
        "        d_model\n",
        "    )\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW2wInusNeLI"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xq1sTtjNgyi"
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9-KePeRNjN4"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)\n",
        "    return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA7drIKONlcK"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "        output = self.dense(concat_attention)\n",
        "\n",
        "        return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3mHNuHLNoiU"
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(dff, activation='relu'),\n",
        "        tf.keras.layers.Dense(d_model)\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lrg_xJ9N4tx"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        attn_output, _ = self.mha(x, x, x, mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "        return out2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKaLacvSN7w7"
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)\n",
        "\n",
        "        ffn_output = self.ffn(out2)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQrnlVMWOBuF"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGC5vXJeOHMh"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "\n",
        "        return x, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFTmtmN5OJVM"
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
        "\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
        "\n",
        "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output)\n",
        "\n",
        "        return final_output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrcb29sJOMR1"
      },
      "source": [
        "# hyper-params\n",
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "EPOCHS = 70"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GruvDrXiOPmT"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mITWV3C8OR3S"
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXhjR4nzOUVe"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rGOkAf3OWzs"
      },
      "source": [
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37hPdmtAOY_o"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uERVOad5OdOV"
      },
      "source": [
        "transformer = Transformer(\n",
        "    num_layers,\n",
        "    d_model,\n",
        "    num_heads,\n",
        "    dff,\n",
        "    encoder_vocab_size,\n",
        "    decoder_vocab_size,\n",
        "    pe_input=encoder_vocab_size,\n",
        "    pe_target=decoder_vocab_size,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzpgMP4yOgRE"
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7BPPE7QOipH"
      },
      "source": [
        "checkpoint_path = \"checkpoints\"\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print ('Latest checkpoint restored!!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZitSb2COlBR"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(\n",
        "            inp, tar_inp,\n",
        "            True,\n",
        "            enc_padding_mask,\n",
        "            combined_mask,\n",
        "            dec_padding_mask\n",
        "        )\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3Hz5FbaOnhr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa09961e-f79c-4b6a-c673-e27fcf47e66e"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    train_loss.reset_states()\n",
        "\n",
        "    for (batch, (inp, tar)) in enumerate(dataset):\n",
        "        train_step(inp, tar)\n",
        "\n",
        "        # 55k samples\n",
        "        # we display 3 batch results -- 0th, middle and last one (approx)\n",
        "        # 55k / 64 ~ 858; 858 / 2 = 429\n",
        "        if batch % 8 == 0:\n",
        "            print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, train_loss.result()))\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
        "\n",
        "    print ('Epoch {} Loss {:.4f}'.format(epoch + 1, train_loss.result()))\n",
        "\n",
        "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 7.9428\n",
            "Epoch 1 Batch 8 Loss 7.9584\n",
            "Epoch 1 Batch 16 Loss 7.9470\n",
            "Epoch 1 Batch 24 Loss 7.9375\n",
            "Epoch 1 Batch 32 Loss 7.9219\n",
            "Epoch 1 Batch 40 Loss 7.9028\n",
            "Epoch 1 Batch 48 Loss 7.8871\n",
            "Epoch 1 Batch 56 Loss 7.8692\n",
            "Epoch 1 Batch 64 Loss 7.8532\n",
            "Epoch 1 Batch 72 Loss 7.8378\n",
            "Epoch 1 Batch 80 Loss 7.8200\n",
            "Epoch 1 Batch 88 Loss 7.8021\n",
            "Epoch 1 Batch 96 Loss 7.7860\n",
            "Epoch 1 Batch 104 Loss 7.7694\n",
            "Epoch 1 Batch 112 Loss 7.7541\n",
            "Epoch 1 Batch 120 Loss 7.7419\n",
            "Epoch 1 Batch 128 Loss 7.7261\n",
            "Epoch 1 Loss 7.7261\n",
            "Time taken for 1 epoch: 20.604976415634155 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 7.5124\n",
            "Epoch 2 Batch 8 Loss 7.4641\n",
            "Epoch 2 Batch 16 Loss 7.4441\n",
            "Epoch 2 Batch 24 Loss 7.4296\n",
            "Epoch 2 Batch 32 Loss 7.4279\n",
            "Epoch 2 Batch 40 Loss 7.4223\n",
            "Epoch 2 Batch 48 Loss 7.4265\n",
            "Epoch 2 Batch 56 Loss 7.4156\n",
            "Epoch 2 Batch 64 Loss 7.4060\n",
            "Epoch 2 Batch 72 Loss 7.3924\n",
            "Epoch 2 Batch 80 Loss 7.3833\n",
            "Epoch 2 Batch 88 Loss 7.3754\n",
            "Epoch 2 Batch 96 Loss 7.3687\n",
            "Epoch 2 Batch 104 Loss 7.3591\n",
            "Epoch 2 Batch 112 Loss 7.3490\n",
            "Epoch 2 Batch 120 Loss 7.3436\n",
            "Epoch 2 Batch 128 Loss 7.3366\n",
            "Epoch 2 Loss 7.3366\n",
            "Time taken for 1 epoch: 5.104659557342529 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 7.1025\n",
            "Epoch 3 Batch 8 Loss 7.1142\n",
            "Epoch 3 Batch 16 Loss 7.1124\n",
            "Epoch 3 Batch 24 Loss 7.1069\n",
            "Epoch 3 Batch 32 Loss 7.0848\n",
            "Epoch 3 Batch 40 Loss 7.0666\n",
            "Epoch 3 Batch 48 Loss 7.0583\n",
            "Epoch 3 Batch 56 Loss 7.0469\n",
            "Epoch 3 Batch 64 Loss 7.0316\n",
            "Epoch 3 Batch 72 Loss 7.0224\n",
            "Epoch 3 Batch 80 Loss 7.0120\n",
            "Epoch 3 Batch 88 Loss 6.9983\n",
            "Epoch 3 Batch 96 Loss 6.9888\n",
            "Epoch 3 Batch 104 Loss 6.9899\n",
            "Epoch 3 Batch 112 Loss 6.9901\n",
            "Epoch 3 Batch 120 Loss 6.9870\n",
            "Epoch 3 Batch 128 Loss 6.9793\n",
            "Epoch 3 Loss 6.9793\n",
            "Time taken for 1 epoch: 3.418018341064453 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 6.7962\n",
            "Epoch 4 Batch 8 Loss 6.6337\n",
            "Epoch 4 Batch 16 Loss 6.7213\n",
            "Epoch 4 Batch 24 Loss 6.7246\n",
            "Epoch 4 Batch 32 Loss 6.7239\n",
            "Epoch 4 Batch 40 Loss 6.7271\n",
            "Epoch 4 Batch 48 Loss 6.7283\n",
            "Epoch 4 Batch 56 Loss 6.7167\n",
            "Epoch 4 Batch 64 Loss 6.7092\n",
            "Epoch 4 Batch 72 Loss 6.7147\n",
            "Epoch 4 Batch 80 Loss 6.7090\n",
            "Epoch 4 Batch 88 Loss 6.7106\n",
            "Epoch 4 Batch 96 Loss 6.7142\n",
            "Epoch 4 Batch 104 Loss 6.7224\n",
            "Epoch 4 Batch 112 Loss 6.7313\n",
            "Epoch 4 Batch 120 Loss 6.7241\n",
            "Epoch 4 Batch 128 Loss 6.7351\n",
            "Epoch 4 Loss 6.7351\n",
            "Time taken for 1 epoch: 3.4114906787872314 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 6.6035\n",
            "Epoch 5 Batch 8 Loss 6.4993\n",
            "Epoch 5 Batch 16 Loss 6.5198\n",
            "Epoch 5 Batch 24 Loss 6.5544\n",
            "Epoch 5 Batch 32 Loss 6.6077\n",
            "Epoch 5 Batch 40 Loss 6.6056\n",
            "Epoch 5 Batch 48 Loss 6.5973\n",
            "Epoch 5 Batch 56 Loss 6.6084\n",
            "Epoch 5 Batch 64 Loss 6.6036\n",
            "Epoch 5 Batch 72 Loss 6.6199\n",
            "Epoch 5 Batch 80 Loss 6.6192\n",
            "Epoch 5 Batch 88 Loss 6.6031\n",
            "Epoch 5 Batch 96 Loss 6.5976\n",
            "Epoch 5 Batch 104 Loss 6.6048\n",
            "Epoch 5 Batch 112 Loss 6.6085\n",
            "Epoch 5 Batch 120 Loss 6.6048\n",
            "Epoch 5 Batch 128 Loss 6.6021\n",
            "Saving checkpoint for epoch 5 at checkpoints/ckpt-1\n",
            "Epoch 5 Loss 6.6021\n",
            "Time taken for 1 epoch: 5.486211061477661 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 6.6866\n",
            "Epoch 6 Batch 8 Loss 6.5959\n",
            "Epoch 6 Batch 16 Loss 6.4786\n",
            "Epoch 6 Batch 24 Loss 6.4975\n",
            "Epoch 6 Batch 32 Loss 6.4923\n",
            "Epoch 6 Batch 40 Loss 6.4772\n",
            "Epoch 6 Batch 48 Loss 6.4781\n",
            "Epoch 6 Batch 56 Loss 6.4732\n",
            "Epoch 6 Batch 64 Loss 6.4680\n",
            "Epoch 6 Batch 72 Loss 6.4860\n",
            "Epoch 6 Batch 80 Loss 6.4945\n",
            "Epoch 6 Batch 88 Loss 6.4811\n",
            "Epoch 6 Batch 96 Loss 6.4873\n",
            "Epoch 6 Batch 104 Loss 6.4974\n",
            "Epoch 6 Batch 112 Loss 6.4979\n",
            "Epoch 6 Batch 120 Loss 6.4972\n",
            "Epoch 6 Batch 128 Loss 6.4985\n",
            "Epoch 6 Loss 6.4985\n",
            "Time taken for 1 epoch: 3.509417772293091 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 5.9268\n",
            "Epoch 7 Batch 8 Loss 6.2347\n",
            "Epoch 7 Batch 16 Loss 6.3478\n",
            "Epoch 7 Batch 24 Loss 6.3240\n",
            "Epoch 7 Batch 32 Loss 6.2870\n",
            "Epoch 7 Batch 40 Loss 6.2751\n",
            "Epoch 7 Batch 48 Loss 6.3010\n",
            "Epoch 7 Batch 56 Loss 6.2934\n",
            "Epoch 7 Batch 64 Loss 6.2940\n",
            "Epoch 7 Batch 72 Loss 6.3133\n",
            "Epoch 7 Batch 80 Loss 6.3349\n",
            "Epoch 7 Batch 88 Loss 6.3421\n",
            "Epoch 7 Batch 96 Loss 6.3575\n",
            "Epoch 7 Batch 104 Loss 6.3557\n",
            "Epoch 7 Batch 112 Loss 6.3596\n",
            "Epoch 7 Batch 120 Loss 6.3620\n",
            "Epoch 7 Batch 128 Loss 6.3668\n",
            "Epoch 7 Loss 6.3668\n",
            "Time taken for 1 epoch: 5.103708744049072 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 6.0231\n",
            "Epoch 8 Batch 8 Loss 6.1998\n",
            "Epoch 8 Batch 16 Loss 6.1736\n",
            "Epoch 8 Batch 24 Loss 6.1510\n",
            "Epoch 8 Batch 32 Loss 6.1655\n",
            "Epoch 8 Batch 40 Loss 6.1848\n",
            "Epoch 8 Batch 48 Loss 6.1874\n",
            "Epoch 8 Batch 56 Loss 6.1866\n",
            "Epoch 8 Batch 64 Loss 6.1803\n",
            "Epoch 8 Batch 72 Loss 6.1825\n",
            "Epoch 8 Batch 80 Loss 6.1882\n",
            "Epoch 8 Batch 88 Loss 6.1937\n",
            "Epoch 8 Batch 96 Loss 6.1930\n",
            "Epoch 8 Batch 104 Loss 6.1939\n",
            "Epoch 8 Batch 112 Loss 6.1891\n",
            "Epoch 8 Batch 120 Loss 6.1844\n",
            "Epoch 8 Batch 128 Loss 6.1790\n",
            "Epoch 8 Loss 6.1790\n",
            "Time taken for 1 epoch: 3.4365274906158447 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 6.1826\n",
            "Epoch 9 Batch 8 Loss 6.0314\n",
            "Epoch 9 Batch 16 Loss 5.9825\n",
            "Epoch 9 Batch 24 Loss 5.9793\n",
            "Epoch 9 Batch 32 Loss 6.0000\n",
            "Epoch 9 Batch 40 Loss 5.9895\n",
            "Epoch 9 Batch 48 Loss 5.9892\n",
            "Epoch 9 Batch 56 Loss 5.9865\n",
            "Epoch 9 Batch 64 Loss 5.9807\n",
            "Epoch 9 Batch 72 Loss 5.9821\n",
            "Epoch 9 Batch 80 Loss 5.9821\n",
            "Epoch 9 Batch 88 Loss 5.9813\n",
            "Epoch 9 Batch 96 Loss 5.9758\n",
            "Epoch 9 Batch 104 Loss 5.9732\n",
            "Epoch 9 Batch 112 Loss 5.9750\n",
            "Epoch 9 Batch 120 Loss 5.9760\n",
            "Epoch 9 Batch 128 Loss 5.9770\n",
            "Epoch 9 Loss 5.9770\n",
            "Time taken for 1 epoch: 3.4711291790008545 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 5.9300\n",
            "Epoch 10 Batch 8 Loss 5.7463\n",
            "Epoch 10 Batch 16 Loss 5.7645\n",
            "Epoch 10 Batch 24 Loss 5.7478\n",
            "Epoch 10 Batch 32 Loss 5.7430\n",
            "Epoch 10 Batch 40 Loss 5.7560\n",
            "Epoch 10 Batch 48 Loss 5.7741\n",
            "Epoch 10 Batch 56 Loss 5.7792\n",
            "Epoch 10 Batch 64 Loss 5.8006\n",
            "Epoch 10 Batch 72 Loss 5.7936\n",
            "Epoch 10 Batch 80 Loss 5.7891\n",
            "Epoch 10 Batch 88 Loss 5.7738\n",
            "Epoch 10 Batch 96 Loss 5.7849\n",
            "Epoch 10 Batch 104 Loss 5.7929\n",
            "Epoch 10 Batch 112 Loss 5.8003\n",
            "Epoch 10 Batch 120 Loss 5.7988\n",
            "Epoch 10 Batch 128 Loss 5.8088\n",
            "Saving checkpoint for epoch 10 at checkpoints/ckpt-2\n",
            "Epoch 10 Loss 5.8088\n",
            "Time taken for 1 epoch: 4.900659561157227 secs\n",
            "\n",
            "Epoch 11 Batch 0 Loss 6.0972\n",
            "Epoch 11 Batch 8 Loss 5.8679\n",
            "Epoch 11 Batch 16 Loss 5.7878\n",
            "Epoch 11 Batch 24 Loss 5.7423\n",
            "Epoch 11 Batch 32 Loss 5.7104\n",
            "Epoch 11 Batch 40 Loss 5.7124\n",
            "Epoch 11 Batch 48 Loss 5.7066\n",
            "Epoch 11 Batch 56 Loss 5.7203\n",
            "Epoch 11 Batch 64 Loss 5.6993\n",
            "Epoch 11 Batch 72 Loss 5.6619\n",
            "Epoch 11 Batch 80 Loss 5.6469\n",
            "Epoch 11 Batch 88 Loss 5.6391\n",
            "Epoch 11 Batch 96 Loss 5.6166\n",
            "Epoch 11 Batch 104 Loss 5.6192\n",
            "Epoch 11 Batch 112 Loss 5.6269\n",
            "Epoch 11 Batch 120 Loss 5.6299\n",
            "Epoch 11 Batch 128 Loss 5.6305\n",
            "Epoch 11 Loss 5.6305\n",
            "Time taken for 1 epoch: 6.153802156448364 secs\n",
            "\n",
            "Epoch 12 Batch 0 Loss 5.2997\n",
            "Epoch 12 Batch 8 Loss 5.4354\n",
            "Epoch 12 Batch 16 Loss 5.3636\n",
            "Epoch 12 Batch 24 Loss 5.3211\n",
            "Epoch 12 Batch 32 Loss 5.3315\n",
            "Epoch 12 Batch 40 Loss 5.3920\n",
            "Epoch 12 Batch 48 Loss 5.3994\n",
            "Epoch 12 Batch 56 Loss 5.3763\n",
            "Epoch 12 Batch 64 Loss 5.3793\n",
            "Epoch 12 Batch 72 Loss 5.3892\n",
            "Epoch 12 Batch 80 Loss 5.4040\n",
            "Epoch 12 Batch 88 Loss 5.4176\n",
            "Epoch 12 Batch 96 Loss 5.4248\n",
            "Epoch 12 Batch 104 Loss 5.4265\n",
            "Epoch 12 Batch 112 Loss 5.4264\n",
            "Epoch 12 Batch 120 Loss 5.4394\n",
            "Epoch 12 Batch 128 Loss 5.4362\n",
            "Epoch 12 Loss 5.4362\n",
            "Time taken for 1 epoch: 6.529330253601074 secs\n",
            "\n",
            "Epoch 13 Batch 0 Loss 5.0345\n",
            "Epoch 13 Batch 8 Loss 5.2648\n",
            "Epoch 13 Batch 16 Loss 5.1643\n",
            "Epoch 13 Batch 24 Loss 5.1980\n",
            "Epoch 13 Batch 32 Loss 5.1565\n",
            "Epoch 13 Batch 40 Loss 5.1924\n",
            "Epoch 13 Batch 48 Loss 5.1923\n",
            "Epoch 13 Batch 56 Loss 5.2121\n",
            "Epoch 13 Batch 64 Loss 5.2118\n",
            "Epoch 13 Batch 72 Loss 5.2093\n",
            "Epoch 13 Batch 80 Loss 5.2190\n",
            "Epoch 13 Batch 88 Loss 5.2283\n",
            "Epoch 13 Batch 96 Loss 5.2366\n",
            "Epoch 13 Batch 104 Loss 5.2414\n",
            "Epoch 13 Batch 112 Loss 5.2425\n",
            "Epoch 13 Batch 120 Loss 5.2550\n",
            "Epoch 13 Batch 128 Loss 5.2457\n",
            "Epoch 13 Loss 5.2457\n",
            "Time taken for 1 epoch: 3.4085333347320557 secs\n",
            "\n",
            "Epoch 14 Batch 0 Loss 4.7059\n",
            "Epoch 14 Batch 8 Loss 4.7291\n",
            "Epoch 14 Batch 16 Loss 4.8338\n",
            "Epoch 14 Batch 24 Loss 4.9098\n",
            "Epoch 14 Batch 32 Loss 4.9011\n",
            "Epoch 14 Batch 40 Loss 4.9268\n",
            "Epoch 14 Batch 48 Loss 4.8953\n",
            "Epoch 14 Batch 56 Loss 4.9155\n",
            "Epoch 14 Batch 64 Loss 4.9446\n",
            "Epoch 14 Batch 72 Loss 4.9447\n",
            "Epoch 14 Batch 80 Loss 4.9667\n",
            "Epoch 14 Batch 88 Loss 4.9649\n",
            "Epoch 14 Batch 96 Loss 4.9715\n",
            "Epoch 14 Batch 104 Loss 4.9896\n",
            "Epoch 14 Batch 112 Loss 5.0040\n",
            "Epoch 14 Batch 120 Loss 5.0193\n",
            "Epoch 14 Batch 128 Loss 5.0252\n",
            "Epoch 14 Loss 5.0252\n",
            "Time taken for 1 epoch: 3.4438748359680176 secs\n",
            "\n",
            "Epoch 15 Batch 0 Loss 4.3646\n",
            "Epoch 15 Batch 8 Loss 4.6014\n",
            "Epoch 15 Batch 16 Loss 4.6822\n",
            "Epoch 15 Batch 24 Loss 4.7257\n",
            "Epoch 15 Batch 32 Loss 4.7877\n",
            "Epoch 15 Batch 40 Loss 4.7874\n",
            "Epoch 15 Batch 48 Loss 4.7462\n",
            "Epoch 15 Batch 56 Loss 4.7413\n",
            "Epoch 15 Batch 64 Loss 4.7525\n",
            "Epoch 15 Batch 72 Loss 4.7398\n",
            "Epoch 15 Batch 80 Loss 4.7628\n",
            "Epoch 15 Batch 88 Loss 4.7642\n",
            "Epoch 15 Batch 96 Loss 4.7689\n",
            "Epoch 15 Batch 104 Loss 4.7711\n",
            "Epoch 15 Batch 112 Loss 4.7882\n",
            "Epoch 15 Batch 120 Loss 4.7923\n",
            "Epoch 15 Batch 128 Loss 4.7963\n",
            "Saving checkpoint for epoch 15 at checkpoints/ckpt-3\n",
            "Epoch 15 Loss 4.7963\n",
            "Time taken for 1 epoch: 3.7713305950164795 secs\n",
            "\n",
            "Epoch 16 Batch 0 Loss 4.2960\n",
            "Epoch 16 Batch 8 Loss 4.5519\n",
            "Epoch 16 Batch 16 Loss 4.5150\n",
            "Epoch 16 Batch 24 Loss 4.4592\n",
            "Epoch 16 Batch 32 Loss 4.4833\n",
            "Epoch 16 Batch 40 Loss 4.4793\n",
            "Epoch 16 Batch 48 Loss 4.4754\n",
            "Epoch 16 Batch 56 Loss 4.4829\n",
            "Epoch 16 Batch 64 Loss 4.4964\n",
            "Epoch 16 Batch 72 Loss 4.5234\n",
            "Epoch 16 Batch 80 Loss 4.5328\n",
            "Epoch 16 Batch 88 Loss 4.5246\n",
            "Epoch 16 Batch 96 Loss 4.5194\n",
            "Epoch 16 Batch 104 Loss 4.5219\n",
            "Epoch 16 Batch 112 Loss 4.5305\n",
            "Epoch 16 Batch 120 Loss 4.5424\n",
            "Epoch 16 Batch 128 Loss 4.5453\n",
            "Epoch 16 Loss 4.5453\n",
            "Time taken for 1 epoch: 3.437483072280884 secs\n",
            "\n",
            "Epoch 17 Batch 0 Loss 4.1751\n",
            "Epoch 17 Batch 8 Loss 4.3484\n",
            "Epoch 17 Batch 16 Loss 4.3233\n",
            "Epoch 17 Batch 24 Loss 4.3291\n",
            "Epoch 17 Batch 32 Loss 4.3119\n",
            "Epoch 17 Batch 40 Loss 4.2962\n",
            "Epoch 17 Batch 48 Loss 4.3031\n",
            "Epoch 17 Batch 56 Loss 4.2957\n",
            "Epoch 17 Batch 64 Loss 4.2853\n",
            "Epoch 17 Batch 72 Loss 4.3011\n",
            "Epoch 17 Batch 80 Loss 4.3108\n",
            "Epoch 17 Batch 88 Loss 4.3103\n",
            "Epoch 17 Batch 96 Loss 4.2983\n",
            "Epoch 17 Batch 104 Loss 4.3012\n",
            "Epoch 17 Batch 112 Loss 4.3040\n",
            "Epoch 17 Batch 120 Loss 4.2970\n",
            "Epoch 17 Batch 128 Loss 4.3066\n",
            "Epoch 17 Loss 4.3066\n",
            "Time taken for 1 epoch: 3.463996648788452 secs\n",
            "\n",
            "Epoch 18 Batch 0 Loss 4.0037\n",
            "Epoch 18 Batch 8 Loss 4.1199\n",
            "Epoch 18 Batch 16 Loss 4.0518\n",
            "Epoch 18 Batch 24 Loss 4.0249\n",
            "Epoch 18 Batch 32 Loss 3.9550\n",
            "Epoch 18 Batch 40 Loss 3.9901\n",
            "Epoch 18 Batch 48 Loss 4.0045\n",
            "Epoch 18 Batch 56 Loss 4.0203\n",
            "Epoch 18 Batch 64 Loss 4.0205\n",
            "Epoch 18 Batch 72 Loss 4.0282\n",
            "Epoch 18 Batch 80 Loss 4.0099\n",
            "Epoch 18 Batch 88 Loss 4.0186\n",
            "Epoch 18 Batch 96 Loss 4.0198\n",
            "Epoch 18 Batch 104 Loss 4.0185\n",
            "Epoch 18 Batch 112 Loss 4.0287\n",
            "Epoch 18 Batch 120 Loss 4.0465\n",
            "Epoch 18 Batch 128 Loss 4.0493\n",
            "Epoch 18 Loss 4.0493\n",
            "Time taken for 1 epoch: 3.459947109222412 secs\n",
            "\n",
            "Epoch 19 Batch 0 Loss 3.5222\n",
            "Epoch 19 Batch 8 Loss 3.4314\n",
            "Epoch 19 Batch 16 Loss 3.6484\n",
            "Epoch 19 Batch 24 Loss 3.6862\n",
            "Epoch 19 Batch 32 Loss 3.7100\n",
            "Epoch 19 Batch 40 Loss 3.6763\n",
            "Epoch 19 Batch 48 Loss 3.6742\n",
            "Epoch 19 Batch 56 Loss 3.6947\n",
            "Epoch 19 Batch 64 Loss 3.6982\n",
            "Epoch 19 Batch 72 Loss 3.7054\n",
            "Epoch 19 Batch 80 Loss 3.7138\n",
            "Epoch 19 Batch 88 Loss 3.6999\n",
            "Epoch 19 Batch 96 Loss 3.7113\n",
            "Epoch 19 Batch 104 Loss 3.7271\n",
            "Epoch 19 Batch 112 Loss 3.7312\n",
            "Epoch 19 Batch 120 Loss 3.7278\n",
            "Epoch 19 Batch 128 Loss 3.7451\n",
            "Epoch 19 Loss 3.7451\n",
            "Time taken for 1 epoch: 3.440042018890381 secs\n",
            "\n",
            "Epoch 20 Batch 0 Loss 3.3293\n",
            "Epoch 20 Batch 8 Loss 3.6243\n",
            "Epoch 20 Batch 16 Loss 3.4832\n",
            "Epoch 20 Batch 24 Loss 3.4877\n",
            "Epoch 20 Batch 32 Loss 3.4908\n",
            "Epoch 20 Batch 40 Loss 3.4795\n",
            "Epoch 20 Batch 48 Loss 3.4295\n",
            "Epoch 20 Batch 56 Loss 3.4303\n",
            "Epoch 20 Batch 64 Loss 3.4395\n",
            "Epoch 20 Batch 72 Loss 3.4369\n",
            "Epoch 20 Batch 80 Loss 3.4559\n",
            "Epoch 20 Batch 88 Loss 3.4552\n",
            "Epoch 20 Batch 96 Loss 3.4484\n",
            "Epoch 20 Batch 104 Loss 3.4432\n",
            "Epoch 20 Batch 112 Loss 3.4710\n",
            "Epoch 20 Batch 120 Loss 3.4747\n",
            "Epoch 20 Batch 128 Loss 3.4842\n",
            "Saving checkpoint for epoch 20 at checkpoints/ckpt-4\n",
            "Epoch 20 Loss 3.4842\n",
            "Time taken for 1 epoch: 3.809957504272461 secs\n",
            "\n",
            "Epoch 21 Batch 0 Loss 3.1718\n",
            "Epoch 21 Batch 8 Loss 3.1730\n",
            "Epoch 21 Batch 16 Loss 3.1443\n",
            "Epoch 21 Batch 24 Loss 3.0655\n",
            "Epoch 21 Batch 32 Loss 3.0818\n",
            "Epoch 21 Batch 40 Loss 3.0885\n",
            "Epoch 21 Batch 48 Loss 3.0910\n",
            "Epoch 21 Batch 56 Loss 3.1012\n",
            "Epoch 21 Batch 64 Loss 3.1046\n",
            "Epoch 21 Batch 72 Loss 3.1201\n",
            "Epoch 21 Batch 80 Loss 3.1131\n",
            "Epoch 21 Batch 88 Loss 3.1135\n",
            "Epoch 21 Batch 96 Loss 3.1079\n",
            "Epoch 21 Batch 104 Loss 3.1186\n",
            "Epoch 21 Batch 112 Loss 3.1363\n",
            "Epoch 21 Batch 120 Loss 3.1502\n",
            "Epoch 21 Batch 128 Loss 3.1667\n",
            "Epoch 21 Loss 3.1667\n",
            "Time taken for 1 epoch: 3.4652209281921387 secs\n",
            "\n",
            "Epoch 22 Batch 0 Loss 2.8815\n",
            "Epoch 22 Batch 8 Loss 2.8721\n",
            "Epoch 22 Batch 16 Loss 2.8424\n",
            "Epoch 22 Batch 24 Loss 2.8699\n",
            "Epoch 22 Batch 32 Loss 2.8593\n",
            "Epoch 22 Batch 40 Loss 2.8383\n",
            "Epoch 22 Batch 48 Loss 2.7963\n",
            "Epoch 22 Batch 56 Loss 2.7997\n",
            "Epoch 22 Batch 64 Loss 2.8001\n",
            "Epoch 22 Batch 72 Loss 2.8104\n",
            "Epoch 22 Batch 80 Loss 2.8239\n",
            "Epoch 22 Batch 88 Loss 2.8145\n",
            "Epoch 22 Batch 96 Loss 2.8127\n",
            "Epoch 22 Batch 104 Loss 2.8382\n",
            "Epoch 22 Batch 112 Loss 2.8401\n",
            "Epoch 22 Batch 120 Loss 2.8482\n",
            "Epoch 22 Batch 128 Loss 2.8553\n",
            "Epoch 22 Loss 2.8553\n",
            "Time taken for 1 epoch: 3.4714159965515137 secs\n",
            "\n",
            "Epoch 23 Batch 0 Loss 2.2729\n",
            "Epoch 23 Batch 8 Loss 2.4030\n",
            "Epoch 23 Batch 16 Loss 2.4590\n",
            "Epoch 23 Batch 24 Loss 2.4275\n",
            "Epoch 23 Batch 32 Loss 2.4462\n",
            "Epoch 23 Batch 40 Loss 2.4696\n",
            "Epoch 23 Batch 48 Loss 2.4700\n",
            "Epoch 23 Batch 56 Loss 2.5024\n",
            "Epoch 23 Batch 64 Loss 2.5052\n",
            "Epoch 23 Batch 72 Loss 2.5106\n",
            "Epoch 23 Batch 80 Loss 2.5109\n",
            "Epoch 23 Batch 88 Loss 2.5336\n",
            "Epoch 23 Batch 96 Loss 2.5305\n",
            "Epoch 23 Batch 104 Loss 2.5567\n",
            "Epoch 23 Batch 112 Loss 2.5645\n",
            "Epoch 23 Batch 120 Loss 2.5692\n",
            "Epoch 23 Batch 128 Loss 2.5826\n",
            "Epoch 23 Loss 2.5826\n",
            "Time taken for 1 epoch: 3.482267141342163 secs\n",
            "\n",
            "Epoch 24 Batch 0 Loss 2.2130\n",
            "Epoch 24 Batch 8 Loss 2.1728\n",
            "Epoch 24 Batch 16 Loss 2.1049\n",
            "Epoch 24 Batch 24 Loss 2.1222\n",
            "Epoch 24 Batch 32 Loss 2.1405\n",
            "Epoch 24 Batch 40 Loss 2.0974\n",
            "Epoch 24 Batch 48 Loss 2.1353\n",
            "Epoch 24 Batch 56 Loss 2.1459\n",
            "Epoch 24 Batch 64 Loss 2.1795\n",
            "Epoch 24 Batch 72 Loss 2.1818\n",
            "Epoch 24 Batch 80 Loss 2.1877\n",
            "Epoch 24 Batch 88 Loss 2.2041\n",
            "Epoch 24 Batch 96 Loss 2.2243\n",
            "Epoch 24 Batch 104 Loss 2.2516\n",
            "Epoch 24 Batch 112 Loss 2.2800\n",
            "Epoch 24 Batch 120 Loss 2.2917\n",
            "Epoch 24 Batch 128 Loss 2.2958\n",
            "Epoch 24 Loss 2.2958\n",
            "Time taken for 1 epoch: 3.4643616676330566 secs\n",
            "\n",
            "Epoch 25 Batch 0 Loss 1.7577\n",
            "Epoch 25 Batch 8 Loss 2.0668\n",
            "Epoch 25 Batch 16 Loss 2.0170\n",
            "Epoch 25 Batch 24 Loss 1.9792\n",
            "Epoch 25 Batch 32 Loss 2.0108\n",
            "Epoch 25 Batch 40 Loss 2.0132\n",
            "Epoch 25 Batch 48 Loss 1.9827\n",
            "Epoch 25 Batch 56 Loss 1.9759\n",
            "Epoch 25 Batch 64 Loss 1.9669\n",
            "Epoch 25 Batch 72 Loss 1.9703\n",
            "Epoch 25 Batch 80 Loss 1.9723\n",
            "Epoch 25 Batch 88 Loss 1.9785\n",
            "Epoch 25 Batch 96 Loss 1.9776\n",
            "Epoch 25 Batch 104 Loss 1.9926\n",
            "Epoch 25 Batch 112 Loss 2.0030\n",
            "Epoch 25 Batch 120 Loss 2.0193\n",
            "Epoch 25 Batch 128 Loss 2.0326\n",
            "Saving checkpoint for epoch 25 at checkpoints/ckpt-5\n",
            "Epoch 25 Loss 2.0326\n",
            "Time taken for 1 epoch: 5.425015687942505 secs\n",
            "\n",
            "Epoch 26 Batch 0 Loss 1.6446\n",
            "Epoch 26 Batch 8 Loss 1.5919\n",
            "Epoch 26 Batch 16 Loss 1.5620\n",
            "Epoch 26 Batch 24 Loss 1.6048\n",
            "Epoch 26 Batch 32 Loss 1.6058\n",
            "Epoch 26 Batch 40 Loss 1.6087\n",
            "Epoch 26 Batch 48 Loss 1.6039\n",
            "Epoch 26 Batch 56 Loss 1.6278\n",
            "Epoch 26 Batch 64 Loss 1.6465\n",
            "Epoch 26 Batch 72 Loss 1.6652\n",
            "Epoch 26 Batch 80 Loss 1.6857\n",
            "Epoch 26 Batch 88 Loss 1.6828\n",
            "Epoch 26 Batch 96 Loss 1.7084\n",
            "Epoch 26 Batch 104 Loss 1.7230\n",
            "Epoch 26 Batch 112 Loss 1.7306\n",
            "Epoch 26 Batch 120 Loss 1.7654\n",
            "Epoch 26 Batch 128 Loss 1.7795\n",
            "Epoch 26 Loss 1.7795\n",
            "Time taken for 1 epoch: 3.562497854232788 secs\n",
            "\n",
            "Epoch 27 Batch 0 Loss 1.5567\n",
            "Epoch 27 Batch 8 Loss 1.4259\n",
            "Epoch 27 Batch 16 Loss 1.4254\n",
            "Epoch 27 Batch 24 Loss 1.3995\n",
            "Epoch 27 Batch 32 Loss 1.4293\n",
            "Epoch 27 Batch 40 Loss 1.4425\n",
            "Epoch 27 Batch 48 Loss 1.4417\n",
            "Epoch 27 Batch 56 Loss 1.4334\n",
            "Epoch 27 Batch 64 Loss 1.4344\n",
            "Epoch 27 Batch 72 Loss 1.4395\n",
            "Epoch 27 Batch 80 Loss 1.4538\n",
            "Epoch 27 Batch 88 Loss 1.4650\n",
            "Epoch 27 Batch 96 Loss 1.4832\n",
            "Epoch 27 Batch 104 Loss 1.4858\n",
            "Epoch 27 Batch 112 Loss 1.4964\n",
            "Epoch 27 Batch 120 Loss 1.5199\n",
            "Epoch 27 Batch 128 Loss 1.5470\n",
            "Epoch 27 Loss 1.5470\n",
            "Time taken for 1 epoch: 3.4804036617279053 secs\n",
            "\n",
            "Epoch 28 Batch 0 Loss 1.1467\n",
            "Epoch 28 Batch 8 Loss 1.1981\n",
            "Epoch 28 Batch 16 Loss 1.1929\n",
            "Epoch 28 Batch 24 Loss 1.2050\n",
            "Epoch 28 Batch 32 Loss 1.1996\n",
            "Epoch 28 Batch 40 Loss 1.2253\n",
            "Epoch 28 Batch 48 Loss 1.2085\n",
            "Epoch 28 Batch 56 Loss 1.2157\n",
            "Epoch 28 Batch 64 Loss 1.2310\n",
            "Epoch 28 Batch 72 Loss 1.2439\n",
            "Epoch 28 Batch 80 Loss 1.2453\n",
            "Epoch 28 Batch 88 Loss 1.2577\n",
            "Epoch 28 Batch 96 Loss 1.2752\n",
            "Epoch 28 Batch 104 Loss 1.2885\n",
            "Epoch 28 Batch 112 Loss 1.3004\n",
            "Epoch 28 Batch 120 Loss 1.3162\n",
            "Epoch 28 Batch 128 Loss 1.3259\n",
            "Epoch 28 Loss 1.3259\n",
            "Time taken for 1 epoch: 4.032739877700806 secs\n",
            "\n",
            "Epoch 29 Batch 0 Loss 0.9634\n",
            "Epoch 29 Batch 8 Loss 1.0313\n",
            "Epoch 29 Batch 16 Loss 1.0673\n",
            "Epoch 29 Batch 24 Loss 1.0353\n",
            "Epoch 29 Batch 32 Loss 1.0309\n",
            "Epoch 29 Batch 40 Loss 1.0385\n",
            "Epoch 29 Batch 48 Loss 1.0608\n",
            "Epoch 29 Batch 56 Loss 1.0546\n",
            "Epoch 29 Batch 64 Loss 1.0681\n",
            "Epoch 29 Batch 72 Loss 1.0832\n",
            "Epoch 29 Batch 80 Loss 1.0908\n",
            "Epoch 29 Batch 88 Loss 1.1171\n",
            "Epoch 29 Batch 96 Loss 1.1224\n",
            "Epoch 29 Batch 104 Loss 1.1411\n",
            "Epoch 29 Batch 112 Loss 1.1579\n",
            "Epoch 29 Batch 120 Loss 1.1783\n",
            "Epoch 29 Batch 128 Loss 1.1935\n",
            "Epoch 29 Loss 1.1935\n",
            "Time taken for 1 epoch: 3.8120601177215576 secs\n",
            "\n",
            "Epoch 30 Batch 0 Loss 0.8247\n",
            "Epoch 30 Batch 8 Loss 0.8013\n",
            "Epoch 30 Batch 16 Loss 0.8869\n",
            "Epoch 30 Batch 24 Loss 0.9092\n",
            "Epoch 30 Batch 32 Loss 0.9096\n",
            "Epoch 30 Batch 40 Loss 0.9144\n",
            "Epoch 30 Batch 48 Loss 0.9308\n",
            "Epoch 30 Batch 56 Loss 0.9273\n",
            "Epoch 30 Batch 64 Loss 0.9418\n",
            "Epoch 30 Batch 72 Loss 0.9558\n",
            "Epoch 30 Batch 80 Loss 0.9581\n",
            "Epoch 30 Batch 88 Loss 0.9696\n",
            "Epoch 30 Batch 96 Loss 0.9743\n",
            "Epoch 30 Batch 104 Loss 0.9873\n",
            "Epoch 30 Batch 112 Loss 1.0065\n",
            "Epoch 30 Batch 120 Loss 1.0182\n",
            "Epoch 30 Batch 128 Loss 1.0285\n",
            "Saving checkpoint for epoch 30 at checkpoints/ckpt-6\n",
            "Epoch 30 Loss 1.0285\n",
            "Time taken for 1 epoch: 3.829806327819824 secs\n",
            "\n",
            "Epoch 31 Batch 0 Loss 0.8448\n",
            "Epoch 31 Batch 8 Loss 0.8846\n",
            "Epoch 31 Batch 16 Loss 0.9079\n",
            "Epoch 31 Batch 24 Loss 0.8675\n",
            "Epoch 31 Batch 32 Loss 0.8445\n",
            "Epoch 31 Batch 40 Loss 0.8468\n",
            "Epoch 31 Batch 48 Loss 0.8601\n",
            "Epoch 31 Batch 56 Loss 0.8699\n",
            "Epoch 31 Batch 64 Loss 0.8786\n",
            "Epoch 31 Batch 72 Loss 0.8818\n",
            "Epoch 31 Batch 80 Loss 0.8933\n",
            "Epoch 31 Batch 88 Loss 0.9049\n",
            "Epoch 31 Batch 96 Loss 0.9146\n",
            "Epoch 31 Batch 104 Loss 0.9193\n",
            "Epoch 31 Batch 112 Loss 0.9286\n",
            "Epoch 31 Batch 120 Loss 0.9434\n",
            "Epoch 31 Batch 128 Loss 0.9499\n",
            "Epoch 31 Loss 0.9499\n",
            "Time taken for 1 epoch: 3.4898433685302734 secs\n",
            "\n",
            "Epoch 32 Batch 0 Loss 0.6545\n",
            "Epoch 32 Batch 8 Loss 0.7498\n",
            "Epoch 32 Batch 16 Loss 0.7074\n",
            "Epoch 32 Batch 24 Loss 0.7225\n",
            "Epoch 32 Batch 32 Loss 0.7236\n",
            "Epoch 32 Batch 40 Loss 0.7036\n",
            "Epoch 32 Batch 48 Loss 0.7150\n",
            "Epoch 32 Batch 56 Loss 0.7336\n",
            "Epoch 32 Batch 64 Loss 0.7393\n",
            "Epoch 32 Batch 72 Loss 0.7418\n",
            "Epoch 32 Batch 80 Loss 0.7605\n",
            "Epoch 32 Batch 88 Loss 0.7734\n",
            "Epoch 32 Batch 96 Loss 0.7892\n",
            "Epoch 32 Batch 104 Loss 0.8065\n",
            "Epoch 32 Batch 112 Loss 0.8202\n",
            "Epoch 32 Batch 120 Loss 0.8363\n",
            "Epoch 32 Batch 128 Loss 0.8433\n",
            "Epoch 32 Loss 0.8433\n",
            "Time taken for 1 epoch: 3.504828691482544 secs\n",
            "\n",
            "Epoch 33 Batch 0 Loss 0.5958\n",
            "Epoch 33 Batch 8 Loss 0.6231\n",
            "Epoch 33 Batch 16 Loss 0.6009\n",
            "Epoch 33 Batch 24 Loss 0.6289\n",
            "Epoch 33 Batch 32 Loss 0.6289\n",
            "Epoch 33 Batch 40 Loss 0.6293\n",
            "Epoch 33 Batch 48 Loss 0.6638\n",
            "Epoch 33 Batch 56 Loss 0.6756\n",
            "Epoch 33 Batch 64 Loss 0.6819\n",
            "Epoch 33 Batch 72 Loss 0.6957\n",
            "Epoch 33 Batch 80 Loss 0.7043\n",
            "Epoch 33 Batch 88 Loss 0.7122\n",
            "Epoch 33 Batch 96 Loss 0.7159\n",
            "Epoch 33 Batch 104 Loss 0.7206\n",
            "Epoch 33 Batch 112 Loss 0.7280\n",
            "Epoch 33 Batch 120 Loss 0.7394\n",
            "Epoch 33 Batch 128 Loss 0.7444\n",
            "Epoch 33 Loss 0.7444\n",
            "Time taken for 1 epoch: 3.498248815536499 secs\n",
            "\n",
            "Epoch 34 Batch 0 Loss 0.4714\n",
            "Epoch 34 Batch 8 Loss 0.5989\n",
            "Epoch 34 Batch 16 Loss 0.5835\n",
            "Epoch 34 Batch 24 Loss 0.5760\n",
            "Epoch 34 Batch 32 Loss 0.5806\n",
            "Epoch 34 Batch 40 Loss 0.5757\n",
            "Epoch 34 Batch 48 Loss 0.5728\n",
            "Epoch 34 Batch 56 Loss 0.5836\n",
            "Epoch 34 Batch 64 Loss 0.5918\n",
            "Epoch 34 Batch 72 Loss 0.5947\n",
            "Epoch 34 Batch 80 Loss 0.5921\n",
            "Epoch 34 Batch 88 Loss 0.6071\n",
            "Epoch 34 Batch 96 Loss 0.6203\n",
            "Epoch 34 Batch 104 Loss 0.6268\n",
            "Epoch 34 Batch 112 Loss 0.6293\n",
            "Epoch 34 Batch 120 Loss 0.6352\n",
            "Epoch 34 Batch 128 Loss 0.6474\n",
            "Epoch 34 Loss 0.6474\n",
            "Time taken for 1 epoch: 3.490755319595337 secs\n",
            "\n",
            "Epoch 35 Batch 0 Loss 0.3619\n",
            "Epoch 35 Batch 8 Loss 0.4718\n",
            "Epoch 35 Batch 16 Loss 0.5126\n",
            "Epoch 35 Batch 24 Loss 0.5170\n",
            "Epoch 35 Batch 32 Loss 0.5294\n",
            "Epoch 35 Batch 40 Loss 0.5561\n",
            "Epoch 35 Batch 48 Loss 0.5526\n",
            "Epoch 35 Batch 56 Loss 0.5509\n",
            "Epoch 35 Batch 64 Loss 0.5556\n",
            "Epoch 35 Batch 72 Loss 0.5448\n",
            "Epoch 35 Batch 80 Loss 0.5436\n",
            "Epoch 35 Batch 88 Loss 0.5477\n",
            "Epoch 35 Batch 96 Loss 0.5482\n",
            "Epoch 35 Batch 104 Loss 0.5511\n",
            "Epoch 35 Batch 112 Loss 0.5569\n",
            "Epoch 35 Batch 120 Loss 0.5666\n",
            "Epoch 35 Batch 128 Loss 0.5701\n",
            "Saving checkpoint for epoch 35 at checkpoints/ckpt-7\n",
            "Epoch 35 Loss 0.5701\n",
            "Time taken for 1 epoch: 3.8286476135253906 secs\n",
            "\n",
            "Epoch 36 Batch 0 Loss 0.6709\n",
            "Epoch 36 Batch 8 Loss 0.5354\n",
            "Epoch 36 Batch 16 Loss 0.5066\n",
            "Epoch 36 Batch 24 Loss 0.4819\n",
            "Epoch 36 Batch 32 Loss 0.4683\n",
            "Epoch 36 Batch 40 Loss 0.4507\n",
            "Epoch 36 Batch 48 Loss 0.4545\n",
            "Epoch 36 Batch 56 Loss 0.4548\n",
            "Epoch 36 Batch 64 Loss 0.4530\n",
            "Epoch 36 Batch 72 Loss 0.4567\n",
            "Epoch 36 Batch 80 Loss 0.4678\n",
            "Epoch 36 Batch 88 Loss 0.4751\n",
            "Epoch 36 Batch 96 Loss 0.4929\n",
            "Epoch 36 Batch 104 Loss 0.4975\n",
            "Epoch 36 Batch 112 Loss 0.5150\n",
            "Epoch 36 Batch 120 Loss 0.5192\n",
            "Epoch 36 Batch 128 Loss 0.5281\n",
            "Epoch 36 Loss 0.5281\n",
            "Time taken for 1 epoch: 3.823396921157837 secs\n",
            "\n",
            "Epoch 37 Batch 0 Loss 0.4054\n",
            "Epoch 37 Batch 8 Loss 0.4567\n",
            "Epoch 37 Batch 16 Loss 0.4319\n",
            "Epoch 37 Batch 24 Loss 0.4202\n",
            "Epoch 37 Batch 32 Loss 0.4149\n",
            "Epoch 37 Batch 40 Loss 0.4124\n",
            "Epoch 37 Batch 48 Loss 0.4128\n",
            "Epoch 37 Batch 56 Loss 0.4028\n",
            "Epoch 37 Batch 64 Loss 0.4064\n",
            "Epoch 37 Batch 72 Loss 0.4087\n",
            "Epoch 37 Batch 80 Loss 0.4147\n",
            "Epoch 37 Batch 88 Loss 0.4161\n",
            "Epoch 37 Batch 96 Loss 0.4217\n",
            "Epoch 37 Batch 104 Loss 0.4272\n",
            "Epoch 37 Batch 112 Loss 0.4360\n",
            "Epoch 37 Batch 120 Loss 0.4358\n",
            "Epoch 37 Batch 128 Loss 0.4435\n",
            "Epoch 37 Loss 0.4435\n",
            "Time taken for 1 epoch: 4.159154891967773 secs\n",
            "\n",
            "Epoch 38 Batch 0 Loss 0.3395\n",
            "Epoch 38 Batch 8 Loss 0.3638\n",
            "Epoch 38 Batch 16 Loss 0.3645\n",
            "Epoch 38 Batch 24 Loss 0.3748\n",
            "Epoch 38 Batch 32 Loss 0.3870\n",
            "Epoch 38 Batch 40 Loss 0.3884\n",
            "Epoch 38 Batch 48 Loss 0.3872\n",
            "Epoch 38 Batch 56 Loss 0.3914\n",
            "Epoch 38 Batch 64 Loss 0.4015\n",
            "Epoch 38 Batch 72 Loss 0.4009\n",
            "Epoch 38 Batch 80 Loss 0.3999\n",
            "Epoch 38 Batch 88 Loss 0.4021\n",
            "Epoch 38 Batch 96 Loss 0.4083\n",
            "Epoch 38 Batch 104 Loss 0.4103\n",
            "Epoch 38 Batch 112 Loss 0.4134\n",
            "Epoch 38 Batch 120 Loss 0.4164\n",
            "Epoch 38 Batch 128 Loss 0.4197\n",
            "Epoch 38 Loss 0.4197\n",
            "Time taken for 1 epoch: 3.5103819370269775 secs\n",
            "\n",
            "Epoch 39 Batch 0 Loss 0.3903\n",
            "Epoch 39 Batch 8 Loss 0.3010\n",
            "Epoch 39 Batch 16 Loss 0.3304\n",
            "Epoch 39 Batch 24 Loss 0.3082\n",
            "Epoch 39 Batch 32 Loss 0.3175\n",
            "Epoch 39 Batch 40 Loss 0.3206\n",
            "Epoch 39 Batch 48 Loss 0.3304\n",
            "Epoch 39 Batch 56 Loss 0.3332\n",
            "Epoch 39 Batch 64 Loss 0.3415\n",
            "Epoch 39 Batch 72 Loss 0.3396\n",
            "Epoch 39 Batch 80 Loss 0.3493\n",
            "Epoch 39 Batch 88 Loss 0.3506\n",
            "Epoch 39 Batch 96 Loss 0.3583\n",
            "Epoch 39 Batch 104 Loss 0.3569\n",
            "Epoch 39 Batch 112 Loss 0.3618\n",
            "Epoch 39 Batch 120 Loss 0.3673\n",
            "Epoch 39 Batch 128 Loss 0.3712\n",
            "Epoch 39 Loss 0.3712\n",
            "Time taken for 1 epoch: 3.5095479488372803 secs\n",
            "\n",
            "Epoch 40 Batch 0 Loss 0.2115\n",
            "Epoch 40 Batch 8 Loss 0.2410\n",
            "Epoch 40 Batch 16 Loss 0.2702\n",
            "Epoch 40 Batch 24 Loss 0.2573\n",
            "Epoch 40 Batch 32 Loss 0.2646\n",
            "Epoch 40 Batch 40 Loss 0.2639\n",
            "Epoch 40 Batch 48 Loss 0.2646\n",
            "Epoch 40 Batch 56 Loss 0.2702\n",
            "Epoch 40 Batch 64 Loss 0.2827\n",
            "Epoch 40 Batch 72 Loss 0.2933\n",
            "Epoch 40 Batch 80 Loss 0.3016\n",
            "Epoch 40 Batch 88 Loss 0.3098\n",
            "Epoch 40 Batch 96 Loss 0.3215\n",
            "Epoch 40 Batch 104 Loss 0.3283\n",
            "Epoch 40 Batch 112 Loss 0.3358\n",
            "Epoch 40 Batch 120 Loss 0.3425\n",
            "Epoch 40 Batch 128 Loss 0.3498\n",
            "Saving checkpoint for epoch 40 at checkpoints/ckpt-8\n",
            "Epoch 40 Loss 0.3498\n",
            "Time taken for 1 epoch: 3.8770699501037598 secs\n",
            "\n",
            "Epoch 41 Batch 0 Loss 0.5103\n",
            "Epoch 41 Batch 8 Loss 0.3218\n",
            "Epoch 41 Batch 16 Loss 0.2748\n",
            "Epoch 41 Batch 24 Loss 0.2798\n",
            "Epoch 41 Batch 32 Loss 0.2840\n",
            "Epoch 41 Batch 40 Loss 0.2816\n",
            "Epoch 41 Batch 48 Loss 0.2743\n",
            "Epoch 41 Batch 56 Loss 0.2757\n",
            "Epoch 41 Batch 64 Loss 0.2793\n",
            "Epoch 41 Batch 72 Loss 0.2872\n",
            "Epoch 41 Batch 80 Loss 0.2996\n",
            "Epoch 41 Batch 88 Loss 0.3032\n",
            "Epoch 41 Batch 96 Loss 0.3075\n",
            "Epoch 41 Batch 104 Loss 0.3136\n",
            "Epoch 41 Batch 112 Loss 0.3214\n",
            "Epoch 41 Batch 120 Loss 0.3269\n",
            "Epoch 41 Batch 128 Loss 0.3307\n",
            "Epoch 41 Loss 0.3307\n",
            "Time taken for 1 epoch: 3.5171267986297607 secs\n",
            "\n",
            "Epoch 42 Batch 0 Loss 0.1648\n",
            "Epoch 42 Batch 8 Loss 0.2394\n",
            "Epoch 42 Batch 16 Loss 0.2293\n",
            "Epoch 42 Batch 24 Loss 0.2291\n",
            "Epoch 42 Batch 32 Loss 0.2341\n",
            "Epoch 42 Batch 40 Loss 0.2417\n",
            "Epoch 42 Batch 48 Loss 0.2481\n",
            "Epoch 42 Batch 56 Loss 0.2534\n",
            "Epoch 42 Batch 64 Loss 0.2538\n",
            "Epoch 42 Batch 72 Loss 0.2506\n",
            "Epoch 42 Batch 80 Loss 0.2535\n",
            "Epoch 42 Batch 88 Loss 0.2608\n",
            "Epoch 42 Batch 96 Loss 0.2684\n",
            "Epoch 42 Batch 104 Loss 0.2778\n",
            "Epoch 42 Batch 112 Loss 0.2793\n",
            "Epoch 42 Batch 120 Loss 0.2816\n",
            "Epoch 42 Batch 128 Loss 0.2900\n",
            "Epoch 42 Loss 0.2900\n",
            "Time taken for 1 epoch: 3.537930965423584 secs\n",
            "\n",
            "Epoch 43 Batch 0 Loss 0.4403\n",
            "Epoch 43 Batch 8 Loss 0.2445\n",
            "Epoch 43 Batch 16 Loss 0.2435\n",
            "Epoch 43 Batch 24 Loss 0.2397\n",
            "Epoch 43 Batch 32 Loss 0.2347\n",
            "Epoch 43 Batch 40 Loss 0.2382\n",
            "Epoch 43 Batch 48 Loss 0.2342\n",
            "Epoch 43 Batch 56 Loss 0.2372\n",
            "Epoch 43 Batch 64 Loss 0.2338\n",
            "Epoch 43 Batch 72 Loss 0.2401\n",
            "Epoch 43 Batch 80 Loss 0.2473\n",
            "Epoch 43 Batch 88 Loss 0.2529\n",
            "Epoch 43 Batch 96 Loss 0.2560\n",
            "Epoch 43 Batch 104 Loss 0.2632\n",
            "Epoch 43 Batch 112 Loss 0.2655\n",
            "Epoch 43 Batch 120 Loss 0.2691\n",
            "Epoch 43 Batch 128 Loss 0.2701\n",
            "Epoch 43 Loss 0.2701\n",
            "Time taken for 1 epoch: 3.5184381008148193 secs\n",
            "\n",
            "Epoch 44 Batch 0 Loss 0.0978\n",
            "Epoch 44 Batch 8 Loss 0.1905\n",
            "Epoch 44 Batch 16 Loss 0.2133\n",
            "Epoch 44 Batch 24 Loss 0.2296\n",
            "Epoch 44 Batch 32 Loss 0.2269\n",
            "Epoch 44 Batch 40 Loss 0.2201\n",
            "Epoch 44 Batch 48 Loss 0.2184\n",
            "Epoch 44 Batch 56 Loss 0.2150\n",
            "Epoch 44 Batch 64 Loss 0.2233\n",
            "Epoch 44 Batch 72 Loss 0.2284\n",
            "Epoch 44 Batch 80 Loss 0.2311\n",
            "Epoch 44 Batch 88 Loss 0.2316\n",
            "Epoch 44 Batch 96 Loss 0.2321\n",
            "Epoch 44 Batch 104 Loss 0.2324\n",
            "Epoch 44 Batch 112 Loss 0.2372\n",
            "Epoch 44 Batch 120 Loss 0.2395\n",
            "Epoch 44 Batch 128 Loss 0.2413\n",
            "Epoch 44 Loss 0.2413\n",
            "Time taken for 1 epoch: 3.5712289810180664 secs\n",
            "\n",
            "Epoch 45 Batch 0 Loss 0.0817\n",
            "Epoch 45 Batch 8 Loss 0.1443\n",
            "Epoch 45 Batch 16 Loss 0.1786\n",
            "Epoch 45 Batch 24 Loss 0.1842\n",
            "Epoch 45 Batch 32 Loss 0.1898\n",
            "Epoch 45 Batch 40 Loss 0.1879\n",
            "Epoch 45 Batch 48 Loss 0.1987\n",
            "Epoch 45 Batch 56 Loss 0.1998\n",
            "Epoch 45 Batch 64 Loss 0.2088\n",
            "Epoch 45 Batch 72 Loss 0.2121\n",
            "Epoch 45 Batch 80 Loss 0.2143\n",
            "Epoch 45 Batch 88 Loss 0.2167\n",
            "Epoch 45 Batch 96 Loss 0.2199\n",
            "Epoch 45 Batch 104 Loss 0.2287\n",
            "Epoch 45 Batch 112 Loss 0.2309\n",
            "Epoch 45 Batch 120 Loss 0.2369\n",
            "Epoch 45 Batch 128 Loss 0.2367\n",
            "Saving checkpoint for epoch 45 at checkpoints/ckpt-9\n",
            "Epoch 45 Loss 0.2367\n",
            "Time taken for 1 epoch: 4.9387102127075195 secs\n",
            "\n",
            "Epoch 46 Batch 0 Loss 0.0461\n",
            "Epoch 46 Batch 8 Loss 0.1597\n",
            "Epoch 46 Batch 16 Loss 0.2196\n",
            "Epoch 46 Batch 24 Loss 0.2090\n",
            "Epoch 46 Batch 32 Loss 0.2076\n",
            "Epoch 46 Batch 40 Loss 0.2126\n",
            "Epoch 46 Batch 48 Loss 0.2048\n",
            "Epoch 46 Batch 56 Loss 0.2024\n",
            "Epoch 46 Batch 64 Loss 0.2010\n",
            "Epoch 46 Batch 72 Loss 0.2034\n",
            "Epoch 46 Batch 80 Loss 0.2063\n",
            "Epoch 46 Batch 88 Loss 0.2070\n",
            "Epoch 46 Batch 96 Loss 0.2084\n",
            "Epoch 46 Batch 104 Loss 0.2089\n",
            "Epoch 46 Batch 112 Loss 0.2132\n",
            "Epoch 46 Batch 120 Loss 0.2110\n",
            "Epoch 46 Batch 128 Loss 0.2121\n",
            "Epoch 46 Loss 0.2121\n",
            "Time taken for 1 epoch: 3.5515568256378174 secs\n",
            "\n",
            "Epoch 47 Batch 0 Loss 0.1423\n",
            "Epoch 47 Batch 8 Loss 0.1488\n",
            "Epoch 47 Batch 16 Loss 0.1665\n",
            "Epoch 47 Batch 24 Loss 0.1830\n",
            "Epoch 47 Batch 32 Loss 0.1932\n",
            "Epoch 47 Batch 40 Loss 0.1935\n",
            "Epoch 47 Batch 48 Loss 0.1878\n",
            "Epoch 47 Batch 56 Loss 0.1872\n",
            "Epoch 47 Batch 64 Loss 0.1910\n",
            "Epoch 47 Batch 72 Loss 0.1996\n",
            "Epoch 47 Batch 80 Loss 0.1983\n",
            "Epoch 47 Batch 88 Loss 0.2014\n",
            "Epoch 47 Batch 96 Loss 0.2046\n",
            "Epoch 47 Batch 104 Loss 0.2058\n",
            "Epoch 47 Batch 112 Loss 0.2115\n",
            "Epoch 47 Batch 120 Loss 0.2105\n",
            "Epoch 47 Batch 128 Loss 0.2116\n",
            "Epoch 47 Loss 0.2116\n",
            "Time taken for 1 epoch: 3.5489206314086914 secs\n",
            "\n",
            "Epoch 48 Batch 0 Loss 0.1193\n",
            "Epoch 48 Batch 8 Loss 0.1750\n",
            "Epoch 48 Batch 16 Loss 0.1986\n",
            "Epoch 48 Batch 24 Loss 0.1824\n",
            "Epoch 48 Batch 32 Loss 0.1782\n",
            "Epoch 48 Batch 40 Loss 0.1787\n",
            "Epoch 48 Batch 48 Loss 0.1813\n",
            "Epoch 48 Batch 56 Loss 0.1823\n",
            "Epoch 48 Batch 64 Loss 0.1786\n",
            "Epoch 48 Batch 72 Loss 0.1820\n",
            "Epoch 48 Batch 80 Loss 0.1880\n",
            "Epoch 48 Batch 88 Loss 0.1893\n",
            "Epoch 48 Batch 96 Loss 0.1891\n",
            "Epoch 48 Batch 104 Loss 0.1916\n",
            "Epoch 48 Batch 112 Loss 0.1915\n",
            "Epoch 48 Batch 120 Loss 0.1919\n",
            "Epoch 48 Batch 128 Loss 0.1921\n",
            "Epoch 48 Loss 0.1921\n",
            "Time taken for 1 epoch: 3.562434196472168 secs\n",
            "\n",
            "Epoch 49 Batch 0 Loss 0.3307\n",
            "Epoch 49 Batch 8 Loss 0.1848\n",
            "Epoch 49 Batch 16 Loss 0.1738\n",
            "Epoch 49 Batch 24 Loss 0.1893\n",
            "Epoch 49 Batch 32 Loss 0.2015\n",
            "Epoch 49 Batch 40 Loss 0.2041\n",
            "Epoch 49 Batch 48 Loss 0.1912\n",
            "Epoch 49 Batch 56 Loss 0.1883\n",
            "Epoch 49 Batch 64 Loss 0.1894\n",
            "Epoch 49 Batch 72 Loss 0.1835\n",
            "Epoch 49 Batch 80 Loss 0.1878\n",
            "Epoch 49 Batch 88 Loss 0.1897\n",
            "Epoch 49 Batch 96 Loss 0.1930\n",
            "Epoch 49 Batch 104 Loss 0.1963\n",
            "Epoch 49 Batch 112 Loss 0.1944\n",
            "Epoch 49 Batch 120 Loss 0.1948\n",
            "Epoch 49 Batch 128 Loss 0.1954\n",
            "Epoch 49 Loss 0.1954\n",
            "Time taken for 1 epoch: 3.538973569869995 secs\n",
            "\n",
            "Epoch 50 Batch 0 Loss 0.1143\n",
            "Epoch 50 Batch 8 Loss 0.1485\n",
            "Epoch 50 Batch 16 Loss 0.1432\n",
            "Epoch 50 Batch 24 Loss 0.1652\n",
            "Epoch 50 Batch 32 Loss 0.1550\n",
            "Epoch 50 Batch 40 Loss 0.1563\n",
            "Epoch 50 Batch 48 Loss 0.1554\n",
            "Epoch 50 Batch 56 Loss 0.1614\n",
            "Epoch 50 Batch 64 Loss 0.1640\n",
            "Epoch 50 Batch 72 Loss 0.1587\n",
            "Epoch 50 Batch 80 Loss 0.1651\n",
            "Epoch 50 Batch 88 Loss 0.1648\n",
            "Epoch 50 Batch 96 Loss 0.1660\n",
            "Epoch 50 Batch 104 Loss 0.1679\n",
            "Epoch 50 Batch 112 Loss 0.1680\n",
            "Epoch 50 Batch 120 Loss 0.1716\n",
            "Epoch 50 Batch 128 Loss 0.1751\n",
            "Saving checkpoint for epoch 50 at checkpoints/ckpt-10\n",
            "Epoch 50 Loss 0.1751\n",
            "Time taken for 1 epoch: 3.891352653503418 secs\n",
            "\n",
            "Epoch 51 Batch 0 Loss 0.0390\n",
            "Epoch 51 Batch 8 Loss 0.2054\n",
            "Epoch 51 Batch 16 Loss 0.2011\n",
            "Epoch 51 Batch 24 Loss 0.2189\n",
            "Epoch 51 Batch 32 Loss 0.2043\n",
            "Epoch 51 Batch 40 Loss 0.1978\n",
            "Epoch 51 Batch 48 Loss 0.1912\n",
            "Epoch 51 Batch 56 Loss 0.1859\n",
            "Epoch 51 Batch 64 Loss 0.1832\n",
            "Epoch 51 Batch 72 Loss 0.1783\n",
            "Epoch 51 Batch 80 Loss 0.1731\n",
            "Epoch 51 Batch 88 Loss 0.1723\n",
            "Epoch 51 Batch 96 Loss 0.1752\n",
            "Epoch 51 Batch 104 Loss 0.1757\n",
            "Epoch 51 Batch 112 Loss 0.1742\n",
            "Epoch 51 Batch 120 Loss 0.1740\n",
            "Epoch 51 Batch 128 Loss 0.1745\n",
            "Epoch 51 Loss 0.1745\n",
            "Time taken for 1 epoch: 5.103436470031738 secs\n",
            "\n",
            "Epoch 52 Batch 0 Loss 0.3014\n",
            "Epoch 52 Batch 8 Loss 0.1638\n",
            "Epoch 52 Batch 16 Loss 0.1395\n",
            "Epoch 52 Batch 24 Loss 0.1315\n",
            "Epoch 52 Batch 32 Loss 0.1456\n",
            "Epoch 52 Batch 40 Loss 0.1517\n",
            "Epoch 52 Batch 48 Loss 0.1476\n",
            "Epoch 52 Batch 56 Loss 0.1508\n",
            "Epoch 52 Batch 64 Loss 0.1532\n",
            "Epoch 52 Batch 72 Loss 0.1545\n",
            "Epoch 52 Batch 80 Loss 0.1566\n",
            "Epoch 52 Batch 88 Loss 0.1602\n",
            "Epoch 52 Batch 96 Loss 0.1614\n",
            "Epoch 52 Batch 104 Loss 0.1642\n",
            "Epoch 52 Batch 112 Loss 0.1665\n",
            "Epoch 52 Batch 120 Loss 0.1642\n",
            "Epoch 52 Batch 128 Loss 0.1664\n",
            "Epoch 52 Loss 0.1664\n",
            "Time taken for 1 epoch: 3.5380828380584717 secs\n",
            "\n",
            "Epoch 53 Batch 0 Loss 0.0612\n",
            "Epoch 53 Batch 8 Loss 0.1033\n",
            "Epoch 53 Batch 16 Loss 0.1254\n",
            "Epoch 53 Batch 24 Loss 0.1324\n",
            "Epoch 53 Batch 32 Loss 0.1320\n",
            "Epoch 53 Batch 40 Loss 0.1322\n",
            "Epoch 53 Batch 48 Loss 0.1342\n",
            "Epoch 53 Batch 56 Loss 0.1342\n",
            "Epoch 53 Batch 64 Loss 0.1337\n",
            "Epoch 53 Batch 72 Loss 0.1336\n",
            "Epoch 53 Batch 80 Loss 0.1366\n",
            "Epoch 53 Batch 88 Loss 0.1370\n",
            "Epoch 53 Batch 96 Loss 0.1425\n",
            "Epoch 53 Batch 104 Loss 0.1456\n",
            "Epoch 53 Batch 112 Loss 0.1499\n",
            "Epoch 53 Batch 120 Loss 0.1524\n",
            "Epoch 53 Batch 128 Loss 0.1557\n",
            "Epoch 53 Loss 0.1557\n",
            "Time taken for 1 epoch: 3.515688180923462 secs\n",
            "\n",
            "Epoch 54 Batch 0 Loss 0.0279\n",
            "Epoch 54 Batch 8 Loss 0.0827\n",
            "Epoch 54 Batch 16 Loss 0.1056\n",
            "Epoch 54 Batch 24 Loss 0.1192\n",
            "Epoch 54 Batch 32 Loss 0.1120\n",
            "Epoch 54 Batch 40 Loss 0.1106\n",
            "Epoch 54 Batch 48 Loss 0.1169\n",
            "Epoch 54 Batch 56 Loss 0.1187\n",
            "Epoch 54 Batch 64 Loss 0.1229\n",
            "Epoch 54 Batch 72 Loss 0.1269\n",
            "Epoch 54 Batch 80 Loss 0.1298\n",
            "Epoch 54 Batch 88 Loss 0.1335\n",
            "Epoch 54 Batch 96 Loss 0.1341\n",
            "Epoch 54 Batch 104 Loss 0.1368\n",
            "Epoch 54 Batch 112 Loss 0.1361\n",
            "Epoch 54 Batch 120 Loss 0.1393\n",
            "Epoch 54 Batch 128 Loss 0.1419\n",
            "Epoch 54 Loss 0.1419\n",
            "Time taken for 1 epoch: 3.5225629806518555 secs\n",
            "\n",
            "Epoch 55 Batch 0 Loss 0.1181\n",
            "Epoch 55 Batch 8 Loss 0.1184\n",
            "Epoch 55 Batch 16 Loss 0.1217\n",
            "Epoch 55 Batch 24 Loss 0.1120\n",
            "Epoch 55 Batch 32 Loss 0.1156\n",
            "Epoch 55 Batch 40 Loss 0.1167\n",
            "Epoch 55 Batch 48 Loss 0.1241\n",
            "Epoch 55 Batch 56 Loss 0.1223\n",
            "Epoch 55 Batch 64 Loss 0.1238\n",
            "Epoch 55 Batch 72 Loss 0.1236\n",
            "Epoch 55 Batch 80 Loss 0.1250\n",
            "Epoch 55 Batch 88 Loss 0.1231\n",
            "Epoch 55 Batch 96 Loss 0.1268\n",
            "Epoch 55 Batch 104 Loss 0.1267\n",
            "Epoch 55 Batch 112 Loss 0.1289\n",
            "Epoch 55 Batch 120 Loss 0.1294\n",
            "Epoch 55 Batch 128 Loss 0.1281\n",
            "Saving checkpoint for epoch 55 at checkpoints/ckpt-11\n",
            "Epoch 55 Loss 0.1281\n",
            "Time taken for 1 epoch: 3.8641419410705566 secs\n",
            "\n",
            "Epoch 56 Batch 0 Loss 0.0989\n",
            "Epoch 56 Batch 8 Loss 0.1287\n",
            "Epoch 56 Batch 16 Loss 0.1064\n",
            "Epoch 56 Batch 24 Loss 0.1129\n",
            "Epoch 56 Batch 32 Loss 0.1090\n",
            "Epoch 56 Batch 40 Loss 0.1084\n",
            "Epoch 56 Batch 48 Loss 0.1130\n",
            "Epoch 56 Batch 56 Loss 0.1123\n",
            "Epoch 56 Batch 64 Loss 0.1134\n",
            "Epoch 56 Batch 72 Loss 0.1138\n",
            "Epoch 56 Batch 80 Loss 0.1142\n",
            "Epoch 56 Batch 88 Loss 0.1163\n",
            "Epoch 56 Batch 96 Loss 0.1191\n",
            "Epoch 56 Batch 104 Loss 0.1215\n",
            "Epoch 56 Batch 112 Loss 0.1203\n",
            "Epoch 56 Batch 120 Loss 0.1242\n",
            "Epoch 56 Batch 128 Loss 0.1242\n",
            "Epoch 56 Loss 0.1242\n",
            "Time taken for 1 epoch: 3.540843963623047 secs\n",
            "\n",
            "Epoch 57 Batch 0 Loss 0.1025\n",
            "Epoch 57 Batch 8 Loss 0.0881\n",
            "Epoch 57 Batch 16 Loss 0.0968\n",
            "Epoch 57 Batch 24 Loss 0.1035\n",
            "Epoch 57 Batch 32 Loss 0.1033\n",
            "Epoch 57 Batch 40 Loss 0.1023\n",
            "Epoch 57 Batch 48 Loss 0.1029\n",
            "Epoch 57 Batch 56 Loss 0.1139\n",
            "Epoch 57 Batch 64 Loss 0.1148\n",
            "Epoch 57 Batch 72 Loss 0.1134\n",
            "Epoch 57 Batch 80 Loss 0.1137\n",
            "Epoch 57 Batch 88 Loss 0.1135\n",
            "Epoch 57 Batch 96 Loss 0.1136\n",
            "Epoch 57 Batch 104 Loss 0.1182\n",
            "Epoch 57 Batch 112 Loss 0.1197\n",
            "Epoch 57 Batch 120 Loss 0.1205\n",
            "Epoch 57 Batch 128 Loss 0.1248\n",
            "Epoch 57 Loss 0.1248\n",
            "Time taken for 1 epoch: 3.5355064868927 secs\n",
            "\n",
            "Epoch 58 Batch 0 Loss 0.0915\n",
            "Epoch 58 Batch 8 Loss 0.1214\n",
            "Epoch 58 Batch 16 Loss 0.1116\n",
            "Epoch 58 Batch 24 Loss 0.1215\n",
            "Epoch 58 Batch 32 Loss 0.1231\n",
            "Epoch 58 Batch 40 Loss 0.1211\n",
            "Epoch 58 Batch 48 Loss 0.1171\n",
            "Epoch 58 Batch 56 Loss 0.1125\n",
            "Epoch 58 Batch 64 Loss 0.1119\n",
            "Epoch 58 Batch 72 Loss 0.1118\n",
            "Epoch 58 Batch 80 Loss 0.1105\n",
            "Epoch 58 Batch 88 Loss 0.1104\n",
            "Epoch 58 Batch 96 Loss 0.1149\n",
            "Epoch 58 Batch 104 Loss 0.1173\n",
            "Epoch 58 Batch 112 Loss 0.1177\n",
            "Epoch 58 Batch 120 Loss 0.1195\n",
            "Epoch 58 Batch 128 Loss 0.1238\n",
            "Epoch 58 Loss 0.1238\n",
            "Time taken for 1 epoch: 3.5223991870880127 secs\n",
            "\n",
            "Epoch 59 Batch 0 Loss 0.0524\n",
            "Epoch 59 Batch 8 Loss 0.0924\n",
            "Epoch 59 Batch 16 Loss 0.1034\n",
            "Epoch 59 Batch 24 Loss 0.1145\n",
            "Epoch 59 Batch 32 Loss 0.1238\n",
            "Epoch 59 Batch 40 Loss 0.1204\n",
            "Epoch 59 Batch 48 Loss 0.1280\n",
            "Epoch 59 Batch 56 Loss 0.1406\n",
            "Epoch 59 Batch 64 Loss 0.1394\n",
            "Epoch 59 Batch 72 Loss 0.1353\n",
            "Epoch 59 Batch 80 Loss 0.1386\n",
            "Epoch 59 Batch 88 Loss 0.1340\n",
            "Epoch 59 Batch 96 Loss 0.1324\n",
            "Epoch 59 Batch 104 Loss 0.1308\n",
            "Epoch 59 Batch 112 Loss 0.1328\n",
            "Epoch 59 Batch 120 Loss 0.1332\n",
            "Epoch 59 Batch 128 Loss 0.1331\n",
            "Epoch 59 Loss 0.1331\n",
            "Time taken for 1 epoch: 3.5134081840515137 secs\n",
            "\n",
            "Epoch 60 Batch 0 Loss 0.0455\n",
            "Epoch 60 Batch 8 Loss 0.1332\n",
            "Epoch 60 Batch 16 Loss 0.1112\n",
            "Epoch 60 Batch 24 Loss 0.1029\n",
            "Epoch 60 Batch 32 Loss 0.1062\n",
            "Epoch 60 Batch 40 Loss 0.1051\n",
            "Epoch 60 Batch 48 Loss 0.1015\n",
            "Epoch 60 Batch 56 Loss 0.1013\n",
            "Epoch 60 Batch 64 Loss 0.0969\n",
            "Epoch 60 Batch 72 Loss 0.0962\n",
            "Epoch 60 Batch 80 Loss 0.0990\n",
            "Epoch 60 Batch 88 Loss 0.0957\n",
            "Epoch 60 Batch 96 Loss 0.0953\n",
            "Epoch 60 Batch 104 Loss 0.0976\n",
            "Epoch 60 Batch 112 Loss 0.1012\n",
            "Epoch 60 Batch 120 Loss 0.1041\n",
            "Epoch 60 Batch 128 Loss 0.1050\n",
            "Saving checkpoint for epoch 60 at checkpoints/ckpt-12\n",
            "Epoch 60 Loss 0.1050\n",
            "Time taken for 1 epoch: 3.8688907623291016 secs\n",
            "\n",
            "Epoch 61 Batch 0 Loss 0.0161\n",
            "Epoch 61 Batch 8 Loss 0.1291\n",
            "Epoch 61 Batch 16 Loss 0.1203\n",
            "Epoch 61 Batch 24 Loss 0.1139\n",
            "Epoch 61 Batch 32 Loss 0.1107\n",
            "Epoch 61 Batch 40 Loss 0.1040\n",
            "Epoch 61 Batch 48 Loss 0.1123\n",
            "Epoch 61 Batch 56 Loss 0.1114\n",
            "Epoch 61 Batch 64 Loss 0.1101\n",
            "Epoch 61 Batch 72 Loss 0.1090\n",
            "Epoch 61 Batch 80 Loss 0.1112\n",
            "Epoch 61 Batch 88 Loss 0.1099\n",
            "Epoch 61 Batch 96 Loss 0.1128\n",
            "Epoch 61 Batch 104 Loss 0.1119\n",
            "Epoch 61 Batch 112 Loss 0.1130\n",
            "Epoch 61 Batch 120 Loss 0.1121\n",
            "Epoch 61 Batch 128 Loss 0.1136\n",
            "Epoch 61 Loss 0.1136\n",
            "Time taken for 1 epoch: 5.855336427688599 secs\n",
            "\n",
            "Epoch 62 Batch 0 Loss 0.1180\n",
            "Epoch 62 Batch 8 Loss 0.1331\n",
            "Epoch 62 Batch 16 Loss 0.1324\n",
            "Epoch 62 Batch 24 Loss 0.1346\n",
            "Epoch 62 Batch 32 Loss 0.1210\n",
            "Epoch 62 Batch 40 Loss 0.1152\n",
            "Epoch 62 Batch 48 Loss 0.1101\n",
            "Epoch 62 Batch 56 Loss 0.1085\n",
            "Epoch 62 Batch 64 Loss 0.1081\n",
            "Epoch 62 Batch 72 Loss 0.1179\n",
            "Epoch 62 Batch 80 Loss 0.1164\n",
            "Epoch 62 Batch 88 Loss 0.1147\n",
            "Epoch 62 Batch 96 Loss 0.1121\n",
            "Epoch 62 Batch 104 Loss 0.1132\n",
            "Epoch 62 Batch 112 Loss 0.1136\n",
            "Epoch 62 Batch 120 Loss 0.1147\n",
            "Epoch 62 Batch 128 Loss 0.1180\n",
            "Epoch 62 Loss 0.1180\n",
            "Time taken for 1 epoch: 4.282394170761108 secs\n",
            "\n",
            "Epoch 63 Batch 0 Loss 0.1596\n",
            "Epoch 63 Batch 8 Loss 0.0711\n",
            "Epoch 63 Batch 16 Loss 0.1106\n",
            "Epoch 63 Batch 24 Loss 0.1085\n",
            "Epoch 63 Batch 32 Loss 0.1186\n",
            "Epoch 63 Batch 40 Loss 0.1130\n",
            "Epoch 63 Batch 48 Loss 0.1127\n",
            "Epoch 63 Batch 56 Loss 0.1117\n",
            "Epoch 63 Batch 64 Loss 0.1150\n",
            "Epoch 63 Batch 72 Loss 0.1150\n",
            "Epoch 63 Batch 80 Loss 0.1153\n",
            "Epoch 63 Batch 88 Loss 0.1125\n",
            "Epoch 63 Batch 96 Loss 0.1126\n",
            "Epoch 63 Batch 104 Loss 0.1114\n",
            "Epoch 63 Batch 112 Loss 0.1100\n",
            "Epoch 63 Batch 120 Loss 0.1094\n",
            "Epoch 63 Batch 128 Loss 0.1091\n",
            "Epoch 63 Loss 0.1091\n",
            "Time taken for 1 epoch: 3.5275514125823975 secs\n",
            "\n",
            "Epoch 64 Batch 0 Loss 0.1585\n",
            "Epoch 64 Batch 8 Loss 0.1099\n",
            "Epoch 64 Batch 16 Loss 0.0850\n",
            "Epoch 64 Batch 24 Loss 0.0969\n",
            "Epoch 64 Batch 32 Loss 0.0929\n",
            "Epoch 64 Batch 40 Loss 0.0929\n",
            "Epoch 64 Batch 48 Loss 0.0861\n",
            "Epoch 64 Batch 56 Loss 0.0841\n",
            "Epoch 64 Batch 64 Loss 0.0860\n",
            "Epoch 64 Batch 72 Loss 0.0860\n",
            "Epoch 64 Batch 80 Loss 0.0850\n",
            "Epoch 64 Batch 88 Loss 0.0883\n",
            "Epoch 64 Batch 96 Loss 0.0889\n",
            "Epoch 64 Batch 104 Loss 0.0915\n",
            "Epoch 64 Batch 112 Loss 0.0912\n",
            "Epoch 64 Batch 120 Loss 0.0943\n",
            "Epoch 64 Batch 128 Loss 0.0948\n",
            "Epoch 64 Loss 0.0948\n",
            "Time taken for 1 epoch: 3.5218796730041504 secs\n",
            "\n",
            "Epoch 65 Batch 0 Loss 0.1139\n",
            "Epoch 65 Batch 8 Loss 0.1078\n",
            "Epoch 65 Batch 16 Loss 0.1130\n",
            "Epoch 65 Batch 24 Loss 0.1100\n",
            "Epoch 65 Batch 32 Loss 0.1251\n",
            "Epoch 65 Batch 40 Loss 0.1197\n",
            "Epoch 65 Batch 48 Loss 0.1138\n",
            "Epoch 65 Batch 56 Loss 0.1058\n",
            "Epoch 65 Batch 64 Loss 0.1065\n",
            "Epoch 65 Batch 72 Loss 0.1056\n",
            "Epoch 65 Batch 80 Loss 0.1039\n",
            "Epoch 65 Batch 88 Loss 0.1014\n",
            "Epoch 65 Batch 96 Loss 0.1028\n",
            "Epoch 65 Batch 104 Loss 0.1019\n",
            "Epoch 65 Batch 112 Loss 0.1011\n",
            "Epoch 65 Batch 120 Loss 0.1008\n",
            "Epoch 65 Batch 128 Loss 0.1020\n",
            "Saving checkpoint for epoch 65 at checkpoints/ckpt-13\n",
            "Epoch 65 Loss 0.1020\n",
            "Time taken for 1 epoch: 3.883472442626953 secs\n",
            "\n",
            "Epoch 66 Batch 0 Loss 0.0323\n",
            "Epoch 66 Batch 8 Loss 0.1126\n",
            "Epoch 66 Batch 16 Loss 0.1168\n",
            "Epoch 66 Batch 24 Loss 0.1078\n",
            "Epoch 66 Batch 32 Loss 0.1002\n",
            "Epoch 66 Batch 40 Loss 0.0949\n",
            "Epoch 66 Batch 48 Loss 0.0886\n",
            "Epoch 66 Batch 56 Loss 0.0910\n",
            "Epoch 66 Batch 64 Loss 0.0928\n",
            "Epoch 66 Batch 72 Loss 0.0923\n",
            "Epoch 66 Batch 80 Loss 0.0952\n",
            "Epoch 66 Batch 88 Loss 0.0955\n",
            "Epoch 66 Batch 96 Loss 0.0961\n",
            "Epoch 66 Batch 104 Loss 0.0969\n",
            "Epoch 66 Batch 112 Loss 0.0974\n",
            "Epoch 66 Batch 120 Loss 0.0973\n",
            "Epoch 66 Batch 128 Loss 0.0969\n",
            "Epoch 66 Loss 0.0969\n",
            "Time taken for 1 epoch: 5.10414457321167 secs\n",
            "\n",
            "Epoch 67 Batch 0 Loss 0.0307\n",
            "Epoch 67 Batch 8 Loss 0.0789\n",
            "Epoch 67 Batch 16 Loss 0.0723\n",
            "Epoch 67 Batch 24 Loss 0.0879\n",
            "Epoch 67 Batch 32 Loss 0.0851\n",
            "Epoch 67 Batch 40 Loss 0.0809\n",
            "Epoch 67 Batch 48 Loss 0.0777\n",
            "Epoch 67 Batch 56 Loss 0.0803\n",
            "Epoch 67 Batch 64 Loss 0.0872\n",
            "Epoch 67 Batch 72 Loss 0.0887\n",
            "Epoch 67 Batch 80 Loss 0.0900\n",
            "Epoch 67 Batch 88 Loss 0.0929\n",
            "Epoch 67 Batch 96 Loss 0.0923\n",
            "Epoch 67 Batch 104 Loss 0.0939\n",
            "Epoch 67 Batch 112 Loss 0.0915\n",
            "Epoch 67 Batch 120 Loss 0.0917\n",
            "Epoch 67 Batch 128 Loss 0.0912\n",
            "Epoch 67 Loss 0.0912\n",
            "Time taken for 1 epoch: 3.537940263748169 secs\n",
            "\n",
            "Epoch 68 Batch 0 Loss 0.0349\n",
            "Epoch 68 Batch 8 Loss 0.0300\n",
            "Epoch 68 Batch 16 Loss 0.0322\n",
            "Epoch 68 Batch 24 Loss 0.0433\n",
            "Epoch 68 Batch 32 Loss 0.0489\n",
            "Epoch 68 Batch 40 Loss 0.0548\n",
            "Epoch 68 Batch 48 Loss 0.0538\n",
            "Epoch 68 Batch 56 Loss 0.0573\n",
            "Epoch 68 Batch 64 Loss 0.0598\n",
            "Epoch 68 Batch 72 Loss 0.0598\n",
            "Epoch 68 Batch 80 Loss 0.0637\n",
            "Epoch 68 Batch 88 Loss 0.0638\n",
            "Epoch 68 Batch 96 Loss 0.0667\n",
            "Epoch 68 Batch 104 Loss 0.0690\n",
            "Epoch 68 Batch 112 Loss 0.0732\n",
            "Epoch 68 Batch 120 Loss 0.0763\n",
            "Epoch 68 Batch 128 Loss 0.0787\n",
            "Epoch 68 Loss 0.0787\n",
            "Time taken for 1 epoch: 3.514864683151245 secs\n",
            "\n",
            "Epoch 69 Batch 0 Loss 0.0611\n",
            "Epoch 69 Batch 8 Loss 0.1138\n",
            "Epoch 69 Batch 16 Loss 0.0939\n",
            "Epoch 69 Batch 24 Loss 0.1175\n",
            "Epoch 69 Batch 32 Loss 0.1065\n",
            "Epoch 69 Batch 40 Loss 0.1101\n",
            "Epoch 69 Batch 48 Loss 0.1052\n",
            "Epoch 69 Batch 56 Loss 0.1008\n",
            "Epoch 69 Batch 64 Loss 0.0965\n",
            "Epoch 69 Batch 72 Loss 0.0955\n",
            "Epoch 69 Batch 80 Loss 0.0941\n",
            "Epoch 69 Batch 88 Loss 0.0923\n",
            "Epoch 69 Batch 96 Loss 0.0916\n",
            "Epoch 69 Batch 104 Loss 0.0906\n",
            "Epoch 69 Batch 112 Loss 0.0907\n",
            "Epoch 69 Batch 120 Loss 0.0913\n",
            "Epoch 69 Batch 128 Loss 0.0901\n",
            "Epoch 69 Loss 0.0901\n",
            "Time taken for 1 epoch: 3.524136781692505 secs\n",
            "\n",
            "Epoch 70 Batch 0 Loss 0.0328\n",
            "Epoch 70 Batch 8 Loss 0.0729\n",
            "Epoch 70 Batch 16 Loss 0.0609\n",
            "Epoch 70 Batch 24 Loss 0.0609\n",
            "Epoch 70 Batch 32 Loss 0.0630\n",
            "Epoch 70 Batch 40 Loss 0.0604\n",
            "Epoch 70 Batch 48 Loss 0.0658\n",
            "Epoch 70 Batch 56 Loss 0.0659\n",
            "Epoch 70 Batch 64 Loss 0.0643\n",
            "Epoch 70 Batch 72 Loss 0.0693\n",
            "Epoch 70 Batch 80 Loss 0.0728\n",
            "Epoch 70 Batch 88 Loss 0.0710\n",
            "Epoch 70 Batch 96 Loss 0.0743\n",
            "Epoch 70 Batch 104 Loss 0.0758\n",
            "Epoch 70 Batch 112 Loss 0.0763\n",
            "Epoch 70 Batch 120 Loss 0.0760\n",
            "Epoch 70 Batch 128 Loss 0.0742\n",
            "Saving checkpoint for epoch 70 at checkpoints/ckpt-14\n",
            "Epoch 70 Loss 0.0742\n",
            "Time taken for 1 epoch: 3.877962112426758 secs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MmWB9wpOp6x"
      },
      "source": [
        "def evaluate(input_document):\n",
        "    input_document = document_tokenizer.texts_to_sequences([input_document])\n",
        "    input_document = tf.keras.preprocessing.sequence.pad_sequences(input_document, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
        "\n",
        "    encoder_input = tf.expand_dims(input_document[0], 0)\n",
        "\n",
        "    decoder_input = [summary_tokenizer.word_index[\"<go>\"]]\n",
        "    output = tf.expand_dims(decoder_input, 0)\n",
        "\n",
        "    for i in range(decoder_maxlen):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
        "\n",
        "        predictions, attention_weights = transformer(\n",
        "            encoder_input,\n",
        "            output,\n",
        "            False,\n",
        "            enc_padding_mask,\n",
        "            combined_mask,\n",
        "            dec_padding_mask\n",
        "        )\n",
        "\n",
        "        predictions = predictions[: ,-1:, :]\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "        if predicted_id == summary_tokenizer.word_index[\"<stop>\"]:\n",
        "            return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(output, axis=0), attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g308MId-PCmh"
      },
      "source": [
        "def summarize(input_document):\n",
        "    summarized = evaluate(input_document=input_document)[0].numpy()\n",
        "    summarized = np.expand_dims(summarized[1:], 0)  # not printing <go> token\n",
        "    return summary_tokenizer.sequences_to_texts(summarized)[0]  # since there is just one translated document"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = []\n",
        "for i in df.Text:\n",
        "  output.append(summarize(i))"
      ],
      "metadata": {
        "id": "-ozlvpxJEJXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reference = []\n",
        "for i in df.Summary:\n",
        "  reference.append(i)"
      ],
      "metadata": {
        "id": "AM5e8FMYF_4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reference"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZaD-RhZLBwb",
        "outputId": "740e0e69-c68f-4350-b6ca-91b3fb187eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['বাংলাদেশে কোচিং বানিজ্য বন্ধ এখন সময়ের দাবি',\n",
              " 'বাংলা ভাষার প্রযুক্তি নিয়ে আমাদের আরো অনেক বেশি আগ্রহী ও গবেষণায় মনোযোগ দিতে হবে',\n",
              " 'যদি শিশুরা বই পড়ার অভ্যাস করে তাহলে সারা জীবনের জন্য আমরা তাদের নিয়ে নিশ্চিন্ত থাকতে পারব।',\n",
              " 'বাংলাদেশে সব স্তরে নারীর ক্ষমতায়নের জন্য আরও অনেক কাজ করে যেতে হবে।',\n",
              " 'ভালো কথা বল, নয়ত চুপ থাকো',\n",
              " 'সমাবর্তনের মাধ্যমে শিক্ষা জীবনের শেষ হলেও সফলতা ও ব্যর্থজীবনের হিসাব গণনা শুরু হয়ে এখান থেকেই',\n",
              " 'বাবার কষ্টার্জিত অর্থের মূল্য দিতে শিখো',\n",
              " 'নিজের ভুলের জন্য অনুতপ্ত হওয়া উচিত',\n",
              " 'দুশমনের শরণ ক্ষতির কারণ',\n",
              " 'অনেক গুলো গুনোবানহীন সন্তানের চেয়ে একটি গুনবান পূর্ন সন্তানই যথেষ্ট',\n",
              " 'মানুষ যখন বিপদে পরে তখন সমাজের তুচ্ছ মানুষরাও তাকে অপদস্ত করে',\n",
              " 'কারো পৌষ মাস,আবার কারো সর্বনাশ',\n",
              " 'আমাদের সমাজেও এমন অনেক লোক আছে যারা মুখে বলে এক কথা কিন্তু করে আরেক',\n",
              " 'উপকারীর উপকার স্বীকার করতে হবে ',\n",
              " 'দিনশেষে এই পৃথিবীর বেশিরভাগ মানুষ কেউ কাউকে বুঝে না',\n",
              " 'যেদিন মিথ্যেগুলোকে সত্যি সত্যি মিথ্যে মনে হবে, সেদিন সব শেষ হয়ে যাবে',\n",
              " 'একটা মানুষ যখন বিশ্বাস করতে শুরু করে যে সে আমার সাথে ভালো থাকবে না, ঠিক তখনই সে চলে যায়',\n",
              " 'কষ্ট দুর্বোধ্য না, কষ্ট থেকে বের হবার উপায় দুর্বোধ্য',\n",
              " 'ভালো থাকতে হলে আগে চাওয়া-পাওয়ার হিসেব মেলাতে হয়',\n",
              " 'এই পৃথিবীতে যারা এখনো কষ্ট পেলে মন উজাড় করে কাঁদতে পারে, তারাই ভালো আছে',\n",
              " 'ধর্ষণের শাস্তি হতে হবে কঠোর',\n",
              " 'দিনশেষে নিজের ভালবাসার মানুষকে জীবনে সবচেয়ে বেশি প্রয়োজন',\n",
              " 'জীবনটা একটা যুদ্ধ পরিশ্রম ছাড়া এই যুদ্ধে জেতা যায় না',\n",
              " 'সমায়ের সাথে সব কিছুর পরিবর্তন হয়',\n",
              " 'যুদ্ধ জয়ের হাঁসি হাসে মানুষ সমাবর্তনে',\n",
              " 'দিনশেষে মানুষ সব পারে',\n",
              " 'জীবনটা কারো জন্য থেমে থাকে না',\n",
              " 'রাস্তায় চলাচলে আমাদের অনেক বেশি সাবধানতা অবলম্বন করতে হবে',\n",
              " \"আমাদের জীবনের অনেক সিদ্ধান্ত এইসব 'হয়তো', 'যদি', 'কিন্তু' তে আটকে থাকে\",\n",
              " 'গর্বের সাথে বাবা-মায়ের পরিচয় দিতে সমাজের মানুষের তথাকথিত স্বীকৃতির কোন প্রয়োজন নেই',\n",
              " 'সবকিছুর সাথে আপোষ করা যায়,কিন্তু নিজের আত্মসম্মানকে যে আঘাত করে,তার সাথে আপোষ করার প্রশ্নই আসেনা ',\n",
              " 'সত্যিকারের ভালোবাসা জীবন থেকে হারাতে দেয়া যাবে না',\n",
              " 'মানুুষ দিনকে দিন হিংস্র হয়ে উঠছে',\n",
              " 'দিনশেষে চুপচাপ বসে থাকাটা একটা ক্ষণস্থায়ী সমাধান আর দীর্ঘস্থায়ী সমস্যার জন্ম দেয়',\n",
              " 'জীবনের একেকটা পর্যায়ে নিজের একেকটা অংশকে ফেলে রেখে আসার নামই বোধহয় বদলে যাওয়া',\n",
              " 'মন থেকে যে মানুষটাকে ভালোবাসি, তার অবহেলাকে পাল্টা অবহেলা করা যায় না',\n",
              " 'বিদেশ থেকে উচ্চশিক্ষা গ্রহন এর পর শিক্ষার্থীদের নিজ দেশের সেবায় দেশে ফিরা উচিত',\n",
              " 'সত্যিকারের বিশ্ববিদ্যালয় হতে হলে তাকে জ্ঞান সৃষ্টি করতে হয়',\n",
              " 'নূতন পৃথিবীটিতে জ্ঞান হচ্ছে সম্পদ এবং সেই সম্পদের পরিমাপ করা হয় পেটেন্ট দিয়ে',\n",
              " 'শিক্ষকতার মত মহৎ পেশা নিয়ে আমরা এই যুগেও নাক ছিটকাই',\n",
              " 'বোকা মানুষগুলো আশায় বাঁচে আর হতাশায় ধুকে ধুকে মরতে থাকে',\n",
              " 'নিজেকে ব্যখ্যা করাটা সত্যিই অনেক কঠিন',\n",
              " 'পারফেক্ট লাইফ বলে মনে হয় কিছুই নেই',\n",
              " 'মন খারাপের গল্প বলার শেষ মানুষটাও চলে গেলে তা সয়ে নেয়া ভীষণ ভীষণ কঠিন',\n",
              " 'আল্লাহ্\\u200cর কাছে আমাদের মন খুলে চাইতে হবে',\n",
              " 'বড় হয়ে যাওয়ার সমস্যাটা এখানেই ,চাইলেই চিৎকার করে কাঁদা যায় না',\n",
              " 'দুনিয়াতে সবাই নিজের পাপের ফল পাবে',\n",
              " 'পৃথিবীর সব কিছু আমরা ঠিক যেমন করে চাই তেমন করে হবে না',\n",
              " 'এই ব্যাস্ত শহরে কেউ কারো না,সবাই নিজেকে নিয়ে ব্যাস্ত',\n",
              " 'জীবনে মায়ের গুরুত্ব কোনো কিছুর সাথে তুলনা করে বুঝানো যাবে না',\n",
              " 'আজম খানের বীরত্ব গাঁথা',\n",
              " 'ভারতে হিন্দু মুসলিম দাঙ্গা',\n",
              " 'ঢাকা শাহজালাল বিমানবন্দরে নেমে ফ্রি তে কল করতে পারবে যাত্রীরা',\n",
              " 'অন্যের জন্য নিজের ক্ষতি করা যবে না',\n",
              " 'ডাক্তার রোগীর দুঃখ তখনই বুঝবে যদি ডাক্তারের ও সেইম রোগ হয়ে থাকে',\n",
              " 'পাগল হউক আর যেই হউক সবার জীবনের মূল্য আছে',\n",
              " 'জীবন কারো জন্য থেমে থকে না',\n",
              " 'যত দিন মেয়েরা পুরুষের চরিত্র বলতে কেবলই প্রজননযন্ত্রের একমুখিতাকে বুঝবে,তত দিন দেশ দুর্নীতিমুক্ত হবে না',\n",
              " 'মেয়েদের মতো জটিল ঘরোয়া বুদ্ধি পুরুষদের মাথায় তেমন ঢোকে না',\n",
              " 'পুরুষের অব্যক্ত বেদনার কথা হয়তো কেউ কখনও বলবে না',\n",
              " 'পুরুষদের যে নিরাপত্তার অভাব, এটা মেনে নিতে পর্যন্ত এ সমাজ কুণ্ঠিত হয়',\n",
              " 'পুরুষ মানুষ সমাজে প্রতিনিয়ত অবহ্লিত হয়ে আসছে',\n",
              " 'দেখেশুনে, হিসেব কষে প্রেম হয় না, বড়জোর ব্যবসা হয়',\n",
              " 'সময়ের কাজ সময়ে করতে হবে',\n",
              " 'ভালোবাসায় শান্তি আছে, শক্তি আছে, স্বস্তি আছে',\n",
              " 'বাবাা মার দোয়া ছাড়া জীবনে সামনে আগানো কঠিন',\n",
              " 'একজন মানুষের সবচাইতে বড় গুণটি হল মানবিকতা',\n",
              " 'যার সার্টিফিকেট যত ভারী, তার অর্থসংক্রান্ত ঘিলু তত কম',\n",
              " 'সব সম্পর্কে যেমনি ভালোবাসা থাকে না, ঠিক তেমনি সব ভালোবাসায় সম্পর্ক থাকে না',\n",
              " 'ভালোবাসাকে সব সময়ই যে একটা টু-ওয়ে ট্রাফিক হতে হবে, এমন নয়',\n",
              " 'সত্যি না জেনে মানুষ অনেক সময় একে অপরকে ভুল বুঝে',\n",
              " ' কাছের কারও কাছে নিজেকে বোঝাতে না পারার মতো অসহায়ত্ব আর নেই',\n",
              " 'কাউকে কষ্ট দিতে হয় না, প্রকৃতি তা বহুগুণে ফেরত দেয়',\n",
              " 'আপনি যদি আপনার মতো করে শতভাগ আনুগত্য চান, তবে একটা কুত্তা পালেন, মানুষ না।',\n",
              " 'সবার একটা ব্যক্তিগত জীবন থাকে',\n",
              " 'বড় মানুষগুলো কাছ থেকে সাধারণত বড় নন',\n",
              " 'যার বিশ্বাস যত বড়, তার গন্তব্য তত বড়',\n",
              " 'যে শূন্যে যেতে পারে না, সে কখনও দশেই উঠতে পারে না',\n",
              " 'মানুষের মেধার মূল্যায়ন করত',\n",
              " 'ভালোবাসার মানুষ এর সামনেই নিজের সুস্থতা',\n",
              " 'নিজেরা নিজেদের ক্ষতি করিস না',\n",
              " 'কারো সম্পর্কে ভালো বলতে না পারলেও খারাপ বলা উচিত না',\n",
              " 'যুদ্ধে আহত শত্রুর প্রতি মানবতা দেখানো উচিত ',\n",
              " 'সোভিয়েত ইউনিয়ন এর  ঘুম নিয়ে এক অদ্ভুত এক্সপেরিমেন্ট',\n",
              " 'স্বামী-স্ত্রীর সম্পর্ক মানে একে অপরের দোষ ঢেকে রাখার একটা সম্পর্ক',\n",
              " 'জীবনে চলার পথে নতুন কিছু গড়তে পুরনো কে ভাঙ্গতে হবে',\n",
              " 'একটা সম্পর্কে দুই জনকেই আন্তরিক হতে হবে',\n",
              " 'ভালোবাসা সে যে পৃথিবীর শ্রেষ্ঠ অনুভূতি',\n",
              " 'বাবা  মার ঝগড়া কখনো যেনো সন্তানের উপর বিরূপ প্রভাব না ফেলে সেদিকে খেয়াল রাখতে হবে',\n",
              " 'অন্যের দোহাই দিয়ে আমরা অনেক সময় নিজেদের স্মাজের কটু কথা থেকে বাঁচতে অনেক পদক্ষেপ নেই',\n",
              " 'অপেক্ষাই হলো শুদ্ধতম ভালোবাসা ও ভালোথাকা',\n",
              " 'কাউকে কোনও সেবা দেওয়ার জন্য টাকা নেওয়ার সময় এমন একটাও কমিটমেন্ট করবেন না, যা রাখা আপনার পক্ষে সম্ভব নয়',\n",
              " 'ব্যবসার নামে ব্যাবসা করা মানুষ গুলা সমাজের কীট',\n",
              " 'এ দুর্ভাগা দেশে আপনি টাকা দিয়েও প্রাপ্য সেবাটি পাবেন না',\n",
              " 'জীবন হলো নদীর মতো , প্রবাহ মান',\n",
              " 'ছেলেদের জীবনে অনেক কষ্ট করতে হয়। ',\n",
              " 'ভালোবাসা আসীম',\n",
              " 'ভাালোবাসার মানুষ এর মাঝে কেও পুরো পৃথিবী খুজে পায়',\n",
              " 'মানুষ এর বই মেলাতে যাওয়ার গুরুত্ব অপরিসীম ',\n",
              " 'বাংলা সাহিত্য সম্পর্কে জানতে হলে মানিক বন্দ্যোপাধ্যায়, সৈয়দ ওয়ালীউল্লাহ, আজিজুল হক , শহীদুল জহির, সৈয়দ শামসুল হক এর সাহিত্য পড়া অতিব জরুরী',\n",
              " 'সাম্প্রদায়িক সম্প্রীতি সমুন্নত রাখুন',\n",
              " 'বিনম্রতা একটি মহৎ গুন',\n",
              " 'মাঝে মাঝে বুদ্ধির অহংকারে চালাকি করতে গিয়ে ভাগ্য এমন বিড়ম্বনা ঘটায় যা মানুষ স্বপ্নেও ভাবতে পারে না ।',\n",
              " 'মানুষ অনেক সময় না বুঝে এমন জিনিস চায় , যা পেতে না পেতে তার থেকে মুক্তি পাবার জন্য ব্যতিব্যস্ত হয় পড়ে ।',\n",
              " 'কাজের সময় এবং খেলার জন্য একটি সময় আছে।',\n",
              " 'অহংকার ও দুর্বিনীতি আচরন সহজেই প্রতিপক্ষ দৃষ্টি আকর্ষণ করে ।',\n",
              " 'পরিস্থিতি ভেবে কাউকে সাহায্য করা উচিত ।',\n",
              " 'দুর্বল সবলের চাল চালতে গেলে তার নিজেরই সর্বনাশ হয় ।',\n",
              " 'সবসময় উপকারের বদলে প্রত্যুপকার করতে হয় ।',\n",
              " 'অন্যায়ের বিরুদ্ধে প্রথমবারই যদি রুখে দাঁড়ানো যায় , তা হলে পরবর্তীতে তোমার প্রতি অন্যায় করতে কেউ সাহস পাবে না ।',\n",
              " 'মানুষের মাঝে স্বার্থ ভিত্তিক বিভাজন সৃষ্টি হলে, তারা অন্যায় কাজ প্রতিরোধ করার সামর্থ্য হারিয়ে ফেলবে।',\n",
              " 'অনেক ক্ষেত্রেই কাগুজে ডিগ্রির চেয়ে অভিজ্ঞতা মূল্য বেশী।',\n",
              " 'যে যত উপরে, তাঁর চুরি ততো বড় এবং তা ধরা ছোঁয়ার বাইরে।',\n",
              " 'চোরের উপর বড় চোর আছে ',\n",
              " 'কারো ক্ষতি করা খারাপ',\n",
              " 'ধর্য একটি মহৎ গুন',\n",
              " 'সময়ের গুরুত্ব দিতে হবে',\n",
              " 'কেউ কোনো প্রশ্ন করলে তাকে পাল্টা কোনো প্রশ্ন না করার মাঝে এক প্রকার পৈশাচিক আনন্দ আছে',\n",
              " 'সমাজে প্রকৃত মানুষের বড়ই অভাব',\n",
              " 'জীবনে যত বড়ই কষ্ট পাই না কেনো কখনো নিজের ক্ষতি করা যাবে না',\n",
              " 'স্বাধীনতার জন্য মুক্তির জন্য জীবন দিয়ে দেয়া',\n",
              " 'পুরোনো ভালোবাসার স্মৃতিচারণ',\n",
              " 'উপন্যাস লেখার বেপারে অনুপ্রেরণা',\n",
              " 'জীবনে  হাজার কষ্টের মাঝেও নিজেকে সুখী রাখতে হবে',\n",
              " 'আপনি যদি ব্যর্থ হন, আপনার দ্বারা শিল্প হবে',\n",
              " 'ই একজন পুরস্কার-বিজয়ীর জীবন চিরদিনের জন্য আলোর দিকে ভালোর দিকে পাল্টে দিতে পারে',\n",
              " 'সফলতা হচ্ছে একটি আপেক্ষিক ব্যাপার',\n",
              " 'আমি হাসিমুখে ভোট চাইতে লাগলাম। ',\n",
              " 'আমি আপনাকে এখনও ভালবাসি।',\n",
              " 'মেয়েদের সম্মান করার মধ্যে দিয়ে মাকে সম্মান করা হয়  কারণ সে একসময় মা হবে। ',\n",
              " 'দায়িত্ব নেওয়ার ভয়ে স্বামীর সংসার ত্যাগ করা এবং কোনো ধরনের সম্পর্কে না জড়ানো।',\n",
              " 'মিথ্যা সম্পর্ক রাখার চেয়ে  না রাখা অনেক ভালো।',\n",
              " 'অতি চালকের গলায় দড়ি ',\n",
              " 'কালো কলঙ্কের দাগ হলেও মাঝে মধ্যে কালোকে বাদে সাদাকে অসম্পূর্ণ লাগে.',\n",
              " 'কেও আমাদের  প্রতি সম্মান ও ভালোবাসা দেখালে , আমাদেরও উচিত তাদের প্রতি সম্মান ও ভালোবাসা দেখানো। ',\n",
              " 'বই পড়া এবং উপহার দেওয়ার মাঝে সুখ খুঁজে নেই ।',\n",
              " 'ভাগ্য আগেই নির্ধারণ থাকে তার মানে এই না যে আপনি চেষ্টা করবেন না, আমাদের উচিত চেষ্টা করা এবং আল্লাহর উপর ভরসা রাখা। ',\n",
              " 'একাকিত্ব জীবন অনেক বেদনাময়। ',\n",
              " 'পৃথিবীতে কোনো কাজকেই  ছোট করে দেখা উচিত নয়. সেই কাজের প্রতি মনে সন্তুষ্টি থাকাটাই জরুরী। ',\n",
              " 'পৃথিবীতে কোনও মেয়েই নিখুঁত নয়  তবে এমন একজন মেয়ে থাকবে যে আপনার জন্য নিখুঁত.',\n",
              " 'খ্যাতির বিড়ম্বনা ',\n",
              " 'একটি বই নাম তার অদম্য সিসিফাস। ',\n",
              " 'অল্পতেই সুখ খুঁজে নিতে হয়। ',\n",
              " 'কৃতজ্ঞ থাকুন যা আপনি পেয়েছেন। ',\n",
              " 'মানুষের ভুল গুলো গ্রহণ করতে শেখা। ',\n",
              " 'সত্যিকারের ভালোবাসা  খুব বেশী সাধারণ হয়। ',\n",
              " '\"সম্পর্কগুলোকে সময় থাকতে মূল্য খুব দরকার।  তাজমহল দেখা তো সবার ভাগ্যেই জুটেছে শুধু মমতাজ বাদে।\"',\n",
              " 'মানুষের থাকা আর না থাকাটা স্মৃতি হয়ে যায়। ',\n",
              " 'ইহুদিদের উপর ঘৃণা',\n",
              " 'জীবনের প্রতি ক্লান্ততা.',\n",
              " 'তারকাদের জীবনের গল্প।',\n",
              " 'নতুন বছর আর নতুন নতুন সম্পর্ক .',\n",
              " 'এয়ারপোর্ট  এ  চলাচলরত মানুষের জীবন কাহিনী।',\n",
              " 'নিজের জীবনের জন্য জীবনসঙ্গী খুঁজা।',\n",
              " 'নিজের নিরাপত্তা নিশ্চিত করার দায়িত্ব নিজেকেই নিতে হবে',\n",
              " 'চেষ্টা করলে সফলতা আসবে',\n",
              " 'সব জায়গাতে সব নিয়ম চলে না।',\n",
              " 'একটি মানুষকে জানার প্রতি আগ্রহ। ',\n",
              " 'শখের জন্য কি না করতে হয়।',\n",
              " 'ওয়াজেদ আলীর জীবনী',\n",
              " 'স্ত্রী স্বামীকে বোকা বানিয়েছে।',\n",
              " ' মানুষ বিভিন্ন ধরনের।',\n",
              " 'বই পড়ুন, বই উপহার দিন এবং দুটো লাইন লিখে দিন।',\n",
              " ' ভালোবাসার মানুষ পেলে তাকে আকড়ে ধরে রাখতে হয়।',\n",
              " 'অল্পতেই সুখ খুঁজে নেয়া।',\n",
              " 'একটি মেয়ের কাহিনী।',\n",
              " 'ভালো ছিল সেই সোনালি অতীতটা।',\n",
              " 'ভালোবাসতে একজন  অন্যজনকে বুঝতে হবে। ',\n",
              " 'জেদ মানুষ কে বড় করতে পারে না .',\n",
              " 'নিজের ব্যর্থতা  কারো উপর চাপিয়ে দেয়া যাবে না',\n",
              " 'করোনা ভাইরাস আক্রমণ বাংলাদেশের প্রেক্ষিতে।',\n",
              " 'আগের সময়ের কিছু স্মৃতি।',\n",
              " 'একটি নারীর যুদ্ধে রুখে দাঁড়ানোর গল্প নারীদিবসে সম্মান  এনে দেয়। ',\n",
              " 'মায়ের মর্ম বোঝানো হয়েছে।',\n",
              " 'রিভিশন দেওয়ার কৌশল।',\n",
              " 'প্রেগন্যান্সিতে ডাক্তারের সাজেশন । ',\n",
              " 'প্রেম দ্বিতীয় সুযোগের দাবি রাখে।',\n",
              " 'ইট মারলে পাটকেলটি খেতে হয়। ',\n",
              " 'আমাদের দেশে শিক্ষা ব্যবস্থা পরিবর্তন করা উচিত। ',\n",
              " 'আঞ্চলিক ভাষার মাঝেই আছে আত্মপরিচয়।',\n",
              " 'চাঁদপুর যাওয়ার অভিজ্ঞতা। ',\n",
              " 'নিজে কিছু  লিখার আগে অন্যের লিখা পড়ার ধোর্য রাখতে হয়। ',\n",
              " 'ভালোবাসার মানুষের জন্য  আত্মসম্মান কম্প্রোমাইজ করা উচিত নয়।',\n",
              " 'বাংলা ভাষার  প্রতি সম্মান জানানো উচিত।',\n",
              " 'অবহেলা পেতে পেতে পরে তা আর গায়ে লাগে না।',\n",
              " 'যে আত্মহত্যা করে তার। মনের কষ্ট কেউ বোঝে না।',\n",
              " 'জীবনে নতুন নতুন মানুষ আসলে পুরাতন মানুষ হারায়ে যায়।',\n",
              " 'অন্যকে বলার আগে নিজেকে ঠিক হতে হবে। ',\n",
              " 'দাম দিলে মান রাখতে হয়। ',\n",
              " 'নিজের ব্যক্তিত্বকে সম্মান করতে শিখা।',\n",
              " 'রাগের প্রকাশ করতে ইচ্ছে হয় মাঝেমাঝে। ',\n",
              " ' মানুষ তার উপরই রাগ করতে পছন্দ করে যাকে সে ভালোবাসে ',\n",
              " 'অতিরিক্ত লজ্জা মানুষের জীবন কে নষ্ট করে দেয়ার জন্য যথেষ্ট। ',\n",
              " 'ভালোবাসার মানুষের মায়ায় পরা উচিত।\\n',\n",
              " 'আপোনজনরাই জীবনের সব। ',\n",
              " ' কাউকে ভালোবাসলে তার সবকিছুকেই ভালোবাসতে হয়।',\n",
              " 'ধর্ষকের চেয়ে একজন বেশ্যা হাজারগুনে ভালো।',\n",
              " 'কষ্ট করে পাওয়া জিনিসের মূল্য অনেক। ',\n",
              " 'বাংলায় কিছু বললে তার মূল্যটা অনেক বেশি। ',\n",
              " 'না চাইতেও বিচ্ছেদ। ',\n",
              " 'বিচ্ছেদে কষ্ট না পেয়ে আগামী দিনের জন্য অপেক্ষা করো। ',\n",
              " 'মিথ্যা ভালোবাসা। ',\n",
              " 'কেউ না কেউ আপনাকে অনেক ভালোবাসে। ',\n",
              " 'ভালোবাসা মানে তার শরীর কে ভালোবাসা না তার মন কে ভালোবাসা।',\n",
              " 'মহিলাদের চেয়ে পুরুষেরা অনেক সোজা প্রকৃতির হয়',\n",
              " 'ফ্রেন্ডের বিভিন্ন ধরণ.',\n",
              " 'কষ্ট মানুষকে আরো শক্তিশালী করে তুলে। ',\n",
              " 'ব্যস্ততার মাঝে তোমাকেও ভুলে যাবো একদিন। ',\n",
              " 'কাছের মানুষ থেকে পাওয়া কষ্ট খুব কঠিন। ',\n",
              " 'বঙ্গবন্ধুর প্রতি আমরা কৃতজ্ঞ।',\n",
              " 'চরিত্রহীন বড়লোক ছেলের চেয়ে চরিত্রবান মধ্যবিত্ত ছেলে ভালো।',\n",
              " 'স্বামী স্ত্রীর একে অপরকে সহযোগিতা করা উচিত। ',\n",
              " 'আত্মসম্মান নিয়ে বাঁচতে শেখা উচিত।',\n",
              " 'অন্যের সাথে কথা হচ্ছে। ',\n",
              " 'ভালোবাসার নামে পেইন দেয়া উচিত না। ',\n",
              " 'প্রেম না তার মায়ায় পড়েছি। ',\n",
              " ' খোলা চুলে তাকাতো সে। ',\n",
              " 'কখন কার প্রতি ভালোবাসা আসে তা কেউ বলতে পারে না। ',\n",
              " 'প্রেমে জোর না থাকলে তা একদিন শেষ হয়ে যাবে। ',\n",
              " 'মনের মানুষ একটাই হয়। ',\n",
              " 'নামাজ পড়লেই হয় না , ঈমান থাকাটা দরকার। ',\n",
              " 'কিছু না বলা কখনও কখনও সর্বাধিক বলে।',\n",
              " 'নিজের দোষ অন্যের উপর চাপিয়ে দেয়া।',\n",
              " 'যে যত যে জিনিসে হোঁচট খেয়েছি সে ততো জিনিসটার মর্ম বোঝে।',\n",
              " 'ভালোবাসাতে মানুষের জন্য  মনের  টান থাকা দরকার।',\n",
              " ' কাউকে  পাওয়ার  অতি  আগ্রহ ',\n",
              " 'আকাশ  পাতাল  পার্থক্য ',\n",
              " 'মনের ইচ্ছা পূরণ  না  করার  বেদনা ',\n",
              " 'ভালোবাসায় দেয়া সেরা উপহার হচ্ছে সময় আর শ্রদ্ধা।',\n",
              " ' নিজের কাছে নিজে আগে ভালো হতে পারাটা গুরুত্বপূর্ণ।',\n",
              " 'সময় পরিবর্তনশীল।',\n",
              " ' কথার ধরন বোঝা কঠিন।',\n",
              " 'জোর করে ভালোবাসা পাওয়া যায় না।',\n",
              " 'বৃদ্ধ বয়সে কাউকে পাশে চাওয়ার ইচ্ছা।',\n",
              " ' চাকরি পেয়ে সংসার করার তীব্র ইচ্ছা',\n",
              " ' বিপরীত আকর্ষণ। ',\n",
              " 'প্রেমে ছেকা',\n",
              " 'নিজের উপর আত্মবিশ্বাস রাখতে হবে। ',\n",
              " 'খারাপ অবস্থা মানুষের জীবন থেকে অনেক মূল্যবান জিনিস ও নিয়ে যায়.',\n",
              " 'লক্ষ্য স্থির থাকলে সেটা আপনি পাবেনই। ',\n",
              " 'প্রতারক, ভন্ড ও চরিত্রহীনদের মুখে মধু অন্তরে বিষ থাকে.',\n",
              " 'বেঁচে থেকেও যে নেই , তা মেনে নেয়া অনেক কঠিন। ',\n",
              " 'সৃষ্টিকর্তার উপর ভরসা রাখতে হবে , মানুষের উপর না। ',\n",
              " 'প্রেমিকার দায়িত্ব কি হওয়া উচিত?',\n",
              " 'একসাথে থাকতে চেয়েও এক না হতে পারার কষ্ট অনেক।',\n",
              " 'অতিরিক্ত ভালোবাসতে পারা মানুষজন অনেক  শক্ত হয়। ',\n",
              " ' যে তোমার কষ্টের মূল্য দিবে তাকে আগলে রাখা উচিত। ',\n",
              " 'নিজে আয় করার তৃপ্তি অনেক। ',\n",
              " 'যে চলে গেছে তাকে যেতে দেয়। ',\n",
              " 'যে কষ্ট পাই সেই শুধু কষ্টের মৰ্ম বুঝে। ',\n",
              " 'মিথ্যা অভিনয়। ',\n",
              " 'বাংলা  হওয়া উচিত আমাদের অভিজাত ভাষা , বাংলা ইংরেজি মিলে নয়। ',\n",
              " 'নিজের উপর আত্মবিশ্বাস রাখতে হবে। ',\n",
              " 'খোঁচাখুঁচির সম্পর্কগুলো অনেক মিষ্টি হয়। ',\n",
              " 'কারো অনুপস্থিতিতেও কাউকে ভালোবাসা যায়।',\n",
              " 'কষ্টের ও সীমা আছে। ',\n",
              " ' মানুষ সব সময় একরকম থাকে না। ',\n",
              " 'নিজের উপর বিশ্বাস রাখতে হবে। ',\n",
              " 'ভাষার প্রতি শ্রদ্ধা। ',\n",
              " 'গুরুত্ব থাকলে দূরত্বটাও কমে যায়। ',\n",
              " 'মানুষ ভালো জিনিসের অপেক্ষায় থাকে। ',\n",
              " 'কিছু মানুষকে চাওয়া আর না চাওয়া একই কথা। ',\n",
              " 'নিজেকে ভালো রাখার জন্য নিজের কষ্ট গুলো গোপন করে রাখাটাই শ্রেয়।',\n",
              " 'বন্ধু অনেক ধরণের হয়। ',\n",
              " 'বলা আর করা এক নয়। ',\n",
              " 'ভালো থাকার অভিনয় করা মানুষগুলোর উপর মায়া লাগে। ',\n",
              " 'অনেক খারাপ মানুষের ভীড়েও একজন  ভালো মানুষ থাকে। ',\n",
              " 'নরম মানুষের উপর সবাই ঝাঁপিয়ে পরে। ',\n",
              " ' গায়ের রং দেখে কাউকে বিচার করা উচিত না। ',\n",
              " ' মানুষকে চিনতে শিখুন। ',\n",
              " ' সুযোগ পেলে অপমান করা মানুষ কখনো বন্ধু হতে পারে না। ',\n",
              " ' সবচেয়ে বেশি অভিনয় আমরা নিজের সাথে করি। ',\n",
              " ' আসল মানুষকে চেনা দরকার। ',\n",
              " ' সবার একটি হিংসুটে প্রেমিক থাকা দরকার। ',\n",
              " ' আবেগকে কমিয়ে ফেলা উচিত। ',\n",
              " ' নিজের কষ্ট কাউকে অনেক সময় বলতে ইচ্ছে করে না। ',\n",
              " ' জীবনসঙ্গীর কষ্টটাকে মেনে নিতে হবে। ',\n",
              " ' কিছু চাওয়া পাওয়াবিহীন সম্পর্ক থাকে। ',\n",
              " '  সময়ের সাথে অসংখ্য ভার্চুয়াল সম্পর্ক হারিয়ে যায়',\n",
              " 'নিজেই নিজের জীবনকে বদলাতে পারেন।',\n",
              " 'স্যাপিওস্যাক্সুয়াল মানুষগুলো বুদ্ধিদীপ্ত হয়।',\n",
              " ' যোগ্যতা দিয়ে ভালোবাসা হয়না।',\n",
              " 'সৃষ্টির সৌন্দর্যই প্রকৃত সৌন্দর্য।',\n",
              " 'ভালোবাসার মানুষের চাওয়া পাওয়ার মূল্য দেয়া। ',\n",
              " 'সবার কাছে ভালো থাকার প্রয়োজন নেই। ',\n",
              " 'থেকেও না থাকার কষ্ট অনেক বেশি। ',\n",
              " 'মনের \\u200cকথা বলতে না পারায় অনেক মানুষ জীবন থেকে চলে যায়।',\n",
              " 'স্কুল লাইফের বন্ধু আসল বন্ধু।',\n",
              " 'একা বেঁচে থাকা শিখা উচিত। ',\n",
              " 'যে চলে যাওয়ার সে চলে যাবেই।',\n",
              " 'অনেক সময় কষ্টের কথা বলা যায় না। ',\n",
              " 'নিজের ইচ্ছা শক্তিই আসল।',\n",
              " 'একটি মানুষের ভিতরে দুই রকমের স্বভাব থাকতে পারে। ',\n",
              " 'অন্যকে কষ্ট দেয়ার চেয়ে নিজে  কষ্টে থাকা ভালো। ',\n",
              " 'নারীরা যেমন ভালোবাসতে জানে তেমনি ঘৃণা করতেও জানে।   ',\n",
              " 'ভালোবাসার জন্য একটি  মানুষই যথেষ্ট। ',\n",
              " 'ভালোবাসা হওয়া উচিত মহান। ',\n",
              " 'হাসি খুশি থাকার মাধ্যমে কথা গোপন করা যায়.',\n",
              " 'মানুষ চিরস্থায়ী জীব.',\n",
              " 'যোগাযোগ থাকলে মানুষের সম্পর্কে পায় পূর্ণতা। ',\n",
              " 'মিথ্যা ভালোবাসা থেকে বিরত থাকাটা উত্তম। ',\n",
              " 'মনকে ভালো রাখার দায়িত্ব নিজের।',\n",
              " 'ভালোবাসা দেয়ার জন্য কোনো নিদৃষ্ট মানুষের থাকাটা প্রয়োজন',\n",
              " nan,\n",
              " 'একাকিত্ব মানুষকে অনেক কিছু শিখায়। ',\n",
              " 'প্রত্যেক মানুষেরই একটা জীবন রয়েছে। ',\n",
              " 'কাউকেও ভালোবাসলে মন থেকে ভালোবাসা উচিৎ। ',\n",
              " 'ভালোবাসায় কষ্ট পাওয়াটা স্বাভাবিক। ',\n",
              " 'মেয়েদের মন বোঝা কঠিন। ',\n",
              " 'জেদ ভালোবাসাকে ধ্বংস করে। ',\n",
              " 'কাউকেও কোনো কিছুর মধ্যে আটকিয়ে রেখোনা। ',\n",
              " 'সমস্যার মুখোমুখি হওয়ার জন্য নিজেকে শক্ত  করো প্রয়োজন। ',\n",
              " 'ভালোবাসা বলার থেকে তা অনুভব করাটা জরুরী। ',\n",
              " 'কোনো কিছু না বলে শুধু ভালোবেসে যাওয়া অনেক বেশি সুন্দর।',\n",
              " 'একই পরিস্থিতির মধ্যে দিয়া কেউ না গেলে ,কেউ কখনো কারো কষ্ট বুঝে  না। ',\n",
              " 'মেয়েরা পুরুষদের  সম্পত্তি নয়  , তাদের সম্পদ',\n",
              " 'কষ্ট পেতে পেতে মানুষের গায়ে সয়ে যায় একদিন। ',\n",
              " 'কাছের মানুষকে সারাজীবন সাথে থাকার ভরসা দিন।',\n",
              " 'ভালোবাসার কোন নির্দিষ্ট দিবস নেই',\n",
              " 'ভালোবাসা  মানে দায়িত্ব, ভরসা, বিশ্বাস, প্রতিশ্রুতি রক্ষা করা।',\n",
              " 'পছন্দের মানুষ সারাজীবন সিঙ্গেল থাকুক,তাতেই শান্তি। ',\n",
              " 'খাওয়া ছাড়া কিচ্ছু না জীবনে',\n",
              " 'দুনিয়াতে সবাই পারফেক্ট হয়না, নিজের জন্য পারফেক্ট মানুষ নিজেকেই খুঁজে নিতে হয়। ',\n",
              " 'সময় চলে যায়।',\n",
              " 'প্রিয় মানুষ হতে হলে ,তার মন বুঝতে হবে আগে। ',\n",
              " 'মুভ অন করা মানে সব কিছু মেনে নিয়ে নতুন করে নিজেকে গুছিয়ে নেয়া',\n",
              " 'যাকে ভালো লাগে তার সব কিছুই ভালো লাগে। ',\n",
              " 'জীবনে কোনো কিছুই স্থায়ী না। ',\n",
              " 'ইচ্ছা থাকলে উপায় হয়। ',\n",
              " 'অধিকার হারানোর চেয়ে কষ্টের জিনিস আর কিছুই নাই। ',\n",
              " 'নিজেকে ভালোবাসতে শেখ। ',\n",
              " 'স্মৃতি গুলা ছড়িয়ে যাক। ',\n",
              " 'জীবনে কারো কথা শুনার জন্য হলেও কাউকে পাশে দরকার। ',\n",
              " 'জীবনে যেকোনো কাজই এমন ভাবে করা উচিত যাতে ঐটায় সেরা হওয়া যায়। ',\n",
              " 'এমন মানুষের সাথে আপনার প্রেম থাকবে যে আপনি নিজেও জানবেন না।',\n",
              " 'ছেলে মেয়ে সবাই সমানভাবে বাহিরে কাজ করতে পারা উচিত।',\n",
              " 'বেস্ট ফ্রেন্ড থাকা মানে অনেক কিছু।',\n",
              " 'বিচ্ছেদ মানুষকে শক্ত করে তুলে।',\n",
              " 'আল্লাহ যা করেন আমাদের ভালোর জন্যই করেন।',\n",
              " 'নারী চায় পুরুষের শেষ প্রেমিকা হতে।',\n",
              " 'জীবনতো  একটাই। ',\n",
              " 'টম এবং জেরী বিনোদনের একটি বড় মাধ্যম। ',\n",
              " 'মেয়েদের উত্তম পোশাক হলো শাড়ী। ',\n",
              " 'চুপচাপ মানুষগুলাও অনেক কথা বলতে চায়। ',\n",
              " 'আপনজনদের আগলে রাখতে শিখুন। ',\n",
              " 'মানুষ অবভ্যাসের দাস। ',\n",
              " 'সব মেয়ের জন্যই কেউ না কেউ রয়েছে।',\n",
              " 'ক্রিকেটের কাহিনী। ',\n",
              " 'সম্পক যত্ন করে রাখা উচিত। ',\n",
              " 'পুরোনো স্মৃতি গুলো মধুর হয়। ',\n",
              " 'কখনো হার মানা যাবে না।',\n",
              " 'অর্থবিত্তের জন্য প্রতিভা চাপা পরে যায়। ',\n",
              " 'ভালোবাসার জন্য লড়াই। ',\n",
              " ' বিশ্বাস অবিশ্বাসের  খেলায় দিনশেষে অবিশ্বাস ই জিতে যায়।',\n",
              " 'সকল মানুষের  দৃষ্টিভঙ্গি আলাদা। ',\n",
              " 'চেষ্টা থাকলে উপায় হয় ',\n",
              " 'ইচ্ছা থাকলেই মনের ইচ্ছা পূরণ করা যায় না',\n",
              " 'কীর্তিমানের মৃত্যু নেই',\n",
              " 'নারীর ঘৃণা  মেনে মেনে নেয়া অনেক কঠিন। ',\n",
              " 'নিজেকে বিশ্বাস করো',\n",
              " 'সত্যিকারের ভালোবাসা কখনো ভুলা যায় না',\n",
              " 'সবাই বন্ধু হতে পারে না',\n",
              " ' সত্যিকারের ভালোবাসা অমর ',\n",
              " 'ভাই বোনের সম্পর্ক অটুট',\n",
              " 'তুমি যাকে  চাও তার কাছে নয় , যে তোমাকে চায় তার কাছে যাও। ',\n",
              " 'কথা না থাকার পরও কথা হয়েছিল। ',\n",
              " 'যখন যার দরকার হয় তখন তাকে পাওয়া যায় না',\n",
              " ' যখন যার প্রয়োজন তখন তাকে পাশে পাবেন না। ',\n",
              " 'নিজেকে সব পরিস্থিতিতে মানিয়ে নেওয়া শিখতে হবে। ',\n",
              " 'কখনো  কখনো  আত্মসম্মান নষ্ট করার চেয়ে নিজের কথা চিন্তা করা অনেক ভালো। ',\n",
              " 'সবার জীবনেই কেউ না কেউ আসবে।',\n",
              " 'মানুষের বিবেকবোধ নেই বললেই চলে। ',\n",
              " 'ভালোবাসা হলো সে যেমন তাকে তেমন ভাবেই ভালোবাসা।',\n",
              " 'প্রত্যেক মানুষেরই কোনো  না কোনো সঙ্গী থাকা  প্রয়োজন।',\n",
              " 'ভালোবাসার জন্য কোনো নিদৃষ্ট  দিনের প্রয়োজন হয় না। ',\n",
              " 'কখনো কখনো সময়ের সাথে সাথে মানুষগুলোই বদলে যায়। ',\n",
              " 'করো জন্য অপেক্ষা করার দরকার নেই। ',\n",
              " 'মানুষের পরিবর্তন হয়। ',\n",
              " 'কিছু মানুষ হুদাই সারারাত জেগে থাকে।',\n",
              " 'নারীরাই নারী জাগরণের প্রধান অন্তরায়',\n",
              " 'এই বঙ্গদেশের কিছু-কিছু আইন দেখে ঠাহর করা যায় না— এটি কত সাল; ২০১৪, না ১৯২১?',\n",
              " 'বাংলাদেশের বিশ্ববিদ্যালয়গুলো তথা গোটা বাংলাদেশ এখন আটকে আছে পঁচিশ পয়সার বৃত্তেই',\n",
              " 'এককালে আমরা প্রযুক্তিকে নিয়ন্ত্রণ করতাম, এখন প্রযুক্তিই আমাদেরকে নিয়ন্ত্রণ করছে',\n",
              " 'আদালত-চত্বরে এই ভুয়া ধর্ষিতাদের দৌরাত্ম্যে প্রকৃত ধর্ষিতারা বিচারবঞ্চিত হন',\n",
              " 'নারীর উপর নারীর নির্যাতন।  ',\n",
              " 'নারীরাই নারী জাগরণের প্রধান অন্তরায়',\n",
              " 'একজন নারীর হাতেও একজন নারী নিরাপদ না। ',\n",
              " 'নারীর অন্যতম শত্রূ নারীই',\n",
              " 'বর্তমানে পাঠকের চাইতে লেখকের সংখ্যা বেশি',\n",
              " 'বই শব্দটাকে পচিয়ে ছেড়েছে মৌসুমি লেখকের পাল',\n",
              " 'লেখক এর লেখা চুরি হয়ে যাওয়াঅবশ্যই কষ্টকর ও \"শাস্তিযোগ্য',\n",
              " 'সুশীলরা বরাবরই দর্শক-পাঠকের মনোরঞ্জনে মাতোয়ারা',\n",
              " 'আমাদের ইতিহাস দাসত্বের ইতিহাস।',\n",
              " 'কাতুকুতু দিয়ে লোক হাসানো যায়, লোক কাঁদানো যায় না',\n",
              " ' ৯ মাসে স্বাধীনতা পেয়ে যাওয়ায় এই সোনামাছ জাতি স্বাধীনতার মাহাত্ম্য বোঝেনি',\n",
              " 'এখনও অনেক বেঈমান এর মনে পাকিস্তান প্রীতি আছে',\n",
              " 'লেখার ক্ষেত্রে একজন লেখককে ভীষণ সৎ হতে হয়',\n",
              " 'মিথ্যে প্রশংসা কবিকে এতটাই বিভ্রান্ত করে যে,কোনো সত্যিকারের  প্রশংসাও তখন কবির কাছে মিথ্যে মনে হয়',\n",
              " 'লেখকের অসততা ধরা পড়ার পর পাঠকরা  মুখ ফিরিয়ে নেন',\n",
              " 'স্কুল জীবন মানুষ এর জীবন এর সব চাইতে সুন্দর সময়',\n",
              " 'বাংলার ইতিহাসে মহানায়কদের  একজন ছিলেন মাওলানা আব্দুল হামিদ খান ভাসানী',\n",
              " 'মানুষ আগেও পশু ছিলো এখনোও তাই। আগে শুধু প্রকাশ হতোনা, এখন হয়। পার্থক্য এখানেই',\n",
              " 'হবু মায়ের প্রতি চাই সহকর্মীদের সহযোগিতা।',\n",
              " 'মিথ্যাচার করে খুশি করার চেয়ে, সত্য বলে দুঃখ পাওয়া শ্রেয়',\n",
              " 'সকলের প্রতি সহ মর্মিতা ইসলাম আমাদের শিক্ষা দেয়',\n",
              " 'কিশোর বয়সের চাঞ্চল্য সব কিছুকে হার মানায়',\n",
              " 'কিশোর বয়সের চাঞ্চল্য সব কিছুকে হার মানায়',\n",
              " 'বই চুরি খারাপ নাহ তবে কারো মনে কষ্ট দিয়ে করা যাবে না ',\n",
              " 'চোরের দশ দিন তো গৃহস্থের এক দিন',\n",
              " 'দুনিয়াতে যাই ঘটুক কারো কারো কাজ হচ্ছে শুধু উপভোগ করা',\n",
              " 'বন্ধু শব্দটা যেমন পবিত্র তেমনি পবিত্র তার ধর্ম',\n",
              " 'বন্ধু শব্দটা যেমন পবিত্র তেমনি পবিত্র তার ধর্ম',\n",
              " nan,\n",
              " 'ভালোবাসা সব ভালো মানুষ এর জন্য উন্মুক্ত না',\n",
              " 'বেঁচে থাকার জন্য সামান্য সামান্য কারনই যথেস্ট',\n",
              " 'গৌতম বুদ্ধ একজন জ্ঞানী',\n",
              " 'অ্যালকোহল বা ক্লোরিন শরীরের ভেতরে থাকা ভাইরাসের কিছুই করতে পারে না।',\n",
              " 'করোনা ভাইরাসে আক্রান্ত হবার সম্ভাবনা বয়-বৃদ্ধ, শিশু- কিশোর সবার আছে',\n",
              " 'করোনা ভাইরাসে উপসর্গ অনেকটাই ফ্লু জাতীয় ',\n",
              " 'করোনা ভাইরাসের মৃত্যু হার অনেক কম।',\n",
              " 'করোনা বিস্তারের জন্য যেকোনো বাহকই যথেষ্ট',\n",
              " 'করোনা ভাইরাস প্রতিরোধে মাস্ক এর পাশাপাশি সচেতনতাও জরুরী।',\n",
              " 'থার্মাল স্ক্যানারের মাধ্যমে করোনাভাইরাসের উপস্থিতি নির্ণয় সম্ভব',\n",
              " 'পুরান ঢাকা, ঢাকার সবচাইতে পুরাতন ইতিহাস বহন করে বয়ে চলছে।',\n",
              " 'নবাবপুর নামেও নবাব কাজেও নবাব। রাজা বাদশাহরা এই নবাবপুর হয়ে বিভিন্ন শহরে যাতায়াত করতেন। ',\n",
              " 'সূত্রাপুরে দারুশিল্প নির্মাণে সূত্রধররা বসবাস করতেন।',\n",
              " nan,\n",
              " 'কেউ ছেড়ে গেলে জীবন থেমে থাকে না',\n",
              " ' ভালোবাসা  অসীম',\n",
              " ' চুপ থাকাটাও অনেক কষ্টের।   ',\n",
              " ' কারো ব্যাক্তিত্বকে ভালোবাসা',\n",
              " ' নিজেকে নিয়ন্ত্রণ করা জানতে হবে। ',\n",
              " 'নিজেকে নিজেরই গুছিয়ে নিতে হয়',\n",
              " 'ভালোবাসা  মানে  জোর  করে  আটকে  রাখা  না  ভালোবাসা  মানে  তাকে  ছেড়ে  দেয়াও। ',\n",
              " 'পাশে থাকার  মতো  একটি  বন্ধুই  যথেষ্ট। ',\n",
              " 'ভালোবাসার সম্পর্ক গুলো ভালো থাকুক',\n",
              " ' ডেটিং এ যাওয়ার কিছু নিয়ম। ',\n",
              " 'ভালোবাসায় বিশ্বাস থাকা জরুরি। ',\n",
              " ' দাঁত  থাকতে দাঁতের মর্ম বোঝে না। ',\n",
              " ' নিজে ভালোতো জগৎ ভালো। ',\n",
              " 'না বলা ভালোবাসায় আসল ভালোবাসা। ',\n",
              " ' দৃষ্টিভঙ্গি বদলালে, জীবন বদলে যাবে।',\n",
              " ' ভালোবাসার মানুষকে অল্প দিয়েও খুশি করা যায়। ',\n",
              " ' ভালোবাসার জন্য কোনো কারণ লাগে না। ',\n",
              " ' মেয়েরা চাইলে সব করতে পারে। ',\n",
              " ' চেষ্টা না করেই হারমানা  উচিত না। ',\n",
              " ' ভালো সময় গুলো  কিছু ভালোবাসার মানুষের সাথে কাটালে মনটা আরো ভালো হয়ে যায়। ',\n",
              " ' যে তোমাকে গুরুত্ব দিবে না , তাকে গুরুত্ব দেওয়ার প্রয়োজন নেই। ',\n",
              " 'ভালোবাসা একবার নষ্ট হয়ে গেলে তা আর ফেরানো যায় না।',\n",
              " ' একাকীত্বতা অনেক কষ্টের। ',\n",
              " ' কাউকে পেতে হলে অনেক কষ্ট করে পেতে হয়।',\n",
              " 'কাউকে ভালো লাগলে তাকে বলে দিতে হয় তাহলে সারা জীবন আফসোস করতে হয়।',\n",
              " ' ভালোবাসতে জানলে ভালোবাসতে শেখো।',\n",
              " ' যত বড় হচ্ছি জীবনে ভুলের মাত্রা বেড়ে যাচ্ছে',\n",
              " ' অবহেলা মানুষের পিছু ছাড়ে না। ',\n",
              " 'মন মরে গেছে এটা বোঝার উপায়।',\n",
              " ' সব দিক দিয়ে বেস্ট হতে হবে না আমাকে ভালোবাসলেই হবে। ',\n",
              " ' ভালো বন্ধু পাওয়া ভাগ্যের ব্যাপার। ',\n",
              " 'কখনো আত্মসম্মান নষ্ট করতে নেই। ',\n",
              " ' এক্সদের  বিয়া হয়ে যাওয়া ভালো। ',\n",
              " ' সবারই মন আছে , তাই প্রেম করতে ইচ্ছা করে। ',\n",
              " ' এক সময় মনে হবে আপনি আগে অনেক বোকামি করতেন। ',\n",
              " ' আগামী কালের জন্য আমরা সব কিছু ফেলে রাখি।',\n",
              " ' মানুষ গুলো একই থাকে শুধু সময়টা বদলে যায়',\n",
              " ' ভালোবাসার মানুষকে এখন সবাই \"প্রাক্তন\" নাম জানে। ',\n",
              " ' কারো জন্য অপেক্ষা করে লাভ নেই। ',\n",
              " 'কিছু মানুষ  কোনো কারণ ছাড়াই সারারাত জেগে থাকে ',\n",
              " ' প্রেম করিনি , ভালোবেসেছি। ',\n",
              " ' জোর করে না ভুলার চেষ্টা  করার  দরকার নেই , একদিন এমনেই ভুলে যাবেন। ',\n",
              " 'অতিমুনাফার জন্য মাস্ক মজুদ করে রাখা। ',\n",
              " 'হ্যান্ড স্যানিটাইজার পিছনে না ছুটে সাবান দিয়ে হাত পরিষ্কার করুন ।',\n",
              " ' প্রেম নয় ভালোবাসা দরকার। ',\n",
              " 'নারীদের প্রতি সম্মান দেখানো উচিত। ',\n",
              " 'মন থেকে নারীর প্রতি সম্মান থাকতে হবে , ফেসবুকে স্ট্যাটাস দিয়ে নয়। ',\n",
              " 'নারীর সমান অধিকার চাওয়া হয়েছে। ',\n",
              " ' অন্যকে জাজমেন্ট না করে  নিজের সময়কে কাজে লাগান। ',\n",
              " 'আমরা নারীরা , চাইলেই সব পারি। ',\n",
              " ' নারীকে সম্মান করা উচিত বছরের প্রতিটি  দিনই।',\n",
              " ' ছোটখাটো ভুলের জন্য সম্পর্ক নষ্ট হয়ে যায়। ',\n",
              " 'নারী দিবেস বিশ্বের সকল নারীকে  শুভেচ্ছা জানানো হয়েছে । ',\n",
              " 'টাকা খরচ ছেলেদের কাজ না , মেয়েরা ছেলেদের পিছনে টাকা খরচ  করতে পারে। ',\n",
              " ' নারীরা নিজেকে নিয়ন্ত্রণ করতে পারলে পুরুষের ও উচিত নিজেকে নিয়ন্ত্রণ  করা। ',\n",
              " ' চিঠি দিয়ে প্রেম করার মজাই আলাদা। \\n',\n",
              " ' মেয়েদের পড়াশোনা করানো উচিত',\n",
              " ' একুশ বছরের মেয়েদের প্রেম করা মানা কারণ তাকে বিয়ে করতে হবে ঐসময়।',\n",
              " ' বাস্তবতা আর সিনেমা এক নয়। ',\n",
              " 'ভালো মানুষের দাম নাই',\n",
              " '  বঙ্গবন্ধুর ৭ মার্চের ভাষণ।',\n",
              " ' সৌন্দর্য শুধু উপর দিয়ে হয় না , ভিতরের  সৌন্দর্য আসল সৌন্দর্য',\n",
              " ' যার মন ভালো সেই প্রকৃত  সুন্দর',\n",
              " ' অল্পতেই সুখী হওয়া যায়।',\n",
              " '  মনুষ্যত্বহীন মানুষ কখনো ভাল মানুষ হতে পারে না।',\n",
              " ' মানুষ যা চায় তা পায় না',\n",
              " ' ধর্যের ফল মিষ্টি হয়',\n",
              " ' মনের কথা শোনার  মতো কেউ থাকে না। ',\n",
              " ' খারাপ অবস্থায় যে ভালোবাসে সেই ভালোবাসা  আসল। ',\n",
              " ' দোষ না করেও যে স্যরি বলে, তাকে ধরে রাখুন। ',\n",
              " ' পাশের বাড়ির ছেলে মেয়েরা অনেক ভালো রেজাল্ট করে ',\n",
              " ' ফ্যামিলির্ উপর আপনজন আর কেউই নেই।',\n",
              " ' বিয়ের পর রোমান্টিক না হওয়ার অভিযোগ।',\n",
              " ' ভালোবাসা পাল্টায় না, প্রকাশ এর ধরণ পাল্টায়',\n",
              " ' করোনা ভাইরাস সম্পর্কে কিছু কথা। ',\n",
              " ' ভালোবাসার গভীরতা',\n",
              " ' ভালোবাসা কাকে বলে সে চিনে। ',\n",
              " ' কেউ একজন আসবে  যে সবার মতো থাকবে না',\n",
              " ' তুমি না থাকলে ভালোবাসা জন্মতোই না',\n",
              " ' প্রযুক্তির যুগে এসে  নাটকের সব ইমোশন গুলা নষ্ট করে দিয়েছে। ',\n",
              " ' কারো প্রতি নির্ভরশীল হওয়া যাবে না',\n",
              " 'অভিমানের চেয়ে খারাপ কিছু আর হতে পারে না',\n",
              " ' ভালো লাগার কোনো কারণ নেই',\n",
              " ' যে আপনাকে খুশি করতে চাবে  ,এর থেকে সুখ আর কিছুই  নেই',\n",
              " ' কুসংস্কার থেকে মেয়েদের মুক্তি দিতে হবে।',\n",
              " ' ছোটখাটো জিনিস এর মধ্যে ভালোবাসা থাকে',\n",
              " ' ভালোবাসতে হলে আগে সব হিসাব করেই ভালোবাসতে হবে',\n",
              " ' এমন মানুষ দরকার যে সারাজীবন পাশে থাকবে',\n",
              " ' ভালোবাসার মানুষের সব খবর রাখা ,সে কার সাথে কথা বলে চলে',\n",
              " ' ভালোবাসা ভাঙ্গার কষ্ট অনেক ',\n",
              " ' ভালোবাসা কখনো ভোলা যায়  না। ',\n",
              " ' সারাদিন কষ্ট করে ভালোবাসার মানুষের ছোট চাওয়া।',\n",
              " ' দৃষ্টিভঙ্গি পরিবর্তন করুন।',\n",
              " ' এমন কেউ থাকে যারা শুধু মানুষকে ভালো রেখেই যায়। ',\n",
              " ' ভালোবাসি কোঠাটান বলার জন্য ও একজন মানুষ দরকার। ',\n",
              " ' বেশি কিছু ছাড়াও  সুখী হওয়া যায়। ',\n",
              " ' কাউকে  পাওয়ার আকুল বাসনা। ',\n",
              " ' ভালোবাসতে হবে না ,আমি ভালোবেসে যাই। ',\n",
              " ' এই প্রজন্ম থেকে কোনো বুদ্ধিজীবী পাওয়া কঠিন। ',\n",
              " '৩ মার্চ এর তাৎপর্য',\n",
              " ' পাবনা জেনেও  ভালোবেসে যাওয়া। ',\n",
              " ' এক্সদের  বিয়া হয়ে যাওয়া ভালো। ',\n",
              " ' সবারই মন আছে , তাই প্রেম করতে ইচ্ছা করে। ',\n",
              " ' এক সময় মনে হবে আপনি আগে অনেক বোকামি করতেন। ',\n",
              " ' আগামী কালের জন্য আমরা সব কিছু ফেলে রাখি।',\n",
              " ' মানুষ গুলো একই থাকে শুধু সময়টা বদলে যায়',\n",
              " ' ভালোবাসার মানুষকে এখন সবাই \"প্রাক্তন\" নাম জানে। ',\n",
              " ' কারো জন্য অপেক্ষা করে লাভ নেই। ',\n",
              " 'কিছু মানুষ  কোনো কারণ ছাড়াই সারারাত জেগে থাকে ',\n",
              " ' প্রেম করিনি , ভালোবেসেছি। ',\n",
              " ' জোর করে না ভুলার চেষ্টা  করার  দরকার নেই , একদিন এমনেই ভুলে যাবেন। ',\n",
              " 'অতিমুনাফার জন্য মাস্ক মজুদ করে রাখা। ',\n",
              " 'হ্যান্ড স্যানিটাইজার পিছনে না ছুটে সাবান দিয়ে হাত পরিষ্কার করুন ।',\n",
              " ' প্রেম নয় ভালোবাসা দরকার। ',\n",
              " 'নারীদের প্রতি সম্মান দেখানো উচিত। ',\n",
              " 'মন থেকে নারীর প্রতি সম্মান থাকতে হবে , ফেসবুকে স্ট্যাটাস দিয়ে নয়। ',\n",
              " 'নারীর সমান অধিকার চাওয়া হয়েছে। ',\n",
              " ' অন্যকে জাজমেন্ট না করে  নিজের সময়কে কাজে লাগান। ',\n",
              " 'আমরা নারীরা , চাইলেই সব পারি। ',\n",
              " ' নারীকে সম্মান করা উচিত বছরের প্রতিটি  দিনই।',\n",
              " ' ছোটখাটো ভুলের জন্য সম্পর্ক নষ্ট হয়ে যায়। ',\n",
              " 'নারী দিবেস বিশ্বের সকল নারীকে  শুভেচ্ছা জানানো হয়েছে । ',\n",
              " 'টাকা খরচ ছেলেদের কাজ না , মেয়েরা ছেলেদের পিছনে টাকা খরচ  করতে পারে। ',\n",
              " ' নারীরা নিজেকে নিয়ন্ত্রণ করতে পারলে পুরুষের ও উচিত নিজেকে নিয়ন্ত্রণ  করা। ',\n",
              " ' চিঠি দিয়ে প্রেম করার মজাই আলাদা। \\n',\n",
              " ' মেয়েদের পড়াশোনা করানো উচিত',\n",
              " ' একুশ বছরের মেয়েদের প্রেম করা মানা কারণ তাকে বিয়ে করতে হবে ঐসময়।',\n",
              " ' বাস্তবতা আর সিনেমা এক নয়। ',\n",
              " 'ভালো মানুষের দাম নাই',\n",
              " '  বঙ্গবন্ধুর ৭ মার্চের ভাষণ।',\n",
              " ' সৌন্দর্য শুধু উপর দিয়ে হয় না , ভিতরের  সৌন্দর্য আসল সৌন্দর্য',\n",
              " ' যার মন ভালো সেই প্রকৃত  সুন্দর',\n",
              " ' অল্পতেই সুখী হওয়া যায়।',\n",
              " '  মনুষ্যত্বহীন মানুষ কখনো ভাল মানুষ হতে পারে না।',\n",
              " ' মানুষ যা চায় তা পায় না',\n",
              " ' ধর্যের ফল মিষ্টি হয়',\n",
              " ' মনের কথা শোনার  মতো কেউ থাকে না। ',\n",
              " ' খারাপ অবস্থায় যে ভালোবাসে সেই ভালোবাসা  আসল। ',\n",
              " ' দোষ না করেও যে স্যরি বলে, তাকে ধরে রাখুন। ',\n",
              " ' পাশের বাড়ির ছেলে মেয়েরা অনেক ভালো রেজাল্ট করে ',\n",
              " ' ফ্যামিলির্ উপর আপনজন আর কেউই নেই।',\n",
              " ' বিয়ের পর রোমান্টিক না হওয়ার অভিযোগ।',\n",
              " ' ভালোবাসা পাল্টায় না, প্রকাশ এর ধরণ পাল্টায়',\n",
              " ' করোনা ভাইরাস সম্পর্কে কিছু কথা। ',\n",
              " ' ভালোবাসার গভীরতা',\n",
              " ' ভালোবাসা কাকে বলে সে চিনে। ',\n",
              " ' কেউ একজন আসবে  যে সবার মতো থাকবে না',\n",
              " ' তুমি না থাকলে ভালোবাসা জন্মতোই না',\n",
              " ' প্রযুক্তির যুগে এসে  নাটকের সব ইমোশন গুলা নষ্ট করে দিয়েছে। ',\n",
              " ' কারো প্রতি নির্ভরশীল হওয়া যাবে না',\n",
              " 'অভিমানের চেয়ে খারাপ কিছু আর হতে পারে না',\n",
              " ' ভালো লাগার কোনো কারণ নেই',\n",
              " ' যে আপনাকে খুশি করতে চাবে  ,এর থেকে সুখ আর কিছুই  নেই',\n",
              " ' কুসংস্কার থেকে মেয়েদের মুক্তি দিতে হবে।',\n",
              " ' ছোটখাটো জিনিস এর মধ্যে ভালোবাসা থাকে',\n",
              " ' ভালোবাসতে হলে আগে সব হিসাব করেই ভালোবাসতে হবে',\n",
              " ' এমন মানুষ দরকার যে সারাজীবন পাশে থাকবে',\n",
              " ' ভালোবাসার মানুষের সব খবর রাখা ,সে কার সাথে কথা বলে চলে',\n",
              " ' ভালোবাসা ভাঙ্গার কষ্ট অনেক ',\n",
              " ' ভালোবাসা কখনো ভোলা যায়  না। ',\n",
              " ' সারাদিন কষ্ট করে ভালোবাসার মানুষের ছোট চাওয়া।',\n",
              " ' দৃষ্টিভঙ্গি পরিবর্তন করুন।',\n",
              " ' এমন কেউ থাকে যারা শুধু মানুষকে ভালো রেখেই যায়। ',\n",
              " ' ভালোবাসি কোঠাটান বলার জন্য ও একজন মানুষ দরকার। ',\n",
              " ' বেশি কিছু ছাড়াও  সুখী হওয়া যায়। ',\n",
              " ' কাউকে  পাওয়ার আকুল বাসনা। ',\n",
              " ' ভালোবাসতে হবে না ,আমি ভালোবেসে যাই। ',\n",
              " ' এই প্রজন্ম থেকে কোনো বুদ্ধিজীবী পাওয়া কঠিন। ',\n",
              " '৩ মার্চ এর তাৎপর্য',\n",
              " ' পাবনা জেনেও  ভালোবেসে যাওয়া। ',\n",
              " 'একজন কবি বা লেখকের শেষ জীবন বড়ই কষ্টের',\n",
              " 'মৃত্যুর আগে মানুষকে তার প্রাপ্য সম্মানটুকু দিতে হবে',\n",
              " 'মানুষ নিজের প্রয়োজনে মানুষ কে কাছে টেনে নেয় কাজ শেষে আবার দূরে ছুড়ে ফেলে দেয়',\n",
              " 'নির্বাহী ম্যাজিস্ট্রেটদের বিচারিক ক্ষমতা প্রত্যাহার করে এই ক্ষমতা কেবল জুডিশিয়াল ম্যাজিস্ট্রেটদের হাতে রাখা উচিত ',\n",
              " 'মানুুষ ক্ষেতি পেয়ে নিজের অতীতকে ভুলে যায়',\n",
              " 'কবি হবে বিনয়ী— বিনয়ের ভাণ্ডার',\n",
              " 'কবিিদের এই সমাজে নিরীহ ও তুচ্ছ তাচ্ছিল্যর চোখে দেখা হয়',\n",
              " 'কবিরা দিনশেষে তাদের প্রাপ্য সম্মানী পান না এই দেশে',\n",
              " 'অন্যের মেধা চুরিকারিদের এই দেশে বিচার হয় না',\n",
              " 'এই দেশে কবিদের বাক স্বাধীনতা নেই',\n",
              " 'কবি হবে উদারমনা',\n",
              " 'এই বাংলাদেশ স্বৈরাচারী কবি দেখতে চায় না, বাংলাদেশ কবিকে দেখতে চায় সবাইকে একসাথে খুশি রাখা পতিতারূপে।',\n",
              " 'কবি হবে সর্বজনের ক্রীতদাস',\n",
              " 'বাংলাদেশে কবিকে হতে হবে সর্বরোগবিশেষজ্ঞ',\n",
              " 'করোনার কারনে ইতালি এখন মৃত্যুপুরী',\n",
              " 'গঠনমূলক সমালোচনা মানুষ মেনে নিতে পারে না',\n",
              " 'লেখক হতে চায় কিন্তু পরিশ্রম করতে চায় না',\n",
              " 'লেখক হতেে হলে হতে হবে যোগ্যতাসম্পন্ন লেখক',\n",
              " 'কখন কোথায় কি প্রশ্ন করতে হয় সে সম্পর্কে স্পষ্ট ধারনা থাকতে হবে',\n",
              " 'বাঙালি জাতির বিবেকের চেয়ে আবেগ বেশি কাজের চেয়ে কথা বেশি',\n",
              " 'দিনশেষে আমরা সবাই খুব একা',\n",
              " 'করোোনাতে আক্রান্ত ব্যাক্তির মৃত দেহ দাফন বা সৎকার খুবই বেদনাদায়ক',\n",
              " \"হঠাত করে কাউকে 'আমি কে' প্রশ্ন করা ঠিক না\",\n",
              " 'সত্যি বলতে টেকনােলজিক্যালি ডিলিট বলতে কিছু নেই',\n",
              " 'তিন বিভাগের কর্মকাণ্ডে সমন্বয় থাকলে রাষ্ট্র সুস্থ থাকে, না থাকলে রাষ্ট্র অসুস্থ হয়ে পড়ে।',\n",
              " 'প্রধানমন্ত্রীর নির্দেশ এখন নির্বিষ ও নিরামিষ হয়ে যাচ্ছে।',\n",
              " 'করোনাা ভাইরাসের বেপারে আমাদের অনেক বেশি সচেতন হতে হবে',\n",
              " 'পারসেন্ট আর শতকরা একই কথা',\n",
              " \"সহৃদয়বান' না লিখে 'হৃদয়বান' বা 'সহৃদয়' লিখতে হবে\",\n",
              " 'মূল্য মানেই দাম, দাম মানেই মূল্য',\n",
              " 'কাল মানে সময়, সময় মানে কাল',\n",
              " 'ইভেন অর্থ এমনকি। তাই কথার মাঝে ইভেন ব্যাবহার করা গেলেও ইবেনকি ব্যাবহার ঠিক না',\n",
              " 'লাশ জীবিত হয় না, মৃতই হয়',\n",
              " 'বহুবচন এর সাথে রা, দের বা গুলো যোগ করা যাবে না।',\n",
              " 'মর্নিং ওয়াক মানেই সকালের হাঁটাহাঁটি',\n",
              " \"সকল' কথাটি বললে তৎপরবর্তী শব্দটিকে আর বহুবচন বানানো যাবে না।\",\n",
              " 'রিপিট করা মানেই আবার ঘটানো',\n",
              " \"সাবেক' মানেই 'অতীতে ছিল এমন কিছু'\",\n",
              " \"কনিষ্ঠ মানেই সবচেয়ে ছোট, জ্যেষ্ঠ মানেই সবচেয়ে বড়, এদের সাথে 'তম' যোগ করা যাবে না\",\n",
              " 'বেস্ট মানেই সবচেয়ে ভালো',\n",
              " 'লেটেস্ট মানেই সর্বশেষ',\n",
              " \"ভ্যাকেন্সি মানেই 'খালি\",\n",
              " 'এইদেশের প্রতিটি পদে অযোগ্যদের  অবস্থান',\n",
              " 'এখন লেখক হতে হলে মেধা না দরকার ফ্যান ফলোয়ার',\n",
              " 'লেখকের লেখালেখি কোনো পেশার মধ্যে পড়ে না এই সমাজের চোখে',\n",
              " 'মেধা থাকুক আর না থাকুক আমারা নিজেদের লেখক হিসাবে ধরে নেই',\n",
              " 'লেখক হলেই যে আপনাকে পদক পেতে হবে এমন কোনো বাধ্যবাধকতা নেই',\n",
              " 'লেখকের লেখাালেখি পেশা হিসাবে মেনে নিতে আমাদের সমাজে এখনো অনেক অগ্যতা রয়েছে',\n",
              " 'লেখকদের পদে-পদে অপদস্থ করতে বাঙালি বদ্ধপরিকর',\n",
              " 'কুলখানি নিছক আমাদের নিজেদের বানানো একটা  রীতি',\n",
              " 'মধ্যবিত্ত পরিবারগুলোয় আয়োজন আছে, আড়ম্বর নেই; অনানুষ্ঠানিক আবেগ আছে, আবেগের আনুষ্ঠানিক প্রকাশ নেই',\n",
              " 'মধ্য্যবিত্ত পরিবারের সন্তানেরা তাদের আবেগের সবটুকু প্রকাশ করতে পারে না',\n",
              " 'অসুখ না হলে মধ্যবিত্ত পরিবারের সন্তানের কপালে মায়েদের হাত পড়ে না',\n",
              " ' বিজ্ঞান যুক্তি ও প্রমানের উপর প্রতিষ্ঠিত আর ধর্ম বিশ্বাসের উপর প্রতিষ্ঠিত।',\n",
              " 'কোনো মাধ্যমের মধ্যে চার্জিত কণা(e‐ Electron) সেই মাধ্যমের আলোর বেগ অতিক্রম করে আর নীল আলো ছড়িয়ে দেয়; একেই চেরেনকভ বিকিরণ বা রেডিয়েশন বলা হয়!',\n",
              " 'সেটা অতীতের ভিউ, কেননা আলো পৃথিবীতে আসতে আসতে সময় লাগে, এখন এই তারার সামনে দিয়ে যদি কোন ধূমকেতু বা গ্রহ যায়, তখন আলো বাধাপ্রাপ্ত হবে, মনে হবে মিট-মিট করলো',\n",
              " 'মস্তিষ্ক হল কেন্দ্রীয় স্নায়ুতন্ত্রের একটি অপরিহার্য অংশ যা মানুষের সমস্ত কিছু নিয়ন্ত্রন করে। ',\n",
              " 'ফোটন তড়িৎ চৌম্বকীয় বল বা ক্ষেত্রের সমার্থক। ',\n",
              " \"কোয়ান্টাম তত্ত্বের মূল কথা হচ্ছে, প্রকৃতির উপাদান গুলোকে ভাঙলে মূল কণিকা গুলো অর্থ্যাৎ 'ইলেকট্রন, প্রোটন এবং নিউট্রন' পাওয়া যাবে। কিন্তু স্ট্রিং থিওরি বলে, এই মূল কণিকা গুলো হচ্ছে এক ধরনের তন্তু বা সুতার কম্পন। এই সুতা বা স্ট্রিং গুলোর বিভিন্ন মোডে কম্পনের কারনেই সেগুলোকে কণা হিসেবে আমরা দেখছি। এবং এই কম্পন প্রতিটি পদার্থের জন্য ভিন্ন। তাই প্রতিটি পদার্থই ভিন্ন ধর্ম প্রদর্শন করে। এমনকি প্রতিটি পদার্থের ভরও এই স্ট্রিং গুলোর কম্পনের ওপর নির্ভর করে।\",\n",
              " 'বৃহস্পতি গ্রহ সূর্যকে কেন্দ্র করে ঘুরে না।',\n",
              " 'বিজ্ঞান হোক সহজ, বিজ্ঞান পৌঁছে যাক ঘরে ঘরে।',\n",
              " 'মহাবিশ্বের বিশালতার মাঝে আমরা খুবই ক্ষুদ্র।',\n",
              " '৬৪০ আলোকবর্ষ দূরে পাওয়া গ্রহে বৃষ্টির মতো ঝরে পড়ে লোহা।',\n",
              " 'সূর্যের চারদিকে গ্রহ ঘুরার করণ এই নয় যে, সূর্য থেকে মহাকর্ষ এসে পৌঁছায় বরং স্পেসটাইমের কারণে বাক সৃষ্টি হয়, গ্রহগুলো সেই বাক বেয়ে ঘুরে।',\n",
              " 'আলোর বেগে গতিশীল হলে সময় কেন থেমে যায়',\n",
              " 'মঙ্গল গ্রহের ভিতর ধারনা করা হচ্ছে পানি পাওয়া সম্ভব তা জীবন ধারনের জন্য অনুকুল বলাই বাহুল্য।',\n",
              " 'পাই এর গুরুত্ব অপরিসীম এই মহাবিশ্বে।',\n",
              " 'গ্রহ যেমন বড় তার শক্তি ধারন ক্ষমতা ততবেশি সাথে থিউরি অফ রিলেটিভিটির চমকতো থাকছেই।',\n",
              " 'ব্ল্যাক হোল শক্তির বড় আধাঁর, এর মধ্য দিয়ে আলো বের হবার মতো শক্তি আলোর নেই কারন গ্রাভিটি অনেক ব্ল্যাক হোলের।',\n",
              " 'এটি একটি টেলিস্কোপের নাম সাথে ব্ল্যাক হোলের বিন্দুর নাম।',\n",
              " '২০-৩০ লক্ষ ডিগ্রি কেলভিন তাপমাত্রায় হাইড্রোজেন গ্যাসের পরমাণুগুলো বিচ্ছিন্ন হয় এবং প্রোটন ও ইলেকট্রনের গ্যাস হিসেবে অবস্থান করে',\n",
              " 'এডউইন হাবল\"-এর নাম অনুসারে হাবল টেলিস্কোপের নামকরণ করা হয়েছিল',\n",
              " 'পূর্ণবিকশিত বা ম্যাচুউরড অবস্থায় একটি নক্ষত্র কতদিন বেঁচে থাকবে তা মূলত নির্ভর করে এর শক্তির উপর।',\n",
              " 'ভালোবাসার মানুষ অনেক সময় অনেক ভালোবাসা প্রকাশ করতে পারে না, কিন্তু সে যে ভালোবাসে না তা বলা যাবে না।',\n",
              " 'ভালোবাসার মানুষ কখনোই চায় না নিজের সংগিনীকে ছেড়ে দিতে।',\n",
              " 'আকাশগঙ্গা একটি ছায়াপথ। সৌরজগতের কেন্দ্র সূর্য এই ছায়াপথের অংশ। অর্থাৎ আমরা থাকি এই ছায়াপথে। এটি একটি সর্পিলাকার ছায়াপথ।',\n",
              " 'করোনা ভাইরাস মোকাবিলায় সবার সচেতন থাকতে হবে পাশাপাশি আল্লাহর ইবাদাত করতে হবে।',\n",
              " 'করোনা ভাইরাস এর সবচাইতে বড় ভ্যাক্সিন \"সচেতনতা\"।',\n",
              " 'করোনা ভাইরাস মোকাবিলায় ফেইসবুকের সঠিক ব্যবহার বাধ্যতা মুলক।',\n",
              " 'ভারত বর্তমান ক্রিকেট এর বিধাতা',\n",
              " 'নিজেদের প্রভাব বজায় রাখতে ভারত চীনকে ক্রিকেট থেকে দূরে রাখছে',\n",
              " 'অর্থের উত্তাপে ভারত আম্পায়ারদেরকে করেছে সেবাদাস। ',\n",
              " 'ক্রিকেটবিশ্বে ভারত এখন কনেরও মামাশ্বশুর, বরেরও চাচাশ্বশুর।',\n",
              " 'ভারত ব্যবসা শিখল, সৌজন্য শিখল না।',\n",
              " 'আইপিএল সমূলে ধ্বংস করেছে ক্রিকেটের মৌলিকতা',\n",
              " 'শুধু ভাইরাসই শক্তিশালী হচ্ছে না,মূর্খরাও শক্তিশালী হচ্ছে',\n",
              " 'দক্ষিণ কোরিয়া শিক্ষা ও গবেষণা এবং স্বাস্থ্যে পৃথিবীর সর্বোচ্চ বরাদ্দ দেওয়া দুই তিনটি দেশ অন্যতম।',\n",
              " 'করোনো টেস্ট কিট বাংলাদেশে আবিস্কার হয়েছে',\n",
              " 'উট পাখির মত মাটিতে মুখ লুকিয়ে স্বল্প সময়ের জন্য কিছু মানুষকে বোকা বানানো যাবে কিন্তু সব সময় না।',\n",
              " 'আমাদের মেয়ররা কার্যত অকার্যকর',\n",
              " 'করোোনার বিরুদ্ধে আমাদের প্রস্তুতি শূন্যের গোড়ায়',\n",
              " 'আমাদের শিক্ষা ও স্বাস্থ্য খাতে বরাদ্দ অতি নগন্য',\n",
              " 'করোনোার ভয়াবহতা আমরা অনুধাবন করতে পারছি না',\n",
              " 'বিদেশ ফেরতদের কোয়ারান্টিনের গুরুত্ব বোঝাতে আমরা ব্যাথ',\n",
              " 'যে দেশ যত বেশি সভ্য সেই দেশ জাতীয় রিস্ককে তত বেশি গুরুত্ব দেয়',\n",
              " 'বিশ্ববিদ্যালয় গুলোর গণরুম বসবাস অযোগ্য ',\n",
              " 'জাতি হিসাবে আমরা বড়ই অসভ্য',\n",
              " 'একটা নির্দিষ্ট পরিমান টাকা মজুদ থাকার পর টাকা থাকা আর না থাকা একই কথা',\n",
              " 'টেক জায়ান্টদের মধ্যে গেটসকেই সবচেয়ে মানবতাবাদী এবং ভিশনারি মনে হয়।',\n",
              " 'মানুষ করোনা নিয়ে গুজব ছড়াতে ব্যস্ত',\n",
              " 'আমরা এই দেশের গুনীদের নানা উপায়ে অপমান করতে ব্যস্ত ',\n",
              " 'আমরাা সুযোগ পেলেই অসৎ পথে চলার চেষ্টা করি',\n",
              " 'আমাদের ভেজাল খাদ্যভাস এর জন্য অল্প বয়সে আমাদের নানা রোগে আক্রান্ত হতে হয়',\n",
              " 'অতিরিক্ত ভেজাল খাওয়ার ফলে এই দেশের মানুষের শরীরে প্রাকৃতিকভাবেই এক ধরণের ইমিউনিটি ডেভেলপ করেছে',\n",
              " 'হোম কোয়ারেন্টাইনে থাকা অবস্থায় বাসায় বসে নাটক সিনেমা দেখে সময় কাটানো যায়',\n",
              " 'আমাদেের করো না সনাক্তকরনের যথেষ্ট টেস্ট কিট নেই',\n",
              " 'করোনা নিয়ে সবার মধ্যে আতঙ্ক থাকলেও কারো মধ্যে কোনো সচেতনতা নেই',\n",
              " 'দেশের ক্রান্তিকালে সবাইকে  সচেতন হতে হবে',\n",
              " 'করোনা ভাইরাসের বিরুদ্ধে কোনো প্রটোকল ই এই দেশে মানা হচ্ছে না',\n",
              " 'নারী দিবস নিয়ে অনেকেই আমরা তুচ্ছ তাচ্ছিল্য করি',\n",
              " 'হোয়াইট বোর্ড আর মার্কার পরিবেষ দূষোণেড় জন্য দায়ী',\n",
              " '২০ শতাংশ মানুষই সকল ভালো কাজের নির্ণায়ক',\n",
              " 'ভারত এবং বাংলাদেষ দুই দেশের মধ্যে ধর্ম নিয়ে এক অদ্ভুদ মিল আছে',\n",
              " 'সান্ধ্যকালীন প্রোগ্রাম কোন ব্যাধি না ওটাও উপসর্গ',\n",
              " 'অনৈতিক শিক্ষকের কাছে পড়া শিক্ষার্থীরা ও এখন নৈতিকতার ধার ধারে না',\n",
              " 'পড়াশুনা কখনো লাভলোকশানের কথা ভেবে করা উচিত নয়',\n",
              " 'বাংলাদেশে মানুষ করোনাকে সেলুকাসে পরিনত করেছে',\n",
              " 'করোনায় আক্রান্ত রোগীদের সেবা দেয়ার জন্য ডাক্তারদের যথেষ্ট প্রোটেক্টিভ গিয়ার নেই',\n",
              " 'প্রস্তুতি নেয়ার অনেক সময় পেয়েও বাংলাদেশ করোনা সনাক্তকরনের টেস্ট কিট মজুদ করেনি',\n",
              " 'মায়ানমার ও উত্তর কোরিয়া করোনায় আক্রান্তদের গুলি করে মেরে ফেলছে',\n",
              " 'এক্সপোনেনশিয়াললি বাড়া মানে সময়ের সমান দূরত্বে আক্রান্তের সংখ্যা দ্বিগুন আকারে বাড়ে।',\n",
              " 'বাংলাদেশে  বিচারিক কাজে নগ্ন হস্তক্ষেপ চলে ',\n",
              " 'ঢাকা বিশ্বের সবচেয়ে দূষিত শহর',\n",
              " ' দুর্নীতি বাজদের জন্য এই দেশ এখনো পিছিয়ে',\n",
              " 'শিশু কিশোরদের ঘৃনা শেখানো উচিত না । ',\n",
              " 'খারাপকে খারাপ ভালো কে ভালো বলতে হবে সেখানে ধর্ম,জাতি,দেশ দেখা চলবে না',\n",
              " 'একজন ফ্রেশ গ্রেজুয়েট বিশ্ববিদ্যালয়ের শিক্ষক হতে পারে না',\n",
              " 'এইদেশ কখনো যোগ্যদের সঠিক সম্মান দিতে পারে নি',\n",
              " 'ভালোবাসার যত্ন নিতে হয়।',\n",
              " ' মিথ্যা ভালোবাসা থেকে বিরত থাকা',\n",
              " ' চোখের পানি সব দুঃখকে  ভাসিয়ে দিতে পারে।',\n",
              " ' ভালোবাসা জীবনের সত্যি গুলোকে  সামনে নিয়ে আসে',\n",
              " 'এক বছর হতে সময় লাগে ৩৬৫ দিন ৫ ঘন্টা ৪৮ মিনিট ৪৫.৯৭ সেকেন্ড।',\n",
              " '  সত্যিকারের ভালোবাসা পাওয়া কঠিন',\n",
              " ' বৃদ্ধ বাবা মায়ের প্রতি ভালোবাসা',\n",
              " ' ভালোবাসার মানুষ না পাওয়ার কষ্ট',\n",
              " ' সময় কাটানোর একটি মাধ্যম',\n",
              " ' আমি তো  দাড়িয়ে আছি',\n",
              " 'সব কিছুর উর্ধে আত্মসম্মান বোধ থাকা জরুরি',\n",
              " 'খারাপ সময় গুলোতে পাশে থাকা',\n",
              " ' কোনো কিছু দ্বিতীয় বার করায় কোনো লজ্জা নেই',\n",
              " ' দেশের পপ সম্রাট আজম খানের জন্মদিন',\n",
              " ' মানুষের মধ্যে শ্রোতার মনোভাবটির অভাব',\n",
              " ' বিয়েতে দেনমোহর জিনিসটা এখন দম্ভ দেখানোর মতো হয়ে গেছে।',\n",
              " ' বয়স বৃদ্ধির সাথে সাথে মানুষের বুঝার ক্ষমতাটাও বেড়ে যায়',\n",
              " ' সময়ের সাথে সাথে মানুষের জীবনের সব কিছুই বদলে যায়',\n",
              " ' মানুষ তার কর্মের জন্য দায়ী',\n",
              " ' কোনো মানুষকে  ছেড়ে আসার পর সে আর আমাদের থাকে না',\n",
              " ' যারা গরিব তাদের জীবনে দুঃখ কষ্ট সব সময়ের জন্য',\n",
              " ' সত্যিকার ভালোবাসার মানুষটি জীবনে একবারই আসে',\n",
              " ' অনুভুতি গুলো সব সময় থেকে যায়',\n",
              " ' মানুষকে জোর করে আটকে রাখা যায় না ',\n",
              " ' ১৮ বসরে করণীয় উপদেশ',\n",
              " ' ভালোবাসা শুধু মাত্রই একটি অনভুতি',\n",
              " 'প্রিয় হয়ে উঠতে হলেও যোগ্যতার প্রয়োজন\\n',\n",
              " 'দুঃসময়ে পরিপূর্ণভাবে পাশে থাকায় হচ্ছে ভালোবাসা।',\n",
              " ' মানুষ  কখনোই  একটি  মৌলিক  মানুষকে  ভালোবাসতে  পারে  না ',\n",
              " ' অরুণিমা শাবির মধ্যেই লুকিয়ে আছে। ',\n",
              " 'মেয়েরা তাদের অধিকার থেকে বঞ্চিত',\n",
              " ' অনেকেই  তার  ভালোবাসার  মানুষকে  ধোকা দেয়।  ',\n",
              " ' একটি সম্পর্ককে টিকিয়ে রাখতে হলে দুই দিক থেকেই বলিদান দেয়া প্রয়োজন। ',\n",
              " ' বইয়ের  সাদা  পাতার  আবেগ  গুলো  খুব  প্রাণময় ',\n",
              " ' স্কুল  জীবনের  স্মৃতি  সকলের  কাছেই  অমূল্য ',\n",
              " \" বাচ্চাটি দু'বার জন্মেছে \",\n",
              " ' জীবনকে উপভোগ করার জন্য সব  কিছুই আবশ্যক  ',\n",
              " ' আমি শুধু তোমারি হতে চাই ',\n",
              " 'সকলের ভাগ্যে প্রকৃত ভালবাসার মানুষ থাকে না',\n",
              " ' শুধু মেরে ফেলাকে খুন বলে না ,মানুষের মন ভাঙ্গাকেও খুন বলে',\n",
              " ' একজন মানুষের প্রতি সকলের ভালবাসা এক নয়',\n",
              " 'বৃন্দাবনের কষ্টের জীবন। ',\n",
              " 'সব কিছু মেনে নিয়েও আমি আপনাকে ভালোবাসবো। ',\n",
              " 'ভবিষ্যতের কথা চিন্তা করে ভালোবাসা হয় না',\n",
              " ' আব্দুল হামিদ দেশের মহান ব্যক্তিত্ব',\n",
              " ' জীবন  থেকে কিভাবে যে শুক্রবার গুলো চলে গেলো ',\n",
              " 'যার মন সুন্দর,  সে অল্পতেই খুশি হয়। ',\n",
              " 'নারীরা নির্যাতনের স্বীকার এইটা নিয়ে প্রতিবাদ। ',\n",
              " 'যৌতুক না নেয়ার বেপারে ছেলেরা বাবা মাকে বোঝাতে পারে ',\n",
              " 'ভালোবাসার জন্য আত্নসম্মান ছেড়ে দিও না ',\n",
              " 'নারীরা সব করতে পারে ',\n",
              " ' মাঝেমাঝে কিছুই ভালো লাগে না ',\n",
              " 'সেকেলে মেয়ের প্রেম ',\n",
              " 'বয়ফ্রেন্ড যখন অন্য ছেলের সাথে প্রেম করে। ',\n",
              " 'ভালোবাসার কিছু অনুভূতি ',\n",
              " 'করোনা ভাইরাসে সব কিছুর দাম বৃদ্ধি। ',\n",
              " 'পরিবার সবচেয়ে বড় জিনিস, ',\n",
              " 'ভালোবাসা লোক দেখানো নয়',\n",
              " 'খারাপ সময়ে সময় আরো খারাপ হয়ে যায়!',\n",
              " 'যা চলে যাই তার ফেরানো যাই না',\n",
              " 'আত্মসম্মান বিসর্জন দিয়ে স্বামীর সংসার করা হয়নি',\n",
              " 'ভাইয়া ডাকা মানে সব শেষ হয়ে যাবে না',\n",
              " ' সব খারাপ মানুষের মাঝে  এখন  ও  ভালো  মানুষ  আছে',\n",
              " ' অর্ণব আর জন্মদিন আজ ',\n",
              " 'করোনা ভাইরাস',\n",
              " 'আপনি ভুল মানুষটির সাথে আছেন, না সঠিক মানুষটির  সাথে যাচাই করুন\\n',\n",
              " 'টাকা দিয়া ভালোবাসা যাই না ',\n",
              " ' ভালোবাসা মানে এক অনুভূতি ',\n",
              " 'বিমান,হেলিকপ্টার এর সাউন্ড শুনলেই ভালো লাগে ',\n",
              " ' ভালোবাসার কোনো কারণ লাগে না ',\n",
              " 'অনেক কষ্টের তুলনায়  ব্রেকআপ আর কষ্ট   কিছুই  না ',\n",
              " 'অন্যরা কে কি ভাবলো আসে যায় না',\n",
              " 'এমন মানুষের সাথে প্রেম করুন যে আপনার প্রতি যত্নবান হবে। ',\n",
              " 'অল্পতেই সুখ খুঁজে পাওয়া যায়।',\n",
              " 'প্রেম করার ইচ্ছা',\n",
              " ' পাকিস্তানিদের কর্মকান্ড আগে আর এখন ',\n",
              " '  ভালো  লাগার  অদ্ভুত কারণ ',\n",
              " ' বাঙলী নারীর সৌন্দর্য শাড়িতে।',\n",
              " ' ভুল মানুষের হয় তাই মানুষ নিখুঁত না',\n",
              " ' কিছু মানুষ থাকে যাদের কিছুতেই কোনো টেনশন নেই',\n",
              " ' বুধবার দিনে ঘটে যাওয়া কিছু কথা',\n",
              " 'কোনো কাজই ছোট নয়',\n",
              " ' সবারই মানিয়ে নেওয়া শিখা উচিত',\n",
              " 'সারাদিন অনলাইন থাকা মানেই প্রেম করা না।',\n",
              " 'মেয়ে একটা গালি হয়ে গেছে এখন',\n",
              " 'মায়ের ভালোবাসাই নির্ভেজাল এর স্বার্থহীন।',\n",
              " 'তৃতীয় বিশ্বযুদ্ধের ভয়াবহতা বাংলাদেশে আসে পড়তে পারে',\n",
              " 'যে তোমার সাথে কথা বলতে চেয়েও কথা বলতে পারছে না তাকে ভালোবাসো ',\n",
              " 'অতীত দেখে কাউকে বিচার করো না ',\n",
              " 'একজন ধর্ষিতা মেয়েকে বিয়ে করা যাই। ',\n",
              " ' আবারো ভালোবাসা যায়, যদি তার কাছে  নিজেকে নতুন করে পরিচয় করিয়ে দেয়া যায়। ',\n",
              " 'কেউ তোমাকে ছাড়া থাকতে পারলে তুমিও তাকে ছাড়া থাকতে পারবে। ',\n",
              " 'আল্লাহ যা দিয়েছে যথেষ্ট দিয়েছে',\n",
              " 'তুমি যা করবে তাই পাবে',\n",
              " 'দেখা না হওয়ার কষ্ট ',\n",
              " ' মেয়েদের মন বোঝার কিছু টিপস। ',\n",
              " 'নিজের স্বপ্ন মেয়েকে দিয়ে পূরণ করা',\n",
              " 'নারীরা শুধ ধর্ষিতা হওয়ার জন্য জন্মায় না ',\n",
              " 'মানুষের চিন্তাভাবনা পরিবর্তন করা দরকার ',\n",
              " 'ধর্ষণ প্রতিনিয়ত ঘটছে ',\n",
              " 'বউ এর জন্য নিজে না খেয়ে ভাগাভাগি করে খাওয়া',\n",
              " 'মেসি সবার সেরা।',\n",
              " 'অগ্নিকান্ডের সময় উপস্থিত জনগণের করণীয়।',\n",
              " 'জ্যামের জন্য এক্সাম মিস ।',\n",
              " 'নাঈমকে টাকা দেয়া হচ্ছে ।',\n",
              " 'উজ্জ্বল অর্থের প্রয়োজনে মিথ্যা সংবাদ প্রচার করে।',\n",
              " 'হোলি খেলাটাই হল না।',\n",
              " 'একজন সাহসী পাবে তার সম্মানী ।',\n",
              " 'স্বপ্ন দেখি ইংরেজীতে একদিন অনেক ভাল করব।',\n",
              " 'সবার সামনে ইংরেজি বলতে পারছি ।',\n",
              " 'লিংকটা চাচ্ছিলাম।',\n",
              " 'জীবনকে বদলে দিয়েছে।',\n",
              " 'পারেন না দেখেই আমার গ্রুপে এসেছেন।',\n",
              " 'বাস্তবতা কে ঘৃনা করি।',\n",
              " 'কুচক্রী মহলের শাস্তি হোক।',\n",
              " 'হাইটেক পার্ক নির্মাণ কাজ হাতে নিয়েছে সরকার।',\n",
              " 'শত শত তরুন তরুণীর কর্মসংস্থা্র ব্যবস্থা হবে।',\n",
              " 'প্রতিবন্ধী মেয়েদের জন্য পরিচর্যা কেন্দ্র স্থাপন করা হবে।',\n",
              " 'বিল গেটস এবং পল অ্যালেনের উদ্যোগে প্রতিষ্ঠিত হয় মাইক্রোসফট।',\n",
              " 'মাইয়ের দৃষ্টান্তমূলক শাস্তি চাই।',\n",
              " 'ভানুয়াতুতে শ্রমিক আটকা পড়েছে।',\n",
              " 'আজকে তো স্বাধীনতা দিবস।',\n",
              " 'এক যুগ ঘুমিয়ে উঠলাম।',\n",
              " 'আজকের ল্যাবটা করা জরুরী।',\n",
              " 'আর্টিফিশিয়াল ইন্টেলিজেন্স ক্লাস হবে না।',\n",
              " 'আগুনে পুড়ে নিহত কাওছারের দুই শিশুর দায়িত্ব নেওয়া বেশি জরুরি।',\n",
              " 'পরিচিতজন খোঁজ না নেওয়া মূলত ভালোবাসা কমায়।কিন্তু সত্য হলো ভালোবাসা কখনও কমেনা।',\n",
              " 'দূর্ঘটনায় সাহায্য না করে সোশ্যাল মিডিয়ায় লাইভে আসার কালচার আমাদের।',\n",
              " 'স্বপ্ন সেটা যা মানুষকে ঘুমাতে দেয় না।',\n",
              " 'বজ্রের বিদ্যুৎ সঞ্চিত করলে সেটা হবে ইলেকট্রিসিটির আধার।',\n",
              " 'স্কাউটের ছেলেমেয়গুলো অসাধারণ উদ্যোগ দেখে নিজে থেকে ওভারব্রীজ দিয়ে পার হয়েছি।',\n",
              " 'আমি অশ্বমেধের ঘোড়া হতে চাই।',\n",
              " 'হঠাৎ মনে হচ্ছে বয়স বাড়ছে, হাজার বছরের পুরানো সেই বয়স',\n",
              " 'কাভার্ডভ্যানের ধাক্কায় ব্র\\u200d্যাকের শিক্ষার্থী ফাহমিদা নিহত।',\n",
              " 'ট্রাফিক জ্যাম আমাদের জীবনের অবিচ্ছেদ্য একটি বিষয়।',\n",
              " 'কোচিং সেন্টার ব্যবসায়ীর দ্বারা শিক্ষার্থীরা হেনস্তার স্বীকার।',\n",
              " 'মিত কি মেনে নেবে মেঘ কে নাকি ভুল বুজবে|',\n",
              " \"মেশিন লার্নিং এর কল্যানে 'ফুল সেলফ ড্রাইভিং' মোড চলে আসবে আমাদের হাতের নাগালে।\",\n",
              " 'সময় গেলে সময় আসবে কিন্তু জানটা শরীর থেকে বেরিয়ে গেলে আর ফিরে আসবে না।',\n",
              " 'পাটকেল হাতে নিয়াও চুপচাপ বসে আছি।',\n",
              " 'ভেতরে মানুষ জীবন-মৃত্যুর মাঝখানে আটকে আছে।',\n",
              " 'সমাজে আমি ও চিন্তা ভাবনা গুলো বেমানান।',\n",
              " 'স্বাধীনতা চাইতে চাইতে আজ তুমি পশুর খাঁচায়।',\n",
              " 'অতীতে গিয়ে তারা পাথর খুঁজে এনে আবার মারামারির প্রস্তুতি নিচ্ছে।',\n",
              " 'থেতলে যাওয়া মাথা দিয়ে ঘুমাতে কষ্ট হয়।',\n",
              " 'টপিকের সাগরে হারিয়ে যাচ্ছি।',\n",
              " 'মানসিকতার পাল্টানোর মধ্য দিয়ে পৃথিবী পাল্টে দেওয়া সম্ভব।',\n",
              " 'অঘটন এর মধ্যে একটা বাজে দিন কাটালাম।',\n",
              " 'বৃষ্টির দিনে গ্রামের বাড়িকে বেশি মিস করি।',\n",
              " 'আন্দোলন করার জন্য স্কুল কলেজ বন্ধ করার দরকার হয় না।',\n",
              " 'শিল্পীর শিল্পকর্ম মৃত্যুর মধ্যে জনপ্রিয়তা এবং চাহিদা হয়ে উঠা অনেক পুরাতন রীতি।',\n",
              " 'কথার ও রাগেরপৃষ্ঠে ঢাকা পড়লো মনের আর্তনাদ।',\n",
              " 'প্রত্যেকটা মানুষেরই কোন কিছুর প্রতি প্রবল আকর্ষণ থাক।',\n",
              " 'প্রাইভেট আর পাবলিক বিশ্ববিদ্যালয়ের পার্থক্য পরীক্ষা ও ছুটি ।',\n",
              " 'কিছু জিনিসের সৌন্দর্যটাই অন্যরকম।',\n",
              " 'ঘুমহীন চোখে ভাবছি বসে, সফল ছেলে কার?',\n",
              " 'সৌখিনতা আর বিলাসিতার জন্য ধনের প্রাচুর্যয়ের খুব একটা দরকার নেই।',\n",
              " 'এগিয়ে চলছি আর ভাবছি কখন বিশ্রামের সময় হবে।',\n",
              " 'লুকিয়ে থাকা সুপারহিরো অদ্ভূত জাদুকর।',\n",
              " 'প্রকৃতির খুব কাছে গিয়ে সময় কাটাতে ইচ্ছে করে।',\n",
              " 'পড়াশোনা বাদ,একটা ভালো গুন্ডা হবো।',\n",
              " 'পরীক্ষা আসলেই মনের মধ্যে অন্যরকম আনন্দ বিরাজ করে।',\n",
              " 'জীবনকে পরিপূর্ণভাবে উপভোগ করার জন্য একা থাকাটা খুবই জরুরী।',\n",
              " 'জীবনটাকে জটিল করার কি দরকার একটা সরল সমীকরণ মাত্র।',\n",
              " 'জমলো মেলা আমার বয়স ষোল তে প্রেম প্রেম খেলা।',\n",
              " 'আয়নাবাজি টিম গল্পটাকে যথাযথভাবে রূপ দিয়েছে।',\n",
              " 'ঘুমের পর এখনও ঘুম ছাড়া আর কিছু দেখার ইচ্ছে হচ্ছে না।',\n",
              " 'চোখের ভাষায় অভিমান হাজারো।',\n",
              " 'সত্যিকারের ভালোবাসা টা আমাকে সে অর্পণ করতে চেয়েছিল।',\n",
              " 'ধর্ম রক্ষা করার জন্য অন্যের বিরুদ্ধ্যে যুদ্ধ ঘোষনা করার দরকার নেই।',\n",
              " 'আলাদিনের জ্বীন লুকিয়ে থাকে বিশ্লেষণের মধ্যে।',\n",
              " 'পড়া শেষ হয় না।',\n",
              " 'রাগ ঝাড়ার মতো বালাই আর নাই।',\n",
              " 'আমার নিস্পাপ সন্তানের নির্মম খুনের বিচারের দাবিতে আপনাদের সমর্থন চাই।',\n",
              " 'স্বাধীনতার পর থেকে চলমান অসুস্থ ধারার রাজনীতি এখনো বহাল।',\n",
              " 'কমনসেন্সহীন মানুষগুলোর সমস্যাটা কি?',\n",
              " 'ভবিষ্যৎতে এমন ঘটনা যেন না ঘটে তাই আগে থেকেই সচেতন থাকা উচিৎ।',\n",
              " 'মানুষ উড়াও এর মাধ্যমে আকাশ পথে চলাফেরা করবে।',\n",
              " 'ড্রাইভাররা কি কখনও নিয়ম মেনে গাড়ি চালাতে পারবে না?',\n",
              " 'আমি আর নিস্পাপ চাদ সারারাত কথা বলে করেছি পার।',\n",
              " 'মাটির দেহ আবার মাটিতেই মিশে যাবে।',\n",
              " 'সবার সামনের দিনগুলা খুব ভাল কাটে।',\n",
              " 'ঘূর্ণিঝড় ফণী আয়তনে বাংলাদেশের চেয়ে বড়।',\n",
              " 'কিছু মানুষের চক্ষু লজ্জা শব্দের সাথে পরিচয় হওয়া উচিত।',\n",
              " 'আমরাও ব্যাঙের মত মানিয়ে নিচ্ছি আমাদের চারপাশের সাথে।',\n",
              " 'ভালোবাসা আলাদা জিনিস যার মাঝে কোন চাহিদা নেই।',\n",
              " 'প্রথমে জানুন কম্পিউটার ইঞ্জিনিয়ার কি নিয়ে পড়াশুনা করে এবং কি কাজ করে, তারপর কথা বলুন।',\n",
              " 'অপ্রত্যাশিত ভাবে কিছুদিন আগে ফোনটা চুরি হয়ে গিয়েছিল।',\n",
              " 'অপ্রত্যাশিত ঘটনাগুলো প্রত্যাশিতভাবে একের পর এক ঘটতে থাকে।',\n",
              " 'সবচেয়ে ভারী বস্তুটা মাথায় ভর করেছে।',\n",
              " 'প্রকৌশোলীর আয় জনগণ ও জাতির সমৃদ্ধির সাথে বৃদ্ধি পায়।',\n",
              " 'বাঁচার ইচ্ছেটা এখন আর কাজ করেনা।',\n",
              " 'নিজে সুযোগ পাইনাই তাই অন্যকেও পাইতে দিবো না।',\n",
              " 'ধন্যবাদ \"নীলাম্বরী\"সকালটা আমার করে দেওয়ার জন্য।',\n",
              " 'পর্দার গল্পের পিছনেই একটা সত্য গল্প লুকায়িত থাকে যা চোখের আড়ালেই নিঃশেষ হয়ে যায় ।',\n",
              " 'অর্থ না বুঝে কখনো কারো বেস্ট ফ্রেন্ড হওয়ার চেষ্টা করো না।',\n",
              " 'আমি কিন্তু মজনু বা ফরহাদ না।',\n",
              " 'কারো প্রতি মায়া বাড়াতে নেই।',\n",
              " 'এক্সপেকটেশন থেকে বেশিই পাইছি মুভিটা থেকে।',\n",
              " 'অভিধানে শেষ বলে কোন শব্দ নাই।',\n",
              " 'তুই তো এখন আমার না।',\n",
              " 'নির্বোধ হয়ে গেছি আমরা',\n",
              " 'ঠাডা পড়ুক সবার উপর।',\n",
              " 'ভালো লাগা আর ভালোবাসা এক নয়।',\n",
              " 'জীবনে কি এমন পূন্য করেছি আল্লাহ আমাকে এত্তোটা সাহায্য করে।',\n",
              " 'আমার কাছে কাল শুধুই রবিবার।',\n",
              " 'ইঞ্জেকশন কে ভয় পায়।',\n",
              " 'কুলখানি না কারো বিয়া খাইতে আসছে।',\n",
              " 'মানুষ জন এর উপকার করতে চাইলে ভাত নাই।',\n",
              " 'কটুর জন্য ছেলে হয়ে গেছে।',\n",
              " 'নিজে কোনো কিছু করার মাঝে যে সুখ তা অন্যের মাধ্যমে পাওয়া যায় না।',\n",
              " 'পোলা গো কইলজা এত্ত বড়।',\n",
              " 'আমার ভাষা নাই।',\n",
              " 'বিরিয়ানি লাভারদের কথা কেউ মাথায় রাখলো নাহ।',\n",
              " 'বিয়ে করে ঘর জামাই রাখে।',\n",
              " 'মানুষ রে কষ্ট দিয়ে লাভ টা কি?',\n",
              " 'আমার টাকা গুলান বাঁচতো।',\n",
              " 'গুজব ভাবিয়া বিভ্রান্ত হবেন না।',\n",
              " 'সবাইকে চলে যেতে দেয়া উচিৎ।',\n",
              " 'অনের বড় হ তোরা।',\n",
              " 'একদিন নিজের একটা পরিচয় হবে।',\n",
              " 'লাখ টাকা খরচ করে বিদেশে ঘুরতে যাই।',\n",
              " 'সীতাকুন্ডের সবচেয়ে দুর্গম ভয়ংকর ঝর্ণা হচ্ছে সোনাইছড়ি।',\n",
              " 'নৌবাহিনীর সক্ষমতা আরো বৃদ্ধি করবে।',\n",
              " 'প্রধানমন্ত্রী ক্ষতিগ্রস্তদের সহায়তার নির্দেশ প্রদান করেছেন।',\n",
              " 'অনুশোচনা ছাড়া আর কিছুই করার থাকবে না।',\n",
              " 'মুশফিক কেন \"জিরো\" রানে আউট হলো।',\n",
              " 'রিটেক নিতে কলিজা লাগে।',\n",
              " 'কেউ কারো সম্পত্তি নয়।',\n",
              " 'দাদীকে খুব মিস করি।',\n",
              " 'সুন্দর অতীত খুব ভোগায়।',\n",
              " 'ভালোবাসা মানে অমরত্ব',\n",
              " 'সঠিক বন্ধু নির্বাচন করুন।',\n",
              " 'মেয়েরা দুই ধরনের হয়।',\n",
              " 'খালি নাচবো আর খাবো।',\n",
              " 'পানামা যাওয়ায় আমি খুশি।',\n",
              " 'নারীরা সবসময় পুরুষ থেকে ক্ষমতাবান।',\n",
              " 'অসাধারণ মানুষের চিন্তা গুলো।',\n",
              " 'আপনি জীবন্ত কিংবদন্তী।',\n",
              " 'নিজেকে গড়ে তোলার নাম সফলতা।',\n",
              " 'এরা ছাত্র না বহিরাগত।',\n",
              " 'তোমাকে পেরিয়ে চলে যাচ্ছি।',\n",
              " 'লোকাল বাসের মতো বাংলাদেশ ক্রিকেট দল।',\n",
              " 'উপভোগে ও প্রকৃতির অভিযোগ নাই।',\n",
              " 'ক্যাসিনো আর শেয়ার বাজার দুইটাই জুয়া।',\n",
              " '১০ কোটি টাকা গুনতে দেওয়া হোক।',\n",
              " 'বাংলাদেশে ভালো ছেলে নাই।',\n",
              " 'অবশেষে বাংলাদেশ পেলো লেগ স্পিনার।',\n",
              " 'ঘরে বসে দূরে কাউকে জ্বালিয়ে মারার মতো মজা আর কোথাও নেই।',\n",
              " 'কমের কাছে থাকার আকুতি।',\n",
              " 'খেলা দেখে আত্মবিশ্বাস কমে যাবে।',\n",
              " 'পৃথিবীতে যত কিছু মহৎ আর কল্যাণ কর , অর্ধেক করিয়াছে নারী , অর্ধেক তার নর ।',\n",
              " 'মানবিক দৃষ্টিতে তি\\u200cন্নি দা\\u200cশকে একটি বিভাগে ভর্তি করানো।',\n",
              " 'কাউকে নিয়ে কিছু লেখা কঠিন ব্যাপার।',\n",
              " 'নোয়াখালীবাসী তাদের সাধ্য মতো চেষ্টা করে',\n",
              " 'সবাই কাবাডি খেলায় মন দে।',\n",
              " 'নম্বর আনব্লক করার প্রয়োজন নাই।',\n",
              " 'প্রাইভেটে পড়েও বেঁচে থাকো।',\n",
              " 'স্ট্যাটাস টা ভারত বিরোধী।',\n",
              " 'দোষ দেয়া সোজা',\n",
              " 'এই যুবকেরাই আগারওয়াল',\n",
              " 'জাজ করতে যাওয়াটা বোকামী।',\n",
              " 'আমাকে ঘুষ দিতে চেয়েছিলো।',\n",
              " 'দেখেই হয়তো চেনা যায়।',\n",
              " 'পেয়েছি একটা ব্যাতিক্রমী গল্প।',\n",
              " 'এক প্লেট সাদা চকচকে ভাত।',\n",
              " 'বিচারের রায়কে শ্রদ্ধা করো।',\n",
              " 'মানুষ কত খারাপ।',\n",
              " 'এটা তো তোমার দোষ।',\n",
              " 'তিনি আবারও ক্ষমতায় আসছেন।',\n",
              " 'যার ন্যুনতম ধারনা নেই।',\n",
              " 'সভা, সমাবেশ করতে দেওয়া উচিত।',\n",
              " \"আরো দু'টি মেট্রোরেল হচ্ছে ঢাকায়।\",\n",
              " 'টাইম মেশিন আছে।',\n",
              " 'ট্রিট নয় ট্রিটমেন্ট চাই।',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD6a2l8YPFge",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7ce65e7c-24a9-43df-feda-c1b6765ddfa8"
      },
      "source": [
        "summarize(\"মানুষের মুখ খুব শ ক্তিশালী এক জিনিস। মানুষ যেটা বলে সেটার একটা প্রভাব আছে।অভিজ্ঞতা থেকে দেখেছি একটা ছেলেকে ক্ষেপানোর জন্য বলা হতো, অমুক মেয়ের সাথে তুই প্রেম করিস। কদিন পরে সত্যি সত্যি তারা প্রেম করা শুরু করে দিয়েছিল।স্বামী-স্ত্রীর মনোমালিন্যর সময় হয়ত স্ত্রী আফসোস করে বলল, আমি পুরোনো হয়ে গেছি - এখন তো আর আমাকে ভালো লাগবে না।সত্যি সত্যি দেখা যাবে কদিন পরে স্বামীর ঠিক ওই জিনিসটাই মনে হতে থাকবে। অথচ হয়ত সে এ ব্যাপারে আগে ভাবেইনি।একটা ছেলেকে পরিবারের সবাই বলে, তুই কোনো কাজের না - দেখা যাবে ছেলেটা আসলেই কিছু করতে পারছে না।এজন্য রসুল সাল্লাল্লাহু আলাইহি ওয়া সাল্লাম বলেছেন, হয় ভালো কথা বলো নয়ত চুপ থাক।আমাদের জীবনের বহু ভালো পরিস্থিতি খারাপ থেকে খারাপ হয়েছে শুধুমাত্র আমাদের কথার কারণে।জিহবা সাবধান ভাইয়েরা। মুখ সাবধান বোনেরা।রসুল সাল্লাল্লাহু আলাইহি ওয়া সাল্লামের কথাটাকে দাম দিই - সংসারে শান্তি আসবে, আয়ে বারাকাহ আসবে।\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ভালো কথা বল নয়ত চুপ থাকো'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERj84JjDP_x-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ef40a8b1-a649-46e9-d925-3c73e8b5ddcb"
      },
      "source": [
        "summarize(\"ক্লাসে সবচেয়ে দূর্বল ছেলেটি কাল সমাবর্তনে এসেছিল সবার চেয়ে হাই পজিশনের জব নিয়ে। বারবার প্রেমে ব্যর্থ হওয়া মেয়েটি এসেছিল একটি সুন্দর ছোট্ট পরিবার নিয়ে। কারো কাছে পাত্তা না পাওয়া, তোকে দিয়ে কিছু হবে না বলা ছেলেটিই সবচেয়ে সুন্দর বউ নিয়ে এসেছে। পড়াশোনার খরচ যোগাতে টিউশন করে হাত খরচ চালানো মেয়েটি কাল গাড়ি দিয়ে ক্যাম্পাসে এসেছিল। ক্লাসের সবচেয়ে সাক্সেস্ফুল ছেলেটি ডিপ্রেশনে ভুগছে জব না পাওয়ায়। ডিপার্টমেন্টের হার্টথ্রোব মেয়েটির চোখে নিচে কালি বিয়ে হচ্ছে না বয়স হয়ে গেছে।এভাবেই সময়ের সাথে বদলে যায় মানুষের জীবনে ইকুয়েশন। আসলে সমাবর্তনের মাধ্যমে শিক্ষা জীবনের শেষ হলেও সফলতা ও ব্যর্থজীবনের হিসাব গণনা শুরু হয়ে এখান থেকেই।তাই ঘৃণা, হিংসা, কম্পিটিশন বাদ দিয়ে জীবনটাকে বাচা উচিত সম্পূর্ণ স্বাদ ও ভালবাসা নিয়ে। কখন জীবনের কোন মোড় দেখায় কোন নিশ্চয়তা নেই, তাই কোন মুহূর্তের জন্য যাতে আফসোস না থাকে।\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'সমাবর্তনের মাধ্যমে শিক্ষা জীবনের শেষ হলেও সফলতা ও ব্যর্থজীবনের হিসাব গণনা শুরু হয়ে এখান থেকেই'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YKHMymdSugA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0c0d8fa3-f6bf-48e2-a1c6-c10c39816e08"
      },
      "source": [
        "summarize(\"ইতালির প্রধানমন্ত্রী জুসেপ্পে কন্তে বলেছেন, একেকজন বাংলাদেশি একেকটা ভাইরাস বোমা। অনেক বাংলাদেশি ভাই সেটাকে শেয়ার করে দেশকে পরোক্ষভাবে তিরস্কার করছেন। অথচ কন্তে সাহেবকে বলা দরকার, আমাদের অসচেতনতা নিয়ে এমন ঢালাও মন্তব্য করার আগে আপনার অগ্রজ শাসকদের দিকে তাকান। নিরো সাহেবের দিকে তাকান।আপনি কী জানেন না? রোম যখন পুড়ছিলো, নিরো তখন সাহেব বাঁশি বাজাচ্ছিলেন।আর আমরা একটু বাঁশি বাজালেই দোষ...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'সকলের প্রতি সহ মর্মিতা ইসলাম আমাদের শিক্ষা দেয়'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(\"মুক্তির সারথি বাংলাদেশ সাধারণ ছাত্র অধিকার সংরক্ষণ পরিষদ আমাদের দেশে স্বাধীনতার পর থেকে চলমান অসুস্থ ধারার রাজনীতি এখনো বহাল তবিয়তে চলছে। এই অবস্থা থেকে বের হয়ে আসতে না পারলে দেশ ও জাতি আরো গভীর অন্ধকারে নিমজ্জিত হবে। একটি দেশের প্রকৃত উন্নয়ন নির্ভর করে সেদেশের রাজনৈতিক স্থিতিশীলতার উপর। দেশে দৃশ্যমান উন্নয়ন অনেক কিন্তু প্রকৃত উন্নয়ন কতটা তা যতেষ্ঠ প্রশ্নের মুখোমুখি আজ। উল্টো দেশের স্তম্ভ গুলো দিনকে দিন দুর্বল থেকে দুর্বলতর করা হচ্ছে। আইন বিচার এবং শাসন বিভাগের অবস্থা বড্ড নাজুক। এখন অনেক সময় দেখি মহান জাতীয় সংসদ কোরাম সংকটে ভুগে। সাংবিধানিক প্রতিষ্ঠান গুলো তাদের স্বকীয়তা হারাচ্ছে অনবরত। বাংলাদেশ নির্বাচন কমিশন, দুর্নীতি দমন কমিশন সহ সাংবিধানিক প্রতিষ্ঠানগুলোকে এখন আর কার্যকর তেমন কোন পদক্ষেপ নিতে দেখি না আর আমরা।রাষ্ট্রের চতুর্থ স্তম্ভ গণমাধ্যম, এই গণমাধ্যমের অবস্থা যে খুব একটা ভাল তাও কিন্তু নয়। তবুও বলবো সব মিলিয়ে এগিয়ে যাচ্ছে প্রিয় স্বদেশ। আগামীতে গণমানুষের প্রত্যাশা পূরণে কাজ করে যাবে ছাত্রসমাজের প্রাণের স্পন্দন বাংলাদেশ সাধারণ ছাত্র অধিকার সংরক্ষণ পরিষদ দেশ ব্যাপি কমিটি হালনাগাদের কার্যক্রম চলমান রয়েছে, আপনি আছেন তো আপনার জেলার কমিটিতে....??যুক্ত না থাকলে এখনি সময় যুক্ত হওয়ার। আপনাদের হাত ধরেই পরিবর্তন আসবে ইনশাআল্লাহ।।\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Swe6Dl93DEfY",
        "outputId": "c54ce1ef-337f-41f4-b13c-a5f57ef8b1e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'স্বাধীনতার পর থেকে চলমান অসুস্থ ধারার রাজনীতি এখনো বহাল।'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUvYIrLxWSAZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bf55194-26e9-4fd7-976e-b457357cd4b8"
      },
      "source": [
        "!pip install rouge"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL_JfyFyXgEP"
      },
      "source": [
        "from rouge import Rouge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSoXj0WkaQw-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea23ff9f-b7a9-457f-cd81-da2a43a242c3"
      },
      "source": [
        "hypothesis = \"স্বাধীনতার পর থেকে চলমান অসুস্থ ধারার রাজনীতি এখনো বহাল।\"\n",
        "reference = \"স্বাধীনতার পর থেকে চলমান অসুস্থ ধারার রাজনীতি এখনো বহাল।\"\n",
        "\n",
        "rouge = Rouge()\n",
        "scores = rouge.get_scores(hypothesis, reference)\n",
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'rouge-1': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-2': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-l': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "BLEUscore = nltk.translate.bleu_score.sentence_bleu([reference], hypothesis)\n",
        "print(BLEUscore)\n"
      ],
      "metadata": {
        "id": "96B3LVoV0DjP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "813a1887-a43b-4653-e7f1-d5d14c3f84fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    }
  ]
}